1. [Psychological gulfs](#Psychological-gulfs)
	1. [Ask vs guess vs tell culture](#Ask-vs-guess-vs-tell-culture)
2. [Epistemic learned helplessness](#Epistemic-learned-helplessness)
	1. [Fact posts as solution](#Fact-posts-as-solution)
4. (UNDER ???)
	1. [The level above Hitler: upper limits on social abilities](#The-level-above-Hitler)
5. (UNDER AI)
	1. [Intelligence as efficient cross-domain optimization](#efficient-cross-domain optimization)
7. [Tools shape users](#Tools-shape-users)	


<a name="#Tools-shape-users"></a>
## Tools shape users
([overview](#overview))

From Venkat Rao's [When tools shape you](https://www.ribbonfarm.com/2016/11/23/when-tools-shape-you/):

```markdown
The weaponized form of McLuhan’s famous phrase the medium is the message is the 
phrase, *first we shape our tools, then our tools shape us* (due to to McLuhan’s 
friend John Culkin).

Doc Ock’s artificially intelligent arms fuse to his brain stem in a reactor 
accident. In the movie version, the intelligence in the arms alters his behavior
by making lower-level brain functions, such as emotional self-regulation, more 
powerful and volatile. The character backstory suggests a personality — a blue-
collar nerd bullied as a schoolkid — that was already primed for destabilization
by the usual sort of super-villain narcissistic wound. The accident alters the 
balance of power between his higher-level brain functions, and the hardware-
extended lower-level brain functions. 

In the Doc Ock story, *first we shape our tools, then our tools shape us* captures
the adversarial coupling between medium and message-sender.
```

Three forms -- weak, stronger, strongest:

```markdown
The weaker form of McLuhan’s idea suggests that media select messages rather than
the other way around: paper selects for formal communication, email selects for 
informal communication, 4chan selects for trolling.

The stronger form suggests that when there is a conflict between medium and message,
the medium wins. A formal communication intent naturally acquires informal overtones
if it ends up as an email, memetic overtones if it ends up as a 4chan message.

Culkin’s form is the strongest. It suggests that the medium reshapes the principal 
crafting the message. The Doc Ock motif suggests why. There is no such thing as a 
dumb agent. All media have at least weak, latent, distributed intelligence. 
Intelligence that can accumulate power, exhibit agency, and contend for control.
```

I wasn't very convinced of Culkin's version, but then Venkat cites Pournelle's iron law of bureaucracy which gave me pause:

```markdown
The most familiar example of this effect is in organizational behavior, captured in
an extension to Alfred Chandler’s famous observation that structure follows strategy.
That becomes *first structure follows strategy, then strategy follows structure*. The 
explicit form is Pournelle’s Iron Law of Bureaucracy: in a mature organization, *agent
goals trump principal goals*.

In all such examples, the mechanism is the same. A seemingly powerless and dumb agent, 
by virtue of having privileged access to information and organizational operations, can
become the principal by converting growing tacit knowledge of reality into consciously
exercised political leverage.
```

Yeah, still not quite convinced that "media can contend for control" -- a bit too anthropomorphic for me. Egregores aren't really like that. Moloch isn't, Ra isn't, and they're *plenty* powerful! But I do think Venkat is pointing towards something real and important here.




(THE LEVEL ABOVE HITLER)

<a name="#efficient-cross-domain optimization"></a>
### Efficient cross-domain optimization
([overview](#overview))

A bit more evocatively, "computationally-frugal cross-domain future-steering". From Eliezer Yudkowsky's [efficient cross-domain optimization](https://www.lesswrong.com/posts/yLeEPFnnB9wE7KLx2/efficient-cross-domain-optimization):

```markdown
Is Deep Blue "intelligent"?  It was powerful enough at optimizing chess boards to
defeat Kasparov, perhaps the most skilled chess player humanity has ever fielded.

A bee builds hives, and a beaver builds dams; but a bee doesn't build dams and a 
beaver doesn't build hives.  A human, watching, thinks, "Oh, I see how to do it" 
and goes on to build a dam using a honeycomb structure for extra strength.

Deep Blue, like the bee and the beaver, never ventured outside the narrow domain 
that it itself was optimized over.

There are no-free-lunch theorems showing that you can't have a *truly general* 
intelligence that optimizes in all possible universes (the vast majority of which 
are maximum-entropy heat baths).  And even practically speaking, human beings are
better at throwing spears than, say, writing computer programs.

But humans are much more cross-domain than bees, beavers, or Deep Blue.  We might
even conceivably be able to comprehend the halting behavior of every Turing 
machine up to 10 states, though I doubt it goes much higher than that.

Every mind operates in some domain, but the domain that humans operate in isn't 
"the savanna" but something more like "not too complicated processes in low-
entropy lawful universes".  We learn whole new domains by observation, in the 
same way that a beaver might learn to chew a different kind of wood.  If I could
write out your prior, I could describe more exactly the universes in which you 
operate.

Is evolution intelligent?  It operates across domains - not quite as well as 
humans do, but with the same general ability to do consequentialist optimization
on causal sequences that wend through widely different domains.  It built the bee.
It built the beaver.

Whatever begins with genes, and impacts inclusive genetic fitness, through any 
chain of cause and effect in any domain, is subject to evolutionary optimization.  
That much is true.

But evolution only achieves this by running millions of actual experiments in which
the causal chains are actually played out.  This is incredibly inefficient.  
Cynthia Kenyon said, "One grad student can do things in an hour that evolution 
could not do in a billion years."  This is not because the grad student does 
quadrillions of detailed thought experiments in their imagination, but because the
grad student abstracts over the search space.

By human standards, evolution is unbelievably stupid.  It is the degenerate case of
design with intelligence equal to zero, as befitting the accidentally occurring 
optimization process that got the whole thing started in the first place.

(As for saying that "evolution built humans, therefore it is efficient", this is, 
firstly, a sophomoric objection; second, it confuses levels.  Deep Blue's programmers
were not superhuman chessplayers.  The importance of distinguishing levels can be 
seen from the point that humans are efficiently optimizing human goals, which are not
the same as evolution's goal of inclusive genetic fitness.  Evolution, in producing 
humans, may have entirely doomed DNA.)

I once heard a senior mainstream AI type suggest that we might try to quantify the 
intelligence of an AI system in terms of its RAM, processing power, and sensory input 
bandwidth.  This at once reminded me of a quote from Dijkstra:  "If we wish to count 
lines of code, we should not regard them as 'lines produced' but as 'lines spent': the
current conventional wisdom is so foolish as to book that count on the wrong side of 
the ledger."  If you want to measure the intelligence of a system, I would suggest 
measuring its optimization power as before, but then dividing by the resources used.
Or you might measure the degree of prior cognitive optimization required to achieve 
the same result using equal or fewer resources.  Intelligence, in other words, is
*efficient* optimization.

So if we say "efficient cross-domain optimization" - is that necessary and sufficient
to convey the wisest meaning of "intelligence", after making a proper effort to factor
out anthropomorphism in ranking solutions?

I do hereby propose:  "Yes."
```

Steering the future:

```markdown
Occasionally I hear someone say something along the lines of, "No matter how smart
you are, a tiger can still eat you."  Sure, if you get stripped naked and thrown 
into a pit with no chance to prepare and no prior training, you may be in trouble. 
And by similar token, a human can be killed by a large rock dropping on their head.
It doesn't mean a big rock is more powerful than a human.

A large asteroid, falling on Earth, would make an impressive bang.  But if we spot 
the asteroid, we can try to deflect it through any number of methods.  With enough 
lead time, a can of black paint will do as well as a nuclear weapon.  And the
asteroid itself won't oppose us on our own level - won't try to think of a 
counterplan.  It won't send out interceptors to block the nuclear weapon.  It won't 
try to paint the opposite side of itself with more black paint, to keep its current
trajectory.  And if we stop that asteroid, the asteroid belt won't send another 
planet-killer in its place.

We might have to do some work to steer the future out of the unpleasant region it 
will go to if we do nothing, but the asteroid itself isn't steering the future in
any meaningful sense.  It's as simple as water flowing downhill, and if we nudge the
asteroid off the path, it won't nudge itself back.

The tiger isn't quite like this.  If you try to run, it will follow you.  If you
dodge, it will follow you.  If you try to hide, it will spot you.  If you climb a 
tree, it will wait beneath.

But if you come back with an armored tank - or maybe just a hunk of poisoned meat -
the tiger is out of luck.  You threw something at it that wasn't in the domain it 
was designed to learn about.  The tiger can't do cross-domain optimization, so all
you need to do is give it a little cross-domain nudge and it will spin off its 
course like a painted asteroid.

Steering the future, not energy or mass, not food or bullets, is the raw currency 
of conflict and cooperation among agents.  Kasparov competed against Deep Blue to 
steer the chessboard into a region where he won - knights and bishops were only his
pawns.  And if Kasparov had been allowed to use any means to win against Deep Blue,
rather than being artificially restricted, it would have been a trivial matter to 
kick the computer off the table - a rather light optimization pressure by comparison
with Deep Blue's examining hundreds of millions of moves per second, or by comparison
with Kasparov's pattern-recognition of the board; but it would have crossed domains 
into a causal chain that Deep Blue couldn't model and couldn't optimize and couldn't
resist.  One bit of optimization pressure is enough to flip a switch that a narrower
opponent can't switch back.

A superior general can win with fewer troops, and superior technology can win with a
handful of troops.  But even a suitcase nuke requires at least a few kilograms of 
matter.  If two intelligences of the same level compete with different resources, the
battle will usually go to the wealthier.
```


(THE LEVEL ABOVE HITLER)

<a name="#The-level-above-Hitler"></a>
### The level above Hitler
([overview](#overview))

This was an intriguing and memorable piece of rhetoric by Scott responding to nostalgebraist. 

Nostalgebraist gives "social abilities" as an example of a goal that has a hard upper limit low enough to be discernible in everyday life, as a problem that EY's definition of intelligence (as [efficient cross-domain optimization](https://www.lesswrong.com/posts/yLeEPFnnB9wE7KLx2/efficient-cross-domain-optimization)) doesn't take into account:

```markdown
At various points Bostrom (like Yudkowsky) implicitly or explicitly uses a 
definition of intelligence that is something like “ability to achieve one’s goals.”
This is nicely clean, but problematic, because it doesn’t take into account the 
fact that some goals may have hard upper limits where others don’t.

In particular, this seems to apply to things having to do with social behavior.  
I can imagine beings that are qualitatively better than humans at math, information
recall, etc., since there are already orders of magnitude of variation in these
abilities among humans.  (John von Neumann is a good example of a person who seems
to have really been “superhuman” in these kinds of areas.)  However, social abilities
like “ability to manipulate others” do not seem unbounded in these ways.  There are 
some people who are good at manipulation, and many of us have developed types of
wariness, etc. to protect ourselves from these people, but it doesn’t seem like this 
is a “skill” like math ability that spans orders of magnitude.  Roughly speaking, are
no “super-manipulators” out there who can manipulate ordinarily wary people (but not 
“super-wary” people?).

For instance, one of the most effective ways to get people to do your bidding is to
start a cult: there are plenty of chilling stories about the level of devotion that 
cultists have had to their various leaders.  However, it’s not at all clear that it 
is possible to be any *better* at cult-creation than the best historical cult leaders
— to create, for instance, a sort of “super-cult” that would be attractive even to 
people who are normally very disinclined to join cults.  (Insert your preferred Less
Wrong joke here.)  I could imagine an AI becoming L. Ron Hubbard, but I’m skeptical 
that an AI could become a super-Hubbard who would convince us all to become its
devotees, even if it wanted to.  If social abilities like this are subject to hard 
upper bounds that have already been nearly achieved, then there’s no potential for AIs
to achieve their goals better by becoming superhuman at these abilities, which makes 
it problematic to just postulate an AI that’s “superhuman at achieving its goals.”
```

Scott's response is the reason I started this subsection:

```markdown
A couple of disagreements. First of all, I feel like the burden of proof should be 
heavily upon somebody who thinks that something stops at the most extreme level 
observed. Socrates might have theorized that it’s impossible for it to get colder than
about 40 F, since that’s probably as low as it ever gets outside in Athens. But when 
we found the real absolute zero, it was with careful experimentation and theoretical 
grounding that gave us a good reason to place it at that point. While I agree it’s 
*possible* that the best manipulator we know is also the hard upper limit for 
manipulation ability, I haven’t seen any evidence for that so I default to thinking 
it’s false.

(lots of fantasy and science fiction does a good job intuition-pumping what a super-
manipulator might look like; I especially recommend R. Scott Bakker’s *Prince Of Nothing*)

But more important, I disagree that L. Ron Hubbard is our upper limit for how successful
a cult leader can get. L. Ron Hubbard might be the upper limit for how successful a cult
leader can get *before we stop calling them a cult leader*.

The level above L. Ron Hubbard is Hitler. It’s difficult to overestimate how sudden and 
surprising Hitler’s rise was. Here was a working-class guy, not especially rich or smart
or attractive, rejected from art school, and he went from nothing to dictator of one of
the greatest countries in the world in about ten years. If you look into the stories, 
they’re really creepy. When Hitler joined, the party that would later become the Nazis 
had a grand total of fifty-five members, and was taken about as seriously as modern
Americans take Stormfront. There are records of conversations from Nazi leaders when 
Hitler joined the party, saying things like “Oh my God, we need to promote this new guy,
everybody he talks to starts agreeing with whatever he says, it’s the creepiest thing.”
There are stories of people who hated Hitler going to a speech or two just to see what 
all the fuss was about and ending up pledging their lives to the Nazi cause.  Even while
he was killing millions and trapping the country in a difficult two-front war, he had
what historians estimate as a 90% approval rating among his own people and rampant
speculation that he was the Messiah. Yeah, sure, there was lots of preexisting racism 
and discontent he took advantage of, but there’s been lots of racism and discontent 
everywhere forever, and there’s only been one Hitler. If he’d been a little bit smarter 
or more willing to listen to generals who were, he would have had a pretty good shot at
conquering the world. 100% with social skills.

The level above Hitler is Mohammed. I’m not saying he was evil or manipulative, just that
he was a genius’ genius at creating movements. Again, he wasn’t born rich or powerful, 
and he wasn’t particularly scholarly. He was a random merchant. He didn’t even get the 
luxury of joining a group of fifty-five people. He started by converting his own family 
to Islam, then his friends, got kicked out of his city, converted another city and then 
came back at the head of an army. By the time of his death at age 62, he had conquered 
Arabia and was its unquestioned, God-chosen leader. By what would have been his eightieth
birthday his followers were in control of the entire Middle East and good chunks of 
Africa. Fifteen hundred years later, one fifth of the world population still thinks of him
as the most perfect human being ever to exist and makes a decent stab at trying to conform
to his desires and opinions in all things.

The level above Mohammed is the one we should be worried about.
```

Additional candidates: Karl Marx, Osama bin Laden, Donald Trump (I don't know how else to explain his win).

Additional discussion below. Roccondilrinon pushes back against Scott with an argument I actually had half-baked in mind:

```markdown
I have to disagree. I think there’s a clear limit to how much you can manipulate people,
because unlike mathematical ability, the ability to manipulate is opposed by other 
people’s ability to reason and defy it. 

I think once you get above the L. Ron Hubbard level, the only examples you can come up 
with are based on sheer circumstance, or are true mass movements that aren’t manipulated
beyond ordinary levels by individuals. That is, a lot of things were the cause of Nazism; 
if nationalist interests hadn’t coalesced around Hitler and his particular brands of
bigotry, they’d have found something else. Mohammed didn’t single-handedly create Islam or
the caliphate, any more than Jesus (or Paul, for that matter) single-handedly created 
Christianity; although I’ll admit I know much less about that part of history than about 
the Nazis.

Education makes people resistant to manipulation. It’s not nearly as simple as “levels” of
manipulative ability. We know a lot more about what makes people tick; we can do
psychological studies and know with mathematical accuracy about causes and effects on the 
mind, and advertisers can and do take advantage of this knowledge. Yet we are (on the whole)
less susceptible to their manipulation than Germany in the 1930s was to Hitler’s propaganda.
Why is that? Because we know more about everything else — we are more educated, and we have
ready access to information about things we don’t know — and because knowledge of these 
techniques makes them somewhat less effective.

Does this mean we shouldn’t worry? On the contrary; we are safer precisely because we do 
worry, and there are plenty of people who don’t and who are still manipulated by demagogues,
and the above obviously applies much more in (what we anachronistically term) the first world.
But if you know anything like as much as someone like Bostrom or Yudkowsky about psychology 
and human biases and so on, you’re already inoculated against manipulation in general.
```

I'm with Rocco for the most part, but having read *The Attention Merchants* I'm less convinced of the part where we're "less susceptible to manipulation", as advertising revenues so amply falsify in the macroscale.

Veronica straszh distinguishes between "super talent" and "fertile soil":

```markdown
We need to explore two questions. The first is, to what degree was this *super talent?*
The second is, to what degree was this *fertile soil?* Obviously it was probably both, 
to some degree. But to my view, if we look closely at the rise of Hitler we see a 
singularly receptive audience. Which does not diminish his talent. But it is to say 
this, in another time or place, we would not know who he is.

Probably.

On the other hand, I know literally nothing about the shape of Arabian culture at the 
time. In fact, I’m not sure how many people do anymore. We might think Arabs do, but 
that was long ago and much has changed, particularly *because* of Islam. A few historians
might. But I bet they disagree on this stuff. How do we distinguish those who know from 
those who do not? (Their answers to these questions probably tell us more about their 
approaches to historiography and less about pre-Islamic Arabia.)

Thus, I think that, like the Hitler example, we should see this as some improbable 
combination of a super talent and highly fertile soil.

So with all that, we get to another question: where are we more likely to be effective, 
in blocking the rise of a super manipulator or in reshaping culture to be less open to 
memetic attack? Which do you think will work?
```



<a name="#Epistemic-learned-helplessness"></a>
## Epistemic learned helplessness
([overview](#overview))
	
There's really only one entry in this subsection until I stumble across more -- Scott Alexander's [eponymous essay on LiveJournal](https://web.archive.org/web/20170622074346/https://squid314.livejournal.com/350090.html), back in the days before he exploded. But one is more than enough: epistemic learned helplessness is one of the largest drivers behind this entire notebook (of which this is just a section).

Scott:

```markdown
I don't think I'm overselling myself too much to expect that I could argue circles
around the average high school dropout. Like I mean that on almost any topic, given
almost any position, I could totally demolish her and make her look like an idiot.
Reduce her to some form of "Look, everything you say fits together and I can't 
explain why you're wrong, I just know you are!" Or, more plausibly, "Shut up I don't
want to talk about this!"

And there are people who can argue circles around me. Not on any topic, maybe, but
on topics where they are experts and have spent their whole lives honing their 
arguments. When I was young I used to read pseudohistory books; Immanuel Velikovsky's
Ages in Chaos is a good example of the best this genre has to offer. I read it and 
it seemed so obviously correct, so *perfect*, that I could barely bring myself to
bother to search out rebuttals.

And then I read the rebuttals, and they were so obviously correct, so *devastating*,
that I couldn't believe I had ever been so dumb as to believe Velikovsky.

And then I read the rebuttals to the rebuttals, and they were so obviously correct
that I felt silly for ever doubting.

And so on for several more iterations, until the labyrinth of doubt seemed 
inescapable. What finally broke me out wasn't so much the lucidity of the consensus
view so much as starting to sample different crackpots. Some were almost as bright
and rhetorically gifted as Velikovsky, all presented insurmountable evidence for 
their theories, and all had mutually exclusive ideas. After all, Noah's Flood 
couldn't have been a cultural memory *both* of the fall of Atlantis *and* of a change 
in the Earth's orbit, let alone of a lost Ice Age civilization or of megatsunamis
from a meteor strike. So given that at least some of those arguments are wrong and
all seemed practically proven, I am obviously just gullible in the field of ancient
history. Given a total lack of independent intellectual steering power and no desire
to spend thirty years building an independent knowledge base of Near Eastern history,
I choose to just accept the ideas of the prestigious people with professorships in 
Archaeology rather than the universally reviled crackpots who write books about Venus
being a comet.

I guess you could consider this a form of *epistemic learned helplessness*, where I 
know any attempt to evaluate the arguments are just going to be a bad idea so I don't 
even try. If you have a good argument that the Early Bronze Age worked completely
differently from the way mainstream historians believe, *I just don't want to hear 
about it*. If you insist on telling me anyway, I will nod, say that your argument makes 
complete sense, and then totally refuse to change my mind or admit even the slightest
possibility that you might be right.

(This is the correct Bayesian action, by the way. If I know that a false argument
sounds just as convincing as a true argument, argument convincingness provides no
evidence either way, and I should ignore it and stick with my prior.)
```

ELH is a useful social safety valve most of the time:

```markdown
I consider myself lucky in that my epistemic learned helplessness is circumscribed;
there are still cases where I will trust the evidence of my own reason. In fact, I 
trust it in most cases other than very carefully constructed arguments known for 
their deceptiveness in fields I know little about. But I think the average high 
school dropout both doesn't and *shouldn't*. Anyone anywhere - politicians, scammy 
businessmen, smooth-talking romantic partners - would be able to argue her into
anything. And so she takes the obvious and correct defensive manuever - she will
never let anyone convince her of any belief that sounds "weird". ...

People used to talk about how terrorists must be very poor and uneducated to fall 
for militant Islam, and then someone did a study and found that they were 
disproportionately well-off, college educated people (many were engineers). I've 
heard a few good arguments in this direction before, things like how engineering 
trains you to have a very black-and-white right-or-wrong view of the world based 
on a few simple formulae, and this meshes with fundamentalism better than it meshes
with subtle liberal religious messages. 

But to these I would add that a sufficiently smart engineer has never been burned
by arguments above his skill level before, has never had any reason to develop 
epistemic learned helplessness. If Osama comes up to him with a really good argument
for terrorism, he thinks "Oh, there's a good argument for terrorism. I guess I 
should become a terrorist," as opposed to "Arguments? You can prove *anything* with
arguments. I'll just stay right here and not do something that will get me 
ostracized and probably killed."

Responsible doctors are at the other end of the spectrum from terrorists in this
regard. I once heard someone rail against how doctors totally ignored all the latest
and most exciting medical studies. The same person, practically in the same breath, 
then railed against how 50% to 90% of medical studies are wrong. *These two 
observations are not unrelated*. Not only are there so many terrible studies, but
pseudomedicine (not the stupid homeopathy type, but the type that links everything
to some obscure chemical on an out-of-the-way metabolic pathway) has, for me, proven
much like pseudohistory in that unless I am an expert *in that particular field of 
medicine* (biochemistry has a disproportionate share of these people and is also an
area where I'm weak) it's hard not to take them seriously, even when they're super-
wrong.
```

<a name="#Fact-posts-as-solution-to-epistemic-learned-helplessness"></a>
### Fact posts as solution to epistemic learned helplessness
([overview](#overview))

While rereading Scott's [epistemic learned helplessness essay](https://web.archive.org/web/20170622074346/https://squid314.livejournal.com/350090.html) I was thinking of how Sarah Constantin's [fact posts](https://www.lesswrong.com/posts/Sdx6A6yLByRRs8iLY/fact-posts-how-and-why) fit in. Well, whaddyaknow? The *first comment under Scott's essay* is Sarah Constantin's pushback, where she also talks about factposting for the first time(!!). She says she used to practice ELH, but then realized it wasn't all that hard to make your own judgments about ideas:

```markdown
I love this essay.

I love it because it's an articulation of a serious argument that I respect but still
end up ultimately opposed to.

I've spent a lot of time considering "What should a person do about weird claims?" The
stuff that *sounds* like the ideas of a crackpot, but potentially a crackpot so clever
that you can't see a hole in his reasoning -- and, also, potentially not a crackpot at
all but an insightful, correct thinker. I used to have roughly the same conclusion as 
you. And roughly the same problem with a tendency to believe the last thing I read, and
along with it, a fear of reading things that might delude me.

But the thing is, I've come to the conclusion that it's not actually that hard to make
your own judgments about ideas. I was confused about strong AI for a while. What did I
do? I read a bunch of papers and textbooks. I talked to my friends who were AI
researchers. I still don't *really* know what's going on because I never really learned 
mathematical logic, but it's a hell of a lot better than a black box. I know *some* 
mathematics, and I can tell the difference between a proof and a hand-wavy argument,
and I've had independent confirmation of the falseness of the ideas I was skeptical
about...I'm pretty sure, sure enough to go on with my life, that my picture of "what's 
up with AI" is more or less accurate.

I'm learning how to do this with biomedical research papers. I am not a biologist so I 
have to black-box a lot, but not *everything*. I can tell that claims with five
conjunctive hypotheses are less likely than claims with one. I can tell when a study was
done with 15 subjects or 15,000. I can certainly evaluate statistical methodology. I can
come to estimates of my true beliefs -- not high confidence, but not all that biased, 
and way better than learned helplessness.

I don't go to the trouble of doing this with everything. I haven't checked out climate
change skeptics, because I don't know fluid dynamics and I'm a little scared of the work
involved in learning. But mostly, my heuristic is, "When confronted with a weird claim
that would be really interesting if true and isn't immediately obvious as bullshit, it's
worth checking Wikipedia and reading one scholarly paper. If I'm still uncertain and
still interested, it's worth reading several more scholarly papers and asking experts I
know."

A lot of bunk is not that hard to debunk. I looked through an 1880 book of materia medica
(herbal medicine) once; most treatments were not just useless but poisonous, and it took
30 seconds of googling to find that out. (Oil of tansy will *fuck you up*, ladies and
gentlemen.) 

A good all-purpose scientist can more or less trust his/her bullshit-o-meter. You should 
know where you're least able to evaluate claims explicitly (for me, that's physics, 
chemistry, and anything to do with war or foreign policy) and use implicit meta-techniques
(were their results reproducible? do they make a lot of conjunctive claims? that sort of
thing). But often, I can just *go in and check the math.* Tim Ferriss makes arithmetic 
errors in his books. You don't have to be a fitness expert to catch them.

I'm no longer afraid of being deluded by charlatans. I wouldn't go to a Scientology 
meeting, because they engage in physical brainwashing, but I can read racists without
becoming a racist, read homeopaths without becoming a homeopath, and so on. I've banged my
brain against a *lot* of things, and come out more or less clean. 

Maybe not everyone can do this (my education certainly helped a lot), but it is *possible*,
and I think most people who are comparably educated and bright (e.g. you) can get better at
evaluating weird claims themselves and do better than they would with epistemic learned 
helplessness.
```

Seven years later, Sarah finally wrote up a continuation (which I've linked to above). 

How?

```markdown
The most useful thinking skill I've taught myself, which I think should be more widely 
practiced, is writing what I call "fact posts."

To write a fact post, you start with an empirical question, or a general topic.  
Something like "How common are hate crimes?" or "Are epidurals really dangerous?" or 
"What causes manufacturing job loss?"  

It's okay if this is a topic you know very little about. This is an exercise in original
seeing and showing your reasoning, not finding the official last word on a topic or doing
the best analysis in the world.

Then you open up a Google doc and start taking notes.

You look for *quantitative data from conventionally reliable sources*.  CDC data for
incidences of diseases and other health risks in the US; WHO data for global health 
issues; Bureau of Labor Statistics data for US employment; and so on. Published scientific
journal articles, especially from reputable journals and large randomized studies.

You explicitly do *not* look for opinion, even expert opinion. You avoid news, and you're 
wary of think-tank white papers. You're looking for raw information. You are taking a sola
scriptura approach, for better and for worse.

And then you start letting the data show you things. 

You see things that are surprising or odd, and you note that. 

You see facts that seem to be inconsistent with each other, and you look into the data
sources and methodology until you clear up the mystery.

You orient towards the random, the unfamiliar, the things that are totally unfamiliar to
your experience. One of the major exports of Germany is *valves*?  When was the last time
I even thought about valves? *Why* valves, what do you use valves in?  OK, show me a list
of all the different kinds of machine parts, by percent of total exports.  

And so, you dig in a little bit, to this part of the world that you hadn't looked at before.
You cultivate the ability to spin up a lightweight sort of fannish obsessive curiosity when
something seems like it might be a big deal.

And you take casual notes and impressions (though keeping track of all the numbers and
their sources in your notes).

You do a little bit of arithmetic to compare things to familiar reference points. How 
does this source of risk compare to the risk of smoking or going horseback riding? How 
does the effect size of this drug compare to the effect size of psychotherapy?

You don't really want to do statistics. You might take percents, means, standard
deviations, maybe a Cohen's d here and there, but nothing fancy.  You're just trying to 
figure out what's going on.

It's often a good idea to rank things by raw scale. What is responsible for the bulk of 
deaths, the bulk of money moved, etc? What is *big*?  Then pay attention more to things,
and ask more questions about things, that are *big*. (Or disproportionately high-impact.)

Once you've accumulated a bunch of facts, and they've "spoken to you" with some conclusions
or answers to your question, you write them up on a blog, so that other people can check
your reasoning.  If your mind gets changed, or you learn more, you write a follow-up post.
You should, on any topic where you continue to learn over time, feel embarrassed by the 
naivety of your early posts.  This is fine. This is how learning works.
```

Why?

```markdown
This is an exercise in original seeing and showing your reasoning, not finding the official 
last word on a topic or doing the best analysis in the world.

You may find that this process gives you contrarian beliefs, but often you won't, you'll 
just have a strongly fact-based assessment of why you believe the usual thing.  

There's a quality of ordinariness about fact-based beliefs. It's not that they're never 
surprising -- they often are. But if you do fact-checking frequently enough, you begin to
have a sense of the world overall that stays in place, even as you discover new facts, 
instead of swinging wildly around at every new stimulus.  For example, after doing lots and
lots of reading of the biomedical literature, I have sort of a "sense of the world" of
biomedical science -- what sorts of things I expect to see, and what sorts of things I 
don't. My "sense of the world" isn't that the world itself is boring -- I actually believe 
in a world rich in discoveries and low-hanging fruit -- but the sense itself has stabilized,
feels like "yeah, that's how things are" rather than "omg what is even going on."

In areas where I'm less familiar, I feel more like "omg what is even going on", which 
sometimes motivates me to go accumulate facts.

The advantage of fact posts is that they give you the ability to form independent opinions 
based on evidence. It's a sort of practice of the skill of seeing. They likely aren't the
optimal way to get the most accurate beliefs -- listening to the best experts would almost
certainly be better -- but you, personally, may not know who the best experts are, or may
be overwhelmed by the swirl of controversy. Fact posts give you a relatively low-effort way
of coming to informed opinions. They make you into the proverbial 'educated layman.'

Being an 'educated layman' makes you much more fertile in generating ideas, for research, 
business, fiction, or anything else. Having facts floating around in your head means you'll 
naturally think of problems to solve, questions to ask, opportunities to fix things in the 
world, applications for your technical skills.
```

Scott Alexander, who's probably forgotten by now the link I dug up above, adds:

```markdown
Don't underestimate Wikipedia as a really good place to get a (usually) unbiased overview of
things and links to more in-depth sources.

The warning against biased sources is well-taken, but if you're looking into something
controversial, you might have to just read the biased sources on both sides, then try to 
reconcile them. I've found it helpful to find a seemingly compelling argument, google something 
like "why X is wrong" or "X debunked" into Google, and see what the other side has to say about 
it. Then repeat until you feel like both sides are talking past each other or disagreeing on 
minutiae. This is important to do even with published papers!

Success often feels like realizing that a topic you thought would have one clear answer actually
has a million different answers depending on how you ask the question. You start with something
like "did the economy do better or worse this year?", you find that it's actually a thousand 
different questions like "did unemployment get better or worse this year?" vs. "did the stock
market get better or worse this year?" and end up with things even more complicated like "did
employment as measured in percentage of job-seekers finding a job within six months get better"
vs. "did employment as measured in total percent of workforce working get better?". Then finally
once you've disentangled all that and realized that the people saying "employment is getting 
better" or "employment is getting worse" are using statistics about subtly different things and 
talking past each other, you use all of the specific things you've discovered to reconstruct a 
picture of whether, in the ways important to you, the economy really is getting better or worse.
```

------------------

<a name="#Psychological-gulfs"></a>
## Psychological gulfs
([overview](#overview))

Spencer Greenberg has a [list of psychological gulfs](https://www.facebook.com/spencer.greenberg/posts/10103598358776962), common differences between people that are so large that those at the opposite extreme ends of the trait (say, the 5th percentile vs. 95th percentile) have a very hard time understanding and relating to each other -- note that each of these examples is supposed to illustrate a somewhat extreme form of each trait for clarity purposes; most people who have or lack each trait don’t have a form that is as extreme as is shown in these examples.

Extraversion vs. Introversion:

```markdown
“Are you coming out? It’s going to be a HUGE night! First we’re meeting up with 
Bill, Harry and Jennifer for drinks. Then stopping by the party to see the whole
crew, and after, if we’re feeling it, we’ll hit up Sing Song karaoke. Then we’re
hitting the clubs for the rest of the night!”

“Thanks…I appreciate the invite. I’m just going to stay in tonight though. I’ve 
really been loving this book I’m reading. All week I’ve been looking forward to 
having the time to finish it.”
```

Conscientiousness vs. Easy goingness:

```markdown
“I can’t believe how much material this exam is going to cover! I still need to 
make an outline of all the material, and flashcards. Last time I color coded my 
outline which worked really well, though it took a long time to make. I might 
borrow outlines from a couple other people to see how they organize the material. 
I’m going to be up until 2am tonight at least.”

“Me too…but more like 4am. I have a date with World of Warcraft. You do realize
this test only counts for 5% of our grade, right? I might just skip the exam
actually.”
```

Social awareness vs. Social unawareness:

```markdown
“Let’s go talk to Sally over there, she clearly wants to get out of that 
conversation with Bill. Plus, I should introduce her to Ethan.”

“Wait, who’s Sally again…is she one of the new engineers? How do you know she 
doesn’t like Bill, did she tell you that? And is Ethan even here tonight??? Why 
do you want to introduce them to each other anyway?”
```

Emotionality vs. Stability:

```markdown
“Sometimes life is so intense that I almost can’t take it. I’ll just burst out 
in tears in the middle of the day and have to hide in the bathroom at work. I 
wouldn’t have it any other way though, it’s what makes life so meaningful.”

“Crying at work you mean? I’ve done that too actually. I was at work when I found
out my sister had died. It was really tough. Actually though, now that I think 
about it, I finished out my shift since I only had 5 minutes of it left anyway.
And I don’t think I cried until later that night when I was at home alone.”
```

Aesthetic sensitivity vs. Aesthetic indifference:

```markdown
“Did you see the colors he painted his walls??? They made my skin crawl.”

“Wait, what color were they? And how is it even possible for colors to make your
skin crawl???”
```

Empathy vs. Unsympatheticness:

```markdown
“Please, please don’t use glue traps. Once the mouse is stuck it will slowly starve
to death. What if I help you trap it and then we can find a good place to release 
it outside?”

“Are you kidding me? We’re talking about a mouse! If the stupid thing weren’t so 
damn fast I’d just stamp right on its head with my boots, that would take so much
less time.”
```

Anxiety vs. Calmness:

```markdown
“I’ve been worried all day because I’ve been waiting for the doctor to call me
with my test results. I mean, I know I probably will test negative, but what if
I don’t? I wouldn’t be able to stay in school anymore, and I’m not sure I could
afford the medical bills. Even if there is a 1% that I test positive, the
consequences would just be so serious that it’s still a big deal. And my chances
might even be worse than 1%! I really don’t need this right now, I was already
really worried about the presentation I have to give to the CEO at the end of the
month. What is life going to throw at me next?”

“Honestly, you just need to relax. What’s the point of worrying about all this?
Worrying doesn’t change anything and you’re just stressing yourself out. Like 
you said, you're really unlikely to test positive. Everything is going to be
totally fine in the end."
```

Openness vs. Closedness:

```markdown
“That was the coolest lecture ever, I’m so inspired right now. I can only BEGIN 
to imagine what it’s like to be Prism, as a visually impaired Chinese Italian non
gender binary person who has spent fifteen years fighting for the medical 
establishment to finally recognize the alternative medical treatments that cured
his own cancer! Prism has so many interesting ideas about relationships and child
rearing too. I’m also really excited now to buy a few books on the diversity of 
social practices among First Nations people.”

“Seriously, you enjoyed that??? That was literally the weirdest thing I’ve ever 
experienced. I wanted to puke when he made us all put our arms around each other 
in a circle and try to open our ‘inner eye’. What does that even mean??? Not to
mention that half the people there were out of it on drugs of some kind. And why
on earth was that woman practically naked?”
```

Authoritarianism vs. Libertarianism:

```markdown
“If your father wants you to move in with him and your mom, then that’s your duty 
as their child. Maybe your pastor can give you advice for how to make it a smooth 
transition.”

“It was my parents choice to have me. Just because they made that choice doesn’t 
mean they have control over my life. Are you serious that if you were me you would
talk to a pastor for advice? Sure, I’m spiritual. But I don’t belong to a church 
or follow one particular set of teachings, I prefer to figure out myself what 
religion and spirituality mean.”
```

Jess Riedel suggests "individualism vs collectivism" might be a better way to carve *individual* psychology at the joints:

```markdown
There seems to a huge difference between folks who see the world in terms of 
interacting individual humans vs. interacting groups of humans (or memes/concepts
that propagate within groups), where the groups are said to be effectively
irreducible for the purpose of useful analysis.
```

Optimism vs. Pessimism:

```markdown
“I can’t wait until vacation! We’re going to have such an incredible time together. 
And it’s going to be such a well deserved break after all this hard work. Plus, 
they’re going to announce bonuses right before we leave. Business has been great,
I bet they’ll be the biggest bonuses yet. When we’re lying on the beach we can 
discuss the fun things we’re going to buy with all that money!”

“Vacation will be pretty fun I guess. But I’ve been thinking…the beaches get so
crowded during the vacation season, maybe it would make more sense to just stay 
home this year. It’s pretty pointless just lying on the beach all day anyway. I 
know you’re excited about bonuses, but I don’t want you to get your hopes up. 
Business looked good this year, but our industry is about to get squeezed with 
all the new technology coming to market. I wouldn’t be surprised if they don’t 
even give us bonuses. After all, we work at a company that tries to convince 
consumers to buy meaningless shit they don’t need, so why would the company care
about making its employees happy?”
```

Sexuality vs. Asexuality:

```markdown
“This club is amazing…it has the hottest people I’ve ever seen! I would literally
sleep with anyone here. It’s hard to even focus on this conversation!”

“Oh…hmm, I guess you’re right, there are a lot of good looking people here. All
the skin tight clothing and showing off of skin seems a bit gratuitous though, 
don’t you think?”
```

Analyticalness vs. Intuitiveness:

```markdown
“I’ve been thinking about social interaction a lot lately, and currently my best
framework for how to start a conversation with a stranger is to make a comment 
about something in the surrounding context that you know the other person is 
already aware of. For instance, about the weather, but only if the weather is well
above or below average for that season. Then, once the other person responds to
your comment, you should ask them a question related to their response to get them
talking further. If the person gives a really short response to your question then
it probably means…”

“Can I stop you right there? Honestly, if you’re analyzing how to have social 
interaction you’re already doing it wrong. Just get a feel for what the other person
is like. Then just say whatever feels most natural to say. Don’t overthink everything!”
```

Self admiration vs. Self doubt:

```markdown
“There are very few incredible people in the world. What are the chances that two truly
unique and awesome people would find each other? It’s one in a million. You’re
unbelievably special, and it couldn’t be more obvious that we’re meant to be together. 
I think that as a team we could achieve just about anything.”

“You keep calling me special, but honestly, I’m embarrassed to admit it, but there’s
nothing special about me. Nearly everything I’ve achieved was just a result of good 
luck, or having unfair opportunities that other people don’t get, and I’m probably one
of the least talented people to achieve what I’ve achieved. Eventually people will
figure that out about me and it will all come crashing down. And when I get good 
opportunities I usually just mess them up or undermine myself. If there’s anything 
special about me, it’s that there’s something wrong with me. I screw things up. 
Fundamentally, not only am I ordinary, but I’m not even an especially good person, and
I don’t deserve much of anything.”
```

Jess Riedel adds "the degree to which the person thinks in terms of normative vs. positive statements":

```markdown
I have been surprised at how difficult it is for me to communicate with folks 
who, by my lights, are unable to discuss a topic without framing it in terms of
value judgements.
```

<a name="#Ask-vs-guess-vs-tell-culture"></a>
## Ask vs guess vs tell culture
([overview](#overview))

Some psychological gulfs have been discussed much more than others. One of them is ask vs guess vs tell, which I first encountered in these two posts written 4 years apart: [Ask and guess culture](https://www.lesswrong.com/posts/vs3kzjLhbdKsndnBy/ask-and-guess) and [tell culture](https://www.lesswrong.com/posts/rEBXN3x6kXgD4pLxs/tell-culture). The first originates with [tangerine's Metafilter post](https://ask.metafilter.com/55153/Whats-the-middle-ground-between-FU-and-Welcome), the second comes from Brienne Yudkowsky.

Basic rules of ask culture:

```markdown
1) Ask when you want something. 
2) Interpret things as requests and feel free to say "no".
```

Example:

```markdown
"I'll be in town this weekend for a business trip. Is it cool if I crash at your 
place?" 

Response: “Yes“ or “no”.
```

Basic rules of guess culture:

```markdown
1) Ask for things if, and *only* if, you're confident the person will say "yes". 
2) Interpret requests as expectations of "yes", and, when possible, avoid saying "no". 
```

Example: 

```markdown
"Hey, great news! I'll be in town this weekend for a business trip!"

Response: Infer that they might be telling you this because they want something from
you, conclude that they might want a place to stay, and offer your hospitality only 
if you want to. Otherwise, pretend you didn’t infer that.
```

Basic rules of tell culture:

```markdown
1) Tell the other person what's going on in your own mind whenever you suspect you'd
both benefit from them knowing. (Do NOT assume others will accurately model your mind 
without your help, or that it will even occur to them to ask you questions to
eliminate their ignorance.) 

2) Interpret things people tell you as attempts to create common knowledge for shared
benefit, rather than as requests or as presumptions of compliance.
```

Example:

```markdown
"I'll be in town this weekend for a business trip. I would like to stay at your place,
since it would save me the cost of a hotel, plus I would enjoy seeing you and expect
we’d have some fun. I'm looking for other options, though, and would rather stay 
elsewhere than inconvenience you." 

Response: “I think I need some space this weekend. But I’d love to get a beer or 
something while you’re in town!” or “You should totally stay with me. I’m looking 
forward to it.”
```

What's the difference between ask and tell again?

```markdown
The burden of honesty is even greater in Tell culture than in Ask culture. To a Guess
culture person, I imagine much of the above sounds passive aggressive or manipulative, 
much worse than the rude bluntness of mere Ask. It’s because Guess people aren’t 
expecting relentless truth-telling. 

Tell culture is cooperation with open source codes.
```

Tangerine's now-classic Metafilter post introducing the ask vs guess culture distinction:

```markdown
In some families, you grow up with the expectation that it's OK to ask for anything
at all, but you gotta realize you might get no for an answer. This is Ask Culture.

In Guess Culture, you avoid putting a request into words unless you're pretty sure 
the answer will be yes. Guess Culture depends on a tight net of shared expectations.
A key skill is putting out delicate feelers. If you do this with enough subtlety,
you won't even have to make the request directly; you'll get an offer. Even then, 
the offer may be genuine or pro forma; it takes yet more skill and delicacy to
discern whether you should accept.

All kinds of problems spring up around the edges. If you're a Guess Culture person -- 
and you obviously are -- then unwelcome requests from Ask Culture people seem 
presumptuous and out of line, and you're likely to feel angry, uncomfortable, and
manipulated.

If you're an Ask Culture person, Guess Culture behavior can seem incomprehensible,
inconsistent, and rife with passive aggression. ...

Thing is, Guess behaviors only work among a subset of other Guess people -- ones who
share a fairly specific set of expectations and signalling techniques. The farther 
you get from your own family and friends and subculture, the more you'll have to
embrace Ask behavior. Otherwise you'll spend your life in a cloud of mild outrage at 
(pace Moomin fans) the Cluelessness of Everyone.
```

The ask vs guess divide isn't as clear as you think:

```markdown
Some *individual people* are more comfortable asking than guessing, and vice versa.

Some families, and some cultures, are more "ask-based" than "guess-based."  
(Apparently East Asia is more "guess-based" than the US.)

It also varies from situation to situation: "Will you marry me?" is a question you
should only ask if you know the answer is yes, but "Would you like to get coffee 
with me?" is the kind of question you should ask freely and not worry too much about
rejection. 
```

Nancy Lebovitz contends that it should be called 'Infer' culture instead:

```markdown
It's how Infer cultures look to people who don't know the rules.
```

TheOtherDave:

```markdown
Guess cultures mostly don't involve guesswork. They involve inferring likely
conditions based on evidence that isn't explicitly articulated.

More precisely: Culture A is an Ask culture relative to Culture B with respect to a 
subject if A explicitly articulates things about that subject that B doesn't 
articulate.

So I think your question is isomorphic to "Why would anyone prefer not to explicitly
articulate all their evidence?"... that is, "Why are some things rude to talk about?"
```

Some advice for experimenting with asking as a guesser:

```markdown
- failure/rejection is so common as to not be shameful (i.e. dating)

- it's someone's job to handle requests, and requests are common (e.g. applying for 
jobs or awards, academic administration)

- granting or refusing a request is ridiculously easy (most internet communication)
```

A bit more nuance on ask vs guess by commenter TheOtherDave:

```markdown
Ask and Guess are sometimes misleading labels for the styles they refer to (though
they are conventional).

For example, "Ask" culture is often OK with "So, I'm assuming here that A, B, and C 
are true; based on that yadda yadda" with the *implicit expectation* is that someone 
will correct me if I'm wrong. In "Guess" culture this sort of thing carries the equally
*implicit expectation* that nobody will correct me. Here both groups are guessing, but
they guess differently.

"Guess" culture also has an implicit expectation in some cases that you do ask, but that
an honest answer is not actually permitted... the answer is constrained by the social 
rules. For example, growing up if a guest says "Well, we should get going." the host is
obligated to reply "Oh, but we're having such a good time!" and none of that actually
lets you know whether the guest is still welcome or not (or, indeed, whether the guest 
has any desire to stay or go).
```

In *The Screwtape Letters*, C.S. Lewis comes down hard on guess culture by introducing what he calls the Generous Conflict Illusion:

```markdown
Later on you can venture on what may be called the Generous Conflict Illusion. This game 
is best played with more than two players, in a family with grown-up children for example.

Something quite trivial, like having tea in the garden, is proposed. One member takes care
to make it quite clear (though not in so many words) that he would rather not but is, of 
course, prepared to do so out of "Unselfishness". The others instantly withdraw their 
proposal, ostensibly through their "Unselfishness", but really because they don't want to
be used as a sort of lay figure on which the first speaker practices petty altruisms. 

But he is not going to be done out of his debauch of Unselfishness either. He insists on 
doing "what the others want". They insist on doing what he wants. Passions are roused. Soon 
someone is saying "Very well then, I won't have any tea at all!", and a real quarrel ensues 
with bitter resentment on both sides. 

You see how it is done? If each side had been frankly contending for its own real wish, they
would all have kept within the bounds of reason and courtesy; but just because the contention
is reversed and each side is fighting the other side's battle, all the bitterness which really 
flows from thwarted self-righteousness and obstinacy and the accumulated grudges of the last 
ten years is concealed from them by the nominal or official "Unselfishness" of what they are 
doing or, at least, held to be excused by it.
```

Isn't ask culture just *better* all around? Scott Alexander responds with a parable:

```markdown
Consider an "ask culture" where employees consider themselves totally allowed to say "no"
without repercussions. 

The boss would prefer people work unpaid overtime so ey gets more work done without having 
to pay anything, so ey asks everyone. Most people say no, because they hate unpaid overtime. 
The only people who agree will be those who really love the company or their job - they end up
looking really good. 

More and more workers realize the value of lying and agreeing to work unpaid overtime so the 
boss thinks they really love the company. Eventually, the few workers who continue refusing 
look really bad, like they're the only ones who aren't team players, and they grudgingly accept.

Only now the boss notices that the employees hate their jobs and hate the boss. The boss decides
to only ask employees if they will work unpaid overtime when it's absolutely necessary. The ask 
culture has become a guess culture.
```

Another reason is signaling people understanding:

```markdown
Guesser culture affords much more signaling of how well you understand people. People who
correctly guess will come off as more intelligent, observant and understanding. It's like
the difference between offering money and offering carefully chosen presents; money may be
more efficient, but efficiency isn't the only factor coming into account.

Interestingly, Chinese culture seems much more guess-based than American culture, but in 
China gifts are usually in cash, not in presents. Maybe societies all need a way to signal
understanding and social suaveness, but choose different mechanisms.
```

Another reason is that there are things it's impolite to express in any words because the *sentiment* is impolite. Relsqui:

```markdown
There are some things which it's impolite to say, in any words, because the sentiment is
impolite--for example, "I don't want you to come to my party." Guess culture, applied 
well, allows you to avoid having to say those things or cause the attendant hurt feelings.
(Guess culture applied poorly avoids the hurt feelings but puts you in the awkward
position where they're at the party anyway because you felt compelled to invite them.) The
same situation in ask culture requires you come out with it.

This may sound like a good thing in the long run--especially if you are yourself asky--but
sometimes there are valid reasons both that you don't want someone at the party (they smell
bad) and that you don't want to hurt their feelings (they're your boss/family member/other
person you'll be spending more time around, especially in a position of authority).
```

Another reason is keeping secrets:

```markdown
In ask culture, if someone asks you something you've promised not to tell, it's certainly
valid to say "Sorry, I can't tell you." But then they know there's a secret, and sometimes
that alone is enough to cause harm--through speculation and deduction, or asking someone 
else, for example. (You could also lie, but that might cause its own problems.) In guess 
culture, there are things you don't ask about. This is part of why.
```

In fact, guess culture seems to be a Nash equilibrium for most human collectives:

```markdown
Ya know, after thousands of years of trying it out in all kinds of environments, it seems 
as though almost every culture on Earth settles on "Guess", with maybe a touch of "Ask" in
the more overbearing ones. A common modification to "Guess" is "Offer", where the mere 
mention of a possible opportunity to help out is treated as creating almost a positive
obligation to notice the need and make a spontaneous offer.

From where I sit, that's pretty strong evidence that "Guess" or maybe "Offer" is more suited 
to collective human nature. There's a pretty heavy burden of proof on any "rationalist" who
wants to change it.

It's also not so obvious that you can effectively change conventions like these by just
starting in and asking others to change. If you tried your "developing trust" tactic with me,
I'd probably play along to avoid conflict on one occasion, and avoid YOU after that. ...

It's evidence that Guess is the Nash equilibrium that human cultures find. Consider that the
Nash equilibrium in the Prisoner's Dilemma (and in the Iterated Prisoner's Dilemma with known 
fixed length) is both defect. It's a common theme in game theory that the Nash equilibrium is
not always the best place to be.
```

Okay, when should you go for tell culture? Example from Brienne:

```markdown
Suppose you’re in a conversation that you’re finding aversive, and you can’t figure out why.
Your goal is to procure a rain check.

- Guess: *You see this annoyed body language? Huh? Look at it! If you don’t stop talking soon
I swear I’ll start tapping my foot.* (Or, possibly, tell a little lie to excuse yourself. 
“Oh, look at the time…”) 

- Ask: “Can we talk about this another time?”

- Tell: "I'm beginning to find this conversation aversive, and I'm not sure why. I propose
we hold off until I've figured that out."
```

Julia Galef pushes back, saying this "can become an excuse to abdicate responsibility for your effect on other people":

```markdown
There are plenty of times when I agree a policy of frankness can be useful, but one of the 
risks of such a policy is that it can become an excuse to abdicate responsibility for your 
effect on other people.

If you tell me that you're having an aversive reaction to our conversation, but can't tell 
me why, it's going to stress me out, and I'm going to feel compelled to go back over our 
conversation to see if I can figure out what I did to cause that reaction in you. That's a 
non-negligible burden to dump on someone.

If, instead, you found an excuse to leave the conversation gracefully (no need for annoyed
body language), you can reflect on the conversation later and decide if there is anything 
in particular I did to cause your aversive reaction. Maybe so, and you want to bring it up
with me later. Or maybe you decide you overreacted to a comment I made, which you now believe
you misinterpreted. Or maybe you decide you were just anxious about something unrelated. 
Overall, chances are good that you can save me a lot of stress and self-consciousness by 
dealing with your emotions yourself as a first pass, and making them my problem only if 
(upon reflection) you decide that it would be helpful to do so.
```



```markdown

```



```markdown

```



```markdown

```



```markdown

```



```markdown

```



```markdown

```


