*[Word count](https://wordcounter.net/): 37,600*

## What is this?

This is the "philosophy, erisology, altruism and spirituality" section of [this notebook](https://monastri.github.io/). 

<a name="#overview"></a>

## Overview

I've sorted the quotes below into the following categories. This is a provisional taxonomy, subject to perpetual refactoring. The reason it has a [Borgesian flavor](https://github.com/monastri/monastri.github.io/blob/master/poetry.md#the-celestial-emporium-of-benevolent-knowledge) is that it's meant to aid recall and idea-building. The categories are ordered alphabetically; the actual quotes (the top-level categories that is) are chronologically added.

1. [Anglerfish and beacons, or why some blogs have higher comment quality](#Anglerfish-and-beacons), on geek subculture dilution by Chapman-sociopaths
1. [Argumentative charity](#argumentative-charity)
5. [Anthropic principle](#anthropic-principle)
	1. [Critiques](#critiques-of-the-anthropic-principle), ft. Cosma, Smolin
2. [Chesterton's fence](#chestertons-fence)
2. [Diseased philosophy](#diseased-philosophy)
2. [Effective altruism](#effective-altruism)
	1. [Weird EA](#weird-EA)
2. [Erisology and thinking less wrongly](#Erisology)	
1. [Expert judgment accuracy](#expert-judgment)
2. [Figuring out Buddhism](#Figuring-out-Buddhism)	
	1. [An analogy for awakening](#Awakening-an-analogy)
	2. [Buddhism is impenetrable because it hasn't been translated](#Buddhism-is-impenetrable-because-it-hasnt-been-translated)
2. [Generalizing from one example, or the typical mind fallacy](#typical-mind-fallacy)
2. [General philosophy](#general-philosophy)
4. [Greenness disintegrates, or, the necessary strangeness of scientific explanations](#The-necessary-strangeness-of-scientific-explanations)
2. [Legibility](#Legibility)
4. [Moloch](#moloch)
2. [Morality, axiology, law](#morality-axiology-law)
5. [Ra](#Ra)
3. [Reading the masters in philosophy](#reading-the-masters-in-philosophy), ft. Aristotle as pro skater
3. [Reality has a surprising amount of detail](#Reality-has-a-surprising-amount-of-detail), ft. the fabled *"Electron Band Structure In Germanium, My Ass"*
2. [Signaling](#signaling)
	1. [X isn't about Y](#x-isnt-about-y)
	2. [Countersignaling](#countersignaling), including metacontrarianism
3. [Slack and deliberate mediocrity](#slack-and-deliberate-mediocrity)
3. [Social rules as game rules](#Social-rules-as-game-rules)
3. [The absurdity heuristic doesn't work very well](#absurdity-heuristic)
3. [The cowpox of doubt](#The-cowpox-of-doubt)

-----------------------------

<a name="#Figuring-out-Buddhism"></a>
## Figuring out Buddhism
([overview](#overview))

<a name="#Buddhism-is-impenetrable-because-it-hasnt-been-translated"></a>
### Buddhism is impenetrable because it hasn't been translated
([overview](#overview))

From Romeo Stevens via Kaj Sotala in [this FB post](https://www.facebook.com/romeostevens/posts/10215386227941544):

```markdown
The issue, as it seems to me, is that almost every text you read on Buddhism does
not attempt to do the actual work of translation. The first transmission of 
Buddhism to the west reified a bunch of translations of terms, such as
concentration, equanimity, tranquility, mindfulness, suffering, etc. and works 
since then have mostly stuck to rearranging these words in different combinations
and referencing the same metaphors that have been in use since the time of the 
Buddha. If these authors had true discernment they would realize that the
umpteenth text on 'establishing the noble bases of tranquility secluded from 
sensuous ignorance' or what-have-you aren't helping anyone who didn't already get 
the message.

At this point I want to say that I think this approach is 'working' for the 
fraction of the population it is going to work for. If we want to make the
practical fruits of Buddhist practice dramatically more accessible to a broader
range of humanity we need people to do the hard work of translation to put the
Buddha's teachings in forms that will be accessible to various groups of people.

The hard work of translation is to attempt to use language to point your mind at 
the same distinctions that the original author was trying to point to. Attempts to
do this will inevitably fail in lots of ways, but can hopefully communicate enough 
of the core message that people can piece together the essential causal relations
after which, having had direct experience as a result of skillful practice, they can
help to improve the translations further.

So, putting my money where my mouth is, I want to try to produce a translation of 
what I see as the core causal loop that causes progress on the Buddha's path. I'm 
attempting this because I believe the core causal loop is actually quite small. The
Buddha had a tougher task because he had to explain causation, locus of control, and
other critical concepts to farmers from scratch.

To begin with, you may think that the purpose of meditation is to eliminate thoughts.
But read the Pali Canon and you find a text rife with concepts, schemas, diagnostic
methods for various classifications of mental activity, meditation taxonomies, 
sensory taxonomies, feedback loops etc. Pretending you're already enlightened and 
that there isn't hard work to do is something the new agers have borrowed from some
shitty spiritual schools of various flavors. I refer to people preaching such 
messages as mindlessness teachers.

To be clear, a decrease in discursive thought, and especially unpleasant mental 
contents that don't seem to serve any purpose, are one of many pleasant effects of
proper practice, but don't really need to be focused on. It is a benefit that arrives
in stages on its own.
```

Romeo claims that Buddhism's core loop is CBT supercharged with a mental state "more intense than most pharmaceuticals":

```markdown
So, what is the core loop?

It's basically cognitive behavioral therapy, supercharged with a mental state
more intense than most pharmaceuticals.

There are two categories of practice, one for cultivating the useful mental state,
the other uses that mental state to investigate the causal linkages between 
various parts of your perception (physical sensations, emotional tones, and mental
reactions) which leads to clearing out of old linkages that weren't constructed 
well.

You have physical sensations in the course of life. Your nervous system reacts to
these sensations with high or low valence (positive, negative, neutral) and arousal
(sympathetic and parasympathetic nervous system activation), your mind reacts to
these now-emotion-laden sensations with activity (mental image, mental talk) out of
which you then build stories to make sense of your situation.

The key insight that drives everything is the knowledge (and later, direct 
experience) that this system isn't wired up efficiently. Importantly: I don't mean
this in a normative way. Like you should wire it the way I say just because, but in
the 'this type of circuit only needs 20 nand gates, why are there 60 and why is it
shunting excess voltage into the anger circuits over there that have nothing to do
with this computation?' way. Regardless of possible arguments over an ultimately 
'correct' way to wire everything, there are very low hanging fruit in terms of 
improvements that will help you effectively pursue *any* other goal you set your
mind to.

Funny aside, emotional 'resistance' might be well named, it might be literal 
electrical resistance in the CNSs wiring as a result of this spaghetti logic.

So back to these stories and story building blocks that are the outputs of this 
system. You generated a bunch of the primitive building blocks when you were very 
young and throwing everything together on an as needed basis with no instructions.
You both have a back log of such stories and story building-blocks and are
generating new ones all the time. Practice improves each of these situations. It 
improves the backlog by going through and reprocessing stories that aren't actually
reality aligned when examined. Again, not pointing to edge cases here but things in
the 'your partner humming the spongebob theme shouldn't make you furious because of
something that happened when you were 12' class. You can clean up all the obvious 
stuff and then let your future self (who now has more resources) think about how to
wisely deal with the fuzzy edge cases. It improves the new stories coming in 
(partially by learning as it processes the back log) by building far fewer incoherent
stories out of pieces that don't fit together, and building less of the shittier
building blocks in the first place.
```

Now for some names, because [names matter](https://github.com/monastri/monastri.github.io/blob/master/notes-memory-brain-extended-cognition.md#names-matter):

```markdown
I'll go ahead and name these things now to connect them up for people who have some
knowledge of existing translations.

Concentration meditation gives rise to a mental state where the mind is very calm and
inclined to neutrality. Of the same sort you'd want in a good judge.

Insight meditation makes one aware of the causal links in the perceptual system between
physical sensations, feelings, and mental reactions.

Sankharas are the stories and story pieces that get reexamined and refactored as a result.
```

The core loop of meditation practice:

```markdown
Concentration puts you in the ideal state for insight.

Insight stirs up Sankaras.

Examining Sankharas riles up the mind, eventually leading to a desire to do some more 
concentration in order to calm down and keep making progress.

Clearing Sankharas cause concentration to go much better. And onward.
```

Why concentration puts you in the ideal state for insight:

```markdown
Insight requires a high degree of temporal and spatial resolution in order to see the 
finer linkages between mental activities that normally flow past you without you
noticing. Concentration meditation improves that resolution.

Second, to examine the Sankharas is to, to some extent, reactivate the sensations, 
feelings, and mental reactions associated with them. Since the ones we are most 
concerned with are the ones that are causing the biggest negative reactions in our 
lives, we need the mind to be calm and tranquil in order to do this work. 
Concentration greatly improves this tranquility as well.
```

How insight stirs up Sankaras -- mindfulness as a way to "clear out the backlog of stories":

```markdown
This would require more speculation about somatic theories that don't yet have a 
good evidence base. Subjectively, it feels like building up insights into 
particular kinds of linkages between physical sensations, feelings, and mental
reactions causes areas of your backlog that are particularly heavy in those 
linkages to get some activation and thus be available to consciousness.

You've experienced this if you've ever had a conceptual insight and then spent the
next week noticing ways it was applicable, seemingly spontaneously. The only 
difference here is that insight can also be non-conceptual (ie, insight into how 
two particular physical sensations interact might generate no verbal content/mental
talk but some sense of something happening.)

So, the Buddha taught a method of concentration, a system for developing insight
that we know as mindfulness, and to use these to both stop building new stories and 
to clear out our backlog of stories. That's actually it. The rest is details for
how this plays out in practice. Failure modes can get a bit weird, and even if you
do it right some mind blowing states and experiences can pop up. So there's lots of
whataboutism for all that.

The miswired central nervous system story gives us simple answers to things like 
trauma (extreme levels of miswiring of things into fear and freeze responses), why
stuff like yoga and exercise help (general CNS health, probably capacitance/fuse
breaker improvements), why psychotherapy sometimes but not always activates 
childhood memories and the significance of that, and why practitioners claim they 
have a much better life but can't always explain why (they perform the same actions
but with much less internal resistance).
```

So why all the extraneous stuff?

```markdown
Well, besides my post on why practitioners make so many metaphysical claims, it's 
also just that there's a lot of idiosyncrasy in first unwiring a randomly wired CNS
and then rewiring it in arbitrary order. Especially when you don't really know that
that's what you're doing as you're doing it and your mindlessness teacher is a bit 
clueless as well (though may still have good pragmatic advice despite bad epistemics.)

In addition, note I said that each of the practices is actually a practice category.
Though the Buddha taught one specific concentration technique and a simple series of
insight techniques, but there are probably a dozen alternatives in each category that
seem to work for some people and which entire traditions have subsequently built 
themselves around and gotten into fights with rival schools about.
```

The last part sounds like this quote by Bruce Lee:

```markdown
It is conceivable that a long time ago a certain martial artist discovered some partial
truth.

During his lifetime, the man resisted the temptation to organize this partial truth, 
although this is a common tendency in a man’s search for security and certainty in life.

After his death, his students took “his” hypothesis, “his” postulates and “his” method
and turned them into law. Impressive creeds were then invented, solemn reinforcing 
ceremonies prescribed, rigid philosophy and patterns formulated, and so on, until finally
an institution was erected. So what originated as one man’s intuition of some sort of
personal fluidity was transformed into solidified, fixed knowledge, complete with 
organized classified responses presented in a logical order.

In so doing, the well-meaning, loyal followers not only made this knowledge a holy shrine 
but also a tomb in which they buried the founder’s wisdom.
```

<a name="#Awakening-an-analogy"></a>
### Awakening: an analogy
([overview](#overview))

From Romeo Stevens via Kaj Sotala in [this FB post](https://www.facebook.com/romeostevens/posts/10215356324193969):

```markdown
If you want to know why it is called awakening, remember a time that you woke up
in a dream. There was a shift in the quality of perception right before and right 
after the realization. Imagine that happening in waking life. 

A taste of this can be given in the quality of the following experience: become aware
that you are observing glowing glyphs on a screen. Now notice the body posture of the
whole organism reading the screen. The various muscular tensions, the feeling of the 
tongue and eyelids blinking, the rise and fall of respiration. There is a small shift 
in perception.

Take the directionality of the difference between now and a few moments ago when you
were unconscious of these things, and extend that vector out past your current horizon
of experience. That is why.
```

<a name="#Social-rules-as-game-rules"></a>
## Social rules as game rules
([overview](#overview))

William T. Powers:

```markdown
One thing I have advocated, without much success, is that children be taught social rules (when they are 
ready) in exactly the same way they are taught and teach each other games. The point is not whether the 
rules are right or wrong. Are the rules of 5-card stud poker or hopscotch right or wrong? It's that we're 
playing a certain game here, and there are rules to this game just as in any other game. If you want to 
be in the game, then you have to learn how to play it. Different groups of people play different games 
(different rules = different game), so if you want to play in different groups, you have to learn the 
games they play. When you develop the levels of understanding above the rule level, you'll be able to 
understand all games, and be able to join in anywhere. You won't be stuck knowing how to play only one game.

My problem with selling this idea is that people tend to think that their game is the only right one. 
In fact, being told that they are playing a game with arbitrary rules is insulting or frightening. They 
want to believe that the rules they know are the ones that everyone ought to play by; they even set 
up systems of punishment and reward to make sure that nobody tries to play a different game. They turn 
the game into something that is deadly serious, and so my idea simply seems frivolous instead of liberating.
```

<a name="#The-necessary-strangeness-of-scientific-explanations"></a>
## The necessary strangeness of scientific explanations
([overview](#overview))

Douglas Hofstadter on the necessary strangeness of scientific explanations:

```markdown
It is no accident, I would maintain, that quantum mechanics is so wildly counterintuitive. Part of the 
nature of explanation is that it must eventually hit some point where further probing only increases 
opacity rather than decreasing it. 

Consider the problem of understanding the nature of solids. You might wonder where solidity comes form. 
What if someone said to you, "The ultimate basis of this brick's solidity is that it is composed of a 
stupendous number of eensy weensy bricklike objects that themselves are rock-solid"? You might be 
interested to learn that bricks are composed of micro-bricks, but the initial question - "What accounts 
for solidity?" - has been thoroughly begged. What we ultimately want is for solidity to vanish, to 
dissolve, to disintegrate into some totally different kind of phenomenon with which we have no experience. 
Only then, when we have reached some completely novel, alien level will we feel that we have really made 
progress in explaining the top-level phenomenon.

...

I first saw this thought expressed in the stimulating book Patterns of Discovery by Norwood Russell 
Hanson. Hanson attributes it to a number of thinkers, such as Isaac Newton, who wrote, in his famous 
work Opticks: "The parts of all homogeneal hard Bodies which fully touch one another, stick together 
very strongly. And for explaining how this may be, some have invented hooked Atoms, which is begging 
the Question." Hanson also quotes James Clerk Maxwell (from an article entitled "Atom"): "We may 
indeed suppose the atom elastic, but this is to endow it with the very property for the explanation 
of which... the atomic constitution was originally assumed." Finally, here is a quote Hanson provides 
from Werner Heisenberg himself: "If atoms are really to explain the origin of color and smell of 
visible material bodies, then they cannot possess properties like color and smell." 

So, although it is not an original thought, it is useful to bear in mind that "greenness disintegrates".
```

<a name="#signaling"></a>
## Signaling
([overview](#overview))

<a name="#x-isnt-about-y"></a>
### X isn't about Y
([overview](#overview))

The founding document for this slogan is Robin Hanson's post [Politics isn't about policy](https://www.overcomingbias.com/2008/09/politics-isnt-a.html). 

Main thesis:

```markdown
Food isn’t about Nutrition
Clothes aren’t about Comfort
Bedrooms aren’t about Sleep
Marriage isn’t about Romance
Talk isn’t about Info
Laughter isn’t about Jokes
Charity isn’t about Helping
Church isn’t about God
Art isn’t about Insight
Medicine isn’t about Health
Consulting isn’t about Advice
School isn’t about Learning
Research isn’t about Progress
Politics isn’t about Policy

The above summarizes much of my contrarian world view.  (What else should go on this list?) 
When I say “X is not about Y,” I mean that while Y is the function commonly said to drive most 
X behavior, in fact some other function Z drives X behavior more.
```

Politics example from the post:

```markdown
High school students are easily engaged to elect class presidents, even though they have little 
idea what if any policies a class president might influence.  Instead such elections are usually
described as “popularity contests.”  That is, theses elections are about which school social 
factions are to have higher social status.  If a jock wins, jocks have higher status.  If your
girlfriend’s brother wins, you have higher status, etc.  And the fact that you have a vote says
that others should take you into account when forming coalitions – you are somebody.


Civics teachers talk as if politics is about policy, that politics is our system for choosing 
policies to deal with common problems.  But as Tyler Cowen suggests, real politics seems to be 
more about who will be our leaders, and what coalitions will rise or fall in status as a result.  
Election media coverage focuses on characterizing the candidates themselves – their personalities,
styles, friends, beliefs, etc.  You might say this is because character is a cheap clue to the
policies candidates would adopt, but I don’t buy it.

The obvious interpretation seems more believable – as with high school class presidents, we care
about policies mainly as clues to candidate character and affiliations.  And to the extent we
consider policies not tied to particular candidates, we mainly care about how policies will effect
which kinds of people will be respected how much.

For example, we want nationalized medicine so poor sick folks will feel cared for, military actions
so foreigners will treat us with respect, business deregulation as a sign of respect for hardworking
businessfolk, official gay marriage as a sign we accept gays, and so on.

This perspective explains why voters tend to prefer proportional representation, why many refuse to
vote for any candidate when none have earned their respect, and why so few are interested in
institutional reforms that would plausibly give more informed policies.
```

<a name="#countersignaling"></a>
### Countersignaling
([overview](#overview))

My go-to reference for countersignaling is Scott Alexander's [Intellectual Hipsters and Meta-Contrarianism](https://www.lesswrong.com/posts/9kcTNWopvXFncXgPy/intellectual-hipsters-and-meta-contrarianism). Key quote from the introduction:

```markdown
In certain situations refusing to signal can be a sign of high status. Thorstein Veblen invented
the term "conspicuous consumption" to refer to the showy spending habits of the nouveau riche,
who unlike the established money of his day took great pains to signal their wealth by buying fast
cars, expensive clothes, and shiny jewelery. Why was such flashiness common among new money but not
old? Because the old money was so secure in their position that it never even occurred to them that
they might be confused with poor people, whereas new money, with their lack of aristocratic breeding, 
worried they might be mistaken for poor people if they didn't make it blatantly obvious that they had
expensive things.

The old money might have started off not buying flashy things for pragmatic reasons - they didn't need
to, so why waste the money? But if F. Scott Fitzgerald is to be believed, the old money actively
cultivated an air of superiority to the nouveau riche and their conspicuous consumption; not buying 
flashy objects becomes a matter of principle. This makes sense: the nouveau riche need to differentiate 
themselves from the poor, but the old money need to differentiate themselves from the nouveau riche.

This process is called countersignaling, and one can find its telltale patterns in many walks of life.
Those who study human romantic attraction warn men not to "come on too strong", and this has similarities
to the nouveau riche example. A total loser might come up to a woman without a hint of romance, promise
her nothing, and demand sex. A more sophisticated man might buy roses for a woman, write her love poetry,
hover on her every wish, et cetera; this signifies that he is not a total loser. But the most desirable 
men may deliberately avoid doing nice things for women in an attempt to signal they are so high status 
that they don't need to. The average man tries to differentiate himself from the total loser by being nice;
the extremely attractive man tries to differentiate himself from the average man by not being especially 
nice.

In all three examples, people at the top of the pyramid end up displaying characteristics similar to 
those at the bottom. Hipsters deliberately wear the same clothes uncool people wear. Families with old
money don't wear much more jewelry than the middle class. And very attractive men approach women with 
the same lack of subtlety a total loser would use.
```

And here's metacontrarians as "intellectual hipsters":

```markdown
A person who is somewhat upper-class will conspicuously signal eir wealth by buying difficult-to-obtain
goods. A person who is very upper-class will conspicuously signal that ey feels no need to conspicuously 
signal eir wealth, by deliberately not buying difficult-to-obtain goods. 

A person who is somewhat intelligent will conspicuously signal eir intelligence by holding difficult-to-
understand opinions. A person who is very intelligent will conspicuously signal that ey feels no need to
conspicuously signal eir intelligence, by deliberately not holding difficult-to-understand opinions.

...just as contrarians risk becoming too contrary, moving from "actually, death has a few side benefits" to 
"DEATH IS GREAT!", meta-contrarians are at risk of becoming too meta-contrary.

All the possible examples here are controversial, so I will just take the least controversial one I can
think of and beg forgiveness. A naive person might think that industrial production is an absolute good
thing. Someone smarter than that naive person might realize that global warming is a strong negative to 
industrial production and desperately needs to be stopped. Someone even smarter than that, to differentiate
emself from the second person, might decide global warming wasn't such a big deal after all, or doesn't 
exist, or isn't man-made.

In this case, the contrarian position happened to be right (well, maybe), and the third person's meta-
contrariness took em further from the truth. I do feel like there are more global warming skeptics among 
what Eliezer called "the atheist/libertarian/technophile/sf-fan/early-adopter/programmer empirical cluster
in personspace" than among, say, college professors.

In fact, very often, the uneducated position of the five year old child may be deeply flawed and the 
contrarian position a necessary correction to those flaws. This makes meta-contrarianism a very dangerous
business. 

Remember, most everyone hates hipsters.

Without meaning to imply anything about whether or not any of these positions are correct or not3, the
following triads come to mind as connected to an uneducated/contrarian/meta-contrarian divide:

- KKK-style racist / politically correct liberal / "but there are scientifically proven genetic differences"
- misogyny / women's rights movement / men's rights movement
- conservative / liberal / libertarian4
- herbal-spiritual-alternative medicine / conventional medicine / Robin Hanson
- don't care about Africa / give aid to Africa / don't give aid to Africa
- Obama is Muslim / Obama is obviously not Muslim, you idiot / Patri Friedman5

What is interesting about these triads is not that people hold the positions (which could be expected by 
chance) but that people get deep personal satisfaction from arguing the positions even when their arguments
are unlikely to change policy6 - and that people identify with these positions to the point where arguments
about them can become personal.

If meta-contrarianism is a real tendency in over-intelligent people, it doesn't mean they should immediately
abandon their beliefs; that would just be meta-meta-contrarianism. It means that they need to recognize the
meta-contrarian tendency within themselves and so be extra suspicious and careful about a desire to believe 
something contrary to the prevailing contrarian wisdom, especially if they really enjoy doing so.

One more time: the fact that those beliefs are in an order does not mean some of them are good and others 
are bad. For example, "5 year old child / pro-death / transhumanist" is a triad, and "warming denier /
warming believer / warming skeptic" is a triad, but I personally support 1+3 in the first triad and 2 in 
the second. You can't evaluate the truth of a statement by its position in a signaling game; otherwise you 
could use human psychology to figure out if global warming is real!
```

Commenter Emile cautions that "going meta" can be dangerous:

```markdown
It's possible to go meta on nearly any issue, and there are a lot of meta-level arguments - group 
affiliation, signaling, rationalization, ulterior motives, whether a position is contrarian or supported
by the majority, who the experts are and how much we should trust them, which group is persecuted the most,
straw man positions and whether anybody really holds them, slippery slopes, different ways to interpret
statements, who is working under which cognitive bias ...

Which is why I prefer discussions to stick to the object level rather than go meta. It's just too easy to
rationalize a position in meta, and to find convincing-sounding arguments as to why the other side mistakenly
disagrees with you. And meta-level disagreements are more likely to persist in the long run, because they are
hard to verify.

Sure, meta-level arguments are very valuable in many cases, we shouldn't drop them altogether. But we should
be very cautious while using them.
```

<a name="#expert-judgment"></a>
## Expert judgment
([overview](#overview))

Cosma Shalizi [compares clinical and actuarial judgment](http://bactra.org/notebooks/clinical-vs-actuarial.html), and finds something confusing; this also throws a wrench in my usual "experts suck at prediction" POV:

```markdown
For something like fifty years now, psychologists have been studying the question of 
"clinical versus actuarial judgment".

The idea goes like this. Say you're interested in diagnosing heart diseases from 
electrocardiograms. Normally we have clinicians, i.e., expert doctors, look at a chart and say
whether the patient has (to be definite) a heart condition requiring treatment within one year. 

Alternately, we could ask the experts what features they look at, when making their prognosis, 
and then fit a statistical model to that data, trying to predict the outcome or classification 
based on those features, which we can still have human experts evaluate. This is the actuarial
approach, since it's just based on averages --- "of patients with features x, y and z, q percent
have a serious heart condition".

The rather surprising, and completely consistent, result of these studies is that there are no 
known cases where clinicians reliably out-perform actuarial methods, even when the statistical 
models are just linear classification rules, i.e., about as simple a model as you can come up 
with. In many areas, statistical classifiers significantly out-perform human experts. They even 
out-perform experts who have access to the statistical results, apparently because the experts 
place too much weight on their own judgment, and not enough on the statistics. Whether you think
this is depressing news or not to some degree depends on your feelings about "clinical" experts.
So: human experts are really bad, or at least no better than simple statistical models.

On the other hand, there is *another* body of experimental work, admittedly more recent, on "simple
heuristics that make us smart", which seems to show that people are often *very good* judges, *under
natural conditions*. That is to say, we're very good at solving the problems we tend to actually 
encounter, presented in the way we encounter them. The heuristics we use to solve those problems
may not be *generally* applicable, but they are *adapted* to our environments, and, in those
environments, are fast, simple and effective.
```

How to reconcile this apparent contradiction? Cosma proposes three different ways; he doesn't know which is best:

```markdown
1. The "clinicial versus actuarial" results are wrong, or at least irrelevant. The experiments
do not reflect the "natural" conditions of clinical judgment. There are many possibilities here,
but the one which springs immediately to mind is that clinicians may not actually have much insight
into the way they *really* make decisions, and that the factors they think they attend to may not 
really be the ones that matter to them. What one really wants is a representative sample of actual
cases, comparing the normal judgment of clinicians to that of the statistical models. This may 
have been done; I don't know.

2. The "fast and frugal heuristics" results are wrong, or at least irrelevant. Whatever adaptive
mechanisms let us figure out good heuristics in everyday life don't apply in the situations where 
we rely on clinical expertise, or at least not in a lot of them. (See, for instance, the discussion
of projective tests like the Rorsharch ink-blots in Holland et al.'s Induction.) The problem can't
just be that we didn't evolve to make psychiatric diagnoses, since we didn't evolve to do most of
the diagnostic/prognostic tasks the fast-and-frugal-heuristics experiments show we can do, presumably
by expating the mechanisms that let our ancestors answer questions like "Just how angry will my
neighbors be if they catch me fishing in their stream?". There has to be something special about the
conditions of clinicial judgment that render our normal cognitive mechanisms ineffective there.

3. Clinicial judgment *is* a "fast and frugal heuristic", with emphasis on the fast and frugal. That is,
it is true that (e.g.) linear classifiers are more *accurate*, but the decision procedures clinicians 
are using may be as accurate as one can get, using only a reasonable amount of information and a
reasonable amount of time, while still using the human brain, which is not a computing platform 
well-suited to floating-point operations. The problem here is that there are areas where clinicians 
do seem to do as well as statistical methods.
```

<a name="#Effective-altruism"></a>
## Effective altruism
([overview](#overview))

The sentiment that drives effective altruism is well expressed in the following peculiarity that Steven Pinker noted in [The trouble with Harvard](https://newrepublic.com/article/119321/harvard-ivy-league-should-judge-students-standardized-tests): 

```markdown
A skilled professional I know had to turn down an important freelance assignment
because of a recurring commitment to chauffeur her son to a resumé-building “social
action” assignment required by his high school. This involved driving the boy for 
45 minutes to a community center, cooling her heels while he sorted used clothing
for charity, and driving him back—forgoing income which, judiciously donated, could 
have fed, clothed, and inoculated an African village. The dubious “lessons” of this 
forced labor as an overqualified ragpicker are that children are entitled to treat 
their mothers’ time as worth nothing, that you can make the world a better place by
destroying economic value, and that the moral worth of an action should be measured
by the conspicuousness of the sacrifice rather than the gain to the beneficiary.
```

What David Friedman says in *The Machinery of Freedom* is also related:

```markdown
The person who says, as almost everyone does say, that human life is of infinite value, not to be measured 
in mere material terms, is talking palpable, if popular, nonsense. If he believed that of his own life, he 
would never cross the street, save to visit his doctor or to earn money for things necessary to physical 
survival. He would eat the cheapest, most nutritious food he could find and live in one small room, saving 
his income for frequent visits to the best possible doctors. He would take no risks, consume no luxuries, 
and live a long life. If you call it living. If a man really believed that other people's lives were 
infinitely valuable, he would live like an ascetic, earn as much money as possible, and spend everything 
not absolutely necessary for survival on CARE packets, research into presently incurable diseases, and 
similar charities.

In fact, people who talk about the infinite value of human life do not live in either of these ways. They 
consume far more than they need to support life. They may well have cigarettes in their drawer and a sports 
car in the garage. They recognize in their actions, if not in their words, that physical survival is only 
one value, albeit a very important one, among many.
```

<a name="#Weird-EA"></a>
### Weird EA
([overview](#overview))

The subheading for this section makes it sound like I'm making fun of the weirder parts of EA. Rest assured I'm not -- I am weird myself, and have always loved and sought out the weird. (That's what pretty much half this document *is*.)

The following are from Scott Alexander's [Fear and Loathing at EA Global 2017](https://slatestarcodex.com/2017/08/16/fear-and-loathing-at-effective-altruism-global-2017/), one of the more moving posts on EA he's written (and he's written a lot on this). 

Context:

```markdown
Effective altruism is the movement devoted to finding the highest-impact ways to help 
other people and the world. Philosopher William MacAskill described it as “doing for 
the pursuit of good what the Scientific Revolution did for the pursuit of truth”. They 
have an annual global conference to touch base and discuss strategy. This year it was 
in the Palace of Fine Arts in San Francisco, and I got a chance to check it out.

The official conference theme was “Doing Good Together”. The official conference 
interaction style was “earnest”. The official conference effectiveness level was “very”.
And it was impossible to walk away from some of the talks without being impressed. ...

The whole conference was flawlessly managed, from laser-fast registration to polished-
sounding speakers to friendly unobtrusive reminders to use the seventeen different apps
that would keep track of your conference-related affairs for you. And the of course the
venue, which really was amazing.
```

The "underbelly of the movement", where the weird stuff is:

```markdown
But walk a little bit outside of the perfectly-scheduled talks, or linger in the common
areas a little bit after the colorfully-arranged vegetarian lunches, and you run into the
shadow side of all of this, the hidden underbelly of the movement.

William MacAskill wanted a “scientific revolution in doing good”. But the Scientific
Revolution progressed from “I wonder why apples fall down” to “huh, every particle is in
an infinite number of places simultaneously, and also cats can be dead and alive at the 
same time”. The effective altruists’ revolution started with “I wonder if some charities
work better than others”. But even at this early stage, it’s gotten to some pretty weird
places.

I got to talk to some people from Wild Animal Suffering Research. They start with the 
standard EA animal rights argument – if you think animals have moral relevance, you can 
save zillions of them for almost no cost. A campaign for cage-free eggs, minimal in the 
grand scheme of things, got most major corporations to change their policies and gave two
hundred million chickens an improved quality of life. But WASR points out that even this
isn’t the most neglected cause. There are up to a trillion reptiles, ten quintillion
insects, and maybe a sextillion zooplankton. And as nasty as factory farms are, life in the
state of nature is nasty, brutish, short, and prone to having parasitic wasps paralyze you
so that their larvae can eat your organs from the inside out while you are still alive. 
WASR researches ways we can alleviate wild animal suffering, from euthanizing elderly 
elephants (probably not high-impact) to using more humane insecticides (recommended as an 
‘interim solution’) to neutralizing predator species in order to relieve the suffering of
prey (still has some thorny issues that need to be resolved).

Wild Animal Suffering Research was nowhere near the weirdest people at Effective Altruism
Global.

I got to talk to people from the Qualia Research Institute, who point out that everyone 
else is missing something big: the hedonic treadmill. People have a certain baseline 
amount of happiness. Fix their problems, and they’ll be happy for a while, then go back to 
baseline. The only solution is to hack consciousness directly, to figure out what exactly
happiness is – unpack what we’re looking for when we describe some mental states as having 
higher positive valence than others – and then add that on to every other mental state
directly. This isn’t quite the dreaded wireheading, the widely-feared technology that will
make everyone so doped up on techno-super-heroin (or direct electrical stimulation of the 
brain’s pleasure centers) that they never do anything else. It’s a rewiring of the brain
that creates a “perpetual but varied bliss” that “reengineers the network of transition 
probabilities between emotions” while retaining the capability to do economically useful 
work. Partly this last criteria is to prevent society from collapsing, but the ultimate
goal is:

    …the possibility of a full-fledged qualia economy: when people have spare
    resources and are interested in new states of consciousness, anyone good at
    mining the state-space for precious gems will have an economic advantage. In 
    principle the whole economy may eventually be entirely based on exploring the 
    state-space of consciousness and trading information about the most valuable
    contents discovered doing so.

The Qualia Research Institute was nowhere near the weirdest people at Effective Altruism 
Global.

I got to talk to some people from the Foundational Research Institute. They do a lot of 
research, and a lot of it is very good, but they’re most infamous within the community for
their particle work. It goes like this: the universe is really really big. So if suffering 
made up an important part of the structure of the universe, this would be so tremendously 
outrageously unconscionably bad that we can’t even conceive of how bad it could be. So the
most important cause might be to worry about whether fundamental physical particles are 
capable of suffering – and, if so, how to destroy physics. From their writeup:

    Speculative scenarios to change the long-run future of physics may dominate any
    concrete work to affect the welfare of intelligent computations — at least within 
    the fraction of our brain’s moral parliament that cares about fundamental physics. 
    The main value (or disvalue) of intelligence would be to explore physics further 
    and seek out tricks by which its long-term character could be transformed. 
    
    For instance, if false-vacuum decay did look beneficial with respect to reducing
    suffering in physics, civilization could wait until its lifetime was almost over 
    anyway (letting those who want to create lots of happy and meaningful intelligent 
    beings run their eudaimonic computations) and then try to ignite a false-vacuum 
    decay for the benefit of the remainder of the universe (assuming this wouldn’t 
    impinge on distant aliens whose time wasn’t yet up). Triggering such a decay might
    require extremely high-energy collisions — presumably more than a million times 
    those found in current particle accelerators — but it might be possible. On the 
    other hand, such decay may happen on its own within billions of years, suggesting
    little benefit to starting early relative to the cosmic scales at stake. 
    
    In any case, I’m not suggesting vacuum decay as the solution — just that there may be 
    many opportunities like it waiting to be found, and that these possibilities may
    dwarf anything else that happens with intelligent life.
```

Scott subscribes to the Lovecraftian "it was not meant that we should voyage far" from our "placid island of ignorance in the midst of black seas of infinity":

```markdown
We live on a placid island of ignorance in the midst of black seas of infinity, 
and it was not meant that we should voyage far. The sciences, each straining in 
its own direction, have hitherto harmed us little; but some day the piecing 
together of dissociated knowledge will open up such terrifying vistas of reality, 
and of our frightful position therein, that we shall either go mad from the 
revelation or flee from the deadly light into the peace and safety of a new dark age.
```

Scott adds:

```markdown
Morality wasn’t supposed to be like this. Most of the effective altruists I met were 
nonrealist utilitarians. They don’t believe in some objective moral law imposed by an 
outside Power. They just think that we should pursue our own human-parochial moral values
effectively. If there was ever a recipe for a safe and milquetoast ethical system, that
should be it. And yet once you start thinking about what morality is – really thinking,
the kind where you try to use mathematical models and formal logic – it opens up into 
these dark eldritch vistas of infinities and contradictions. The effective altruists
started out wanting to do good. And they did: whole nine-digit-sums worth of good,
spreadsheets full of lives saved and diseases cured and disasters averted. But if you 
really want to understand what you’re doing – get past the point where you can catch 
falling apples, to the point where you have a complete theory of gravitation – you end 
up with something as remote from normal human tenderheartedness as the conference lunches
were from normal human food.
```

And this is the money quote that made me start this section in the first place, because it touched me deeply (perhaps part of it is simply Scott's rhetoric working on me?):

```markdown
But I worry I’m painting a misleading picture here. It isn’t that effective altruism is
divided into two types of people: the boring effective suits, and the wacky explorers of
bizarre ethical theories. I mean, there’s always going to be *some* division. But by and 
large these were the same people, or at least you couldn’t predict who was who. They 
would go up and give a talk about curing river blindness in Nigeria, and then you’d catch 
them later and learn that they were worried that maybe the most effective thing was 
preventing synthetic biology from taking over the ecosystem. Or you would hear someone 
give their screed, think “what a weirdo”, and then learn they were a Harvard professor who 
served on a bunch of Fortune 500 company boards. Maybe the right analogy would be physics.
A lot of physicists work on practical things like solar panels and rechargeable batteries.
A tiny minority work on stranger things like wormholes and alternate universes. But it’s 
not like these are two different factions in physics that hate each other. And every so 
often a solar panel engineer might look into the math behind alternate universes, or a
wormhole theorist might have opinions on battery design. They’re doing really different 
stuff, but it’s within the same tradition.

The movement’s unofficial leader is William MacAskill. He’s a pretty typical overachiever
– became an Oxford philosophy professor at age 28 (!), founded three successful non-profits,
and goes around hobnobbing with rich people trying to get them to donate money (he himself
has pledged to give away everything he earns above $36,000). I had always assumed he was 
just a random dignified suit-wearing person who was slightly exasperated at having to put 
up with the rest of the movement. But I got a chance to talk to him – just for a few minutes,
before he had to run off and achieve something – and I was shocked at how much he knew about
all the weirdest aspects of the community, and how protective he felt of them. And in his 
closing speech, he urged the attendees to “keep EA weird”, giving examples of times when 
seemingly bizarre ideas won out and became accepted by the mainstream.

If it were just the senior research analysts at their spreadsheets, we could dismiss them as
the usual Ivy League lizard people and move on. If it were just the fringes ranting about 
cyber-neuro-metaphilosophy, we could dismiss them as loonies and forget about it. And if it 
were just the two groups, separate and doing their own thing, we could end National Geographic-
style, intoning in our best David Attenborough voice that “Effective Altruism truly is a land
of contrasts”. But it’s more than that. Some animating spirit gives rise to the whole thing, 
some unifying aesthetic that can switch to either pole and back again on a whim. After a lot
of thought, I have only one guess about what it might be.

I think the effective altruists are genuinely good people.

Over lunch, a friend told me about his meeting with an EA philosopher who hadn’t been able 
to make it to the conference. This friend had met the philosopher, and as they were walking,
the philosopher had stopped to pick up worms writhing on the sidewalk and put them back in 
the moist dirt.

And this story struck me, because I had taken a walk with one of the speakers earlier, and 
seen her do the same thing. She had been apologetic, said she knew it was a waste of her 
time and mine. She’d wondered if it was pathological, whether maybe she needed to be checked
for obsessive compulsive disorder. But when I asked her whether she wanted to stop doing it,
she’d thought about it a little, and then – finally – saved the worm.

And there was a story about the late great moral philosopher Derek Parfit, himself a member
of the effective altruist movement. This is from Larissa MacFarquhar:

    As for his various eccentricities, I don’t think they add anything to an understanding 
    of his philosophy, but I find him very moving as a person. When I was interviewing him 
    for the first time, for instance, we were in the middle of a conversation and suddenly 
    he burst into tears. It was completely unexpected, because we were not talking about 
    anything emotional or personal, as I would define those things. I was quite startled, 
    and as he cried I sat there rewinding our conversation in my head, trying to figure out
    what had upset him. Later, I asked him about it. It turned out that what had made him 
    cry was the idea of suffering. We had been talking about suffering in the abstract. I 
    found that very striking.

    Now, I don’t think any professional philosopher is going to make this mistake, but 
    nonprofessionals might think that utilitarianism, for instance (Parfit is a utilitarian),
    or certain other philosophical ways of think about morality, are quite unemotional, 
    quite calculating, quite cold; and so because as I am writing mostly for nonphilosophers,
    it seemed like a good corrective to know that for someone like Parfit these issues are 
    extremely emotional, even in the abstract.

    The weird thing was that the same thing happened again with a philosophy graduate student
    whom I was interviewing some months later. Now you’re going to start thinking it’s me, 
    but I was interviewing a philosophy graduate student who, like Parfit, had a very
    unemotional demeanor; we started talking about suffering in the abstract, and he burst 
    into tears. I don’t quite know what to make of all this but I do think that insofar as 
    one is interested in the relationship of ideas to people who think about them, and not 
    just in the ideas themselves, those small events are moving and important.
    
I imagine some of those effective altruists, picking up worms, and I can see them here too. 
I can see them sitting down and crying at the idea of suffering, at allowing it to exist.

Larissa MacFarquhar says she doesn’t know what to make of this. I think I sort of do. I’m not
much of an effective altruist – at least, I’ve managed to evade the 80,000 Hours coaches long
enough to stay in medicine. But every so often, I can see the world as they have to. Where 
the very existence of suffering, any suffering at all, is an immense cosmic wrongness, an 
intolerable gash in the world, distressing and enraging. Where a single human lifetime seems
frighteningly inadequate compared to the magnitude of the problem. Where all the normal 
interpersonal squabbles look trivial in the face of a colossal war against suffering itself, 
one that requires a soldier’s discipline and a general’s eye for strategy.

All of these Effecting Effective Effectiveness people don’t obsess over efficiency out of 
bloodlessness. They obsess because the struggle is so desperate, and the resources so few. 
Their efficiency is military efficiency. Their cooperation is military discipline. Their unity 
is the unity of people facing a common enemy. And they are winning. Very slowly, WWI trench-
warfare-style. But they really are.
```

<a name="#Erisology"></a>
### Erisology
([overview](#overview)) 

From John Nerst's [What is erisology?](https://everythingstudies.com/what-is-erisology/), the founding document of the discipline:

```markdown
“Disagreement” can mean many things, but this is what I have in mind: A lot of online discourse
is hostile and often needlessly adversarial (I trust no one needs to be convinced of this). 
Specifically, a lot of this disagreement is dysfunctional, by which I mean that it results from 
(or is exacerbated by) one or both of the parties, intentionally or unintentionally, misunderstanding
the other party’s position or the nature of their differences. ...

Erisology is the study of this dysfunction and, theoretically, the attempt to fix some of it by
making people more aware of how it happens and how it doesn’t always need to happen. 

...a lot of different research paradigms and philosophical frameworks are in play when people talk
about anything even remotely abstract and/or ambiguous. And behind disagreement on even the most
concrete things there is often one or several undissolved philosophical issues being discussed by 
proxy, and at the same time the discussion process itself is disturbed by all kinds of corrupting
psychological and social influences.

An erisology research program would try to integrate basic insights and models from all these fields.
It would involve describing and cataloging the kinds of issues that hide under the surface in
dysfunctional discourse and the processes that make us unaware of them, contributing to the problem.
Ultimately and hypothetically the goal would be to improve discourse by creating and spreading ideas
and mental tools that work to defuse unnecessary conflict before it occurs, as well as clarify
necessary conflict so we know what it’s really about.
```

Erisology would necessarily be cross-discplinary, which is music to my ears. A sample:

```markdown
The study of cognitive biases and how they affect our thinking, breaking it in particular predictable
ways.

Traditional philosophy and its discussion of the nature of categories, objects and properties; a 
staggering proportion of online verbal conflict concern, at its core, some variety of the question
of what category something belongs in. The pitfall here is that people act as though such questions
have true answers when in most cases they don’t – making it possible for two people to both be right
while contradicting each other.

Data analysis and its understanding of the relationships between models and data, clusters and 
categories, axes and properties. Statistical modeling and interpretation issues mirror a lot of the
problems that arise when people use their own particular experiences to build models of how the world
works (which later clash with those of others).

Cognitive and perceptual psychology, for insights in how we form concepts in the brain and how they
affect our perceptions and interpretations of what we see, giving rise to differences between people 
we have a tough time understanding because they are so fundamental to our mental function they slip 
out of awareness. Also useful is how attitudes and opinions are sometimes the downstream result of 
ultimately physiological differences in perception and emotion.

Personality psychology, for differences between people that may create hard-to-comprehend, subconscious 
divisions.

Poststructuralist theory and its conception of language as being inherently slippery and devoid of 
ultimate, definitive meaning. Our intuitive blindness to this causes us to misinterpret things other
people say without realizing it.

Rhetoric, the art of persuasion, is partly useful because it’s a practice more than a science and as
far as I know lack theory that grounds “what works and what doesn’t” in human psychology.

Anthropology and its examination of how many things we take for granted in our societies are non-obvious
and somewhat arbitrary.

Literary theory and its treatment of narratives, their interpretation and how they cannot be definitive
or claim absolute truth.

Epistemology, and how people take for granted different approaches to knowledge. I’m not talking so much
about explicit differences like “personal revelation vs. scientific study” but more underlying differences
like the balance between personal experience and statistics, empirical data vs. theoretical considerations.
These differences are sometimes discussed but are present as an important factor in way more contexts than
they are explicitly talked about.

Sociology and history and their theories of social construction, which are very useful when not overstated
and used as a political bludgeon. They also have valuable insights about how the design of technology and 
institutions shape behavior.

Evolutionary psychology and social instincts, especially those related to intra- and intergroup conflict 
like argumentation, rivalry, social status, identity and dehumanization. An important aspect here is also
recognizing that modern large-scale societies is an extremely unnatural social structure for humans and
this gives rise to all kinds of weird effects.

Computer science, specifically insights from attempts to create artificial intelligence and the
difficulties of modeling human concepts. Writing software also give you good habits, since it often makes
you understand that accurately modeling reality is way more complicated that you first thought.

Not the purview of any particular field, but understanding reductionism and its discontents are important
to a lot of erisology covering the often disappointing interactions between academic disciplines. 
Differing attitudes to reductionism vs. inherent semantics makes people find different kinds of explanations
satisfactory.
```

I'd be remiss not to mention that Carlos Bueno's [advice on optimizing software performance](#Performance-optimization) ("in 8-figure compute environments", as he says on Twitter) has a *ton* of good stuff on thinking less wrongly.

<a name="#The-cowpox-of-doubt"></a>
### The cowpox of doubt
([overview](#overview)) 

Just now I came across this comment by JenniferRM on [Eliezer's post](https://www.lesswrong.com/posts/YicoiQurNBxSp7a65/is-clickbait-destroying-our-general-intelligence):

```markdown
I think that repeated low level exposure to lying liars improves people's bullshit
detectors.

By modern standards, people who first started listening to radio were *insanely 
gulllible* in response to the sound of authoritative voices, both in the US and in
Germany. Similarly for TV a few decades later. The very first ads on the Internet 
(primitive though they were) had incredibly high conversion rates... For a given 
"efficacy" of any kind of propaganda, more of the same tends to have less effect 
over time.

I fully expect this current media milieu to be considered charmingly simple, with 
gullible audiences and hamhanded influence campaigns, relative to the manipulative
tactics that will be invented in future decades, because this stuff will stop working. :)
```

This was the first time I ever read a JenniferRM comment/post and thought, *I have something to say in response!* The TL;DR reason is that Jennifer is about as far beyond Scott Alexander as Scott is beyond me. [Pace Scott](https://slatestarcodex.com/2014/03/13/five-years-and-one-week-of-less-wrong/):

```markdown
I’ll end with something that recently encouraged me a lot. Sometimes I talk to Will 
Newsome, or Steve Rayhawk, or Jennifer RM, or people like that in the general category
of “we all know they are very smart but they have no ability to communicate their 
insights to others”. They say inscrutable things, and I nod and pretend to understand 
because it’s less painful than asking them to explain and sitting through an equally
inscrutable explanation. And recently, the things that Will and Steve and Jennifer were 
saying a couple of years ago have started making perfect sense to me. The things they’re
saying now still sound like nonsense, but now I can be optimistic that in a few years 
I’ll pick up those too.

I find this really exciting. It suggests there’s this path to be progressed down, that
intellectual change isn’t just a random walk. Some people are further down the path 
than I am, and report there are actual places to get to that sound very exciting. And
other people are around the same place I am, and still other people are lagging behind
me. But when I look back at where we were five years ago, it’s so far back that none of
us can even see it anymore, so far back that it’s not until I trawl the archives that I
realize how many things there used to be that we didn’t know.
```

Granted, it isn't original at all -- it's Scott's [cowpox of doubt](https://slatestarcodex.com/2014/04/15/the-cowpox-of-doubt/). Relevant quote:

```markdown
I remember hearing someone I know try to explain rationality to his friends.

He started with “It’s important to have correct beliefs. You might think this is
obvious, but think about creationists and homeopaths and people who think the moon

landing was a hoax.” And then further on in this vein.

And I thought: “NO NO NO NO NO NO NO!”

I will make a confession. Every time someone talks about the stupidity of 
creationists, moon-hoaxers, and homeopaths, I cringe.

It’s not that moon-hoaxers, homeopaths et al aren’t dumb. They are. It’s not even
that these people don’t do real harm. They do.

What annoys me about the people who harp on moon-hoaxing and homeopathy – without 
any interest in the rest of medicine or space history – is that it seems like an 
attempt to Other irrationality.

It’s saying “Look, over here! It’s irrational people, believing things that we can
instantly dismiss as dumb. Things we feel no temptation, not one bit, to believe. 
It must be that they are defective and we are rational.”

But to me, the rationality movement is about Self-ing irrationality.

It is about realizing that you, yes you, might be wrong about the things that you’re
most certain of, and nothing can save you except maybe extreme epistemic paranoia.

Talking about moon-hoaxers and homeopaths too much, at least the way we do it, is
*counterproductive* to this goal. Throw examples of obviously stupid false beliefs
at someone, and they start thinking all false beliefs are obvious. Give too many
examples of false beliefs that aren’t tempting to them, and they start believing 
they’re immune to temptation.

...

Inoculation is when you use a weak pathogen like cowpox to build immunity against
a stronger pathogen like smallpox. The inoculation effect in psychology is when a
person, upon being presented with several weak arguments against a proposition, 
becomes immune to stronger arguments against the same position.

Tell a religious person that Christianity is false because Jesus is just a blatant
ripoff of the warrior-god Mithras and they’ll open up a Near Eastern history book,
notice that’s not true at all, and then be that much more skeptical of the next
argument against their faith. “Oh, atheists. Those are those people who think stupid
things like Jesus = Mithras. I already figured out they’re not worth taking 
seriously.” Except on a deeper level that precedes and is immune to conscious thought.

So we take the intelligent Internet-reading public, and we throw a bunch of
incredibly dumb theories at them – moon-hoaxism, homeopathy, creationism, anti-
vaxxing, lizard people, that one guy who thought the rapture would come a couple
years ago, whatever. And they are easily debunked, and the stuff you and all your 
friends believed was obviously true is, in fact, obviously true, and any time you 
spent investigating whether you were wrong is time you wasted.

And I worry that we are vaccinating people against reading the research for themselves
instead of trusting smarmy bloggers who talk about how stupid the other side is.

That we are vaccinating people against thinking there might be important truths on both
sides of an issue.

That we are vaccinating people against understanding how “scientific evidence” is a
really complicated concept, and that many things that are in peer-reviewed journals 
will later turn out to be wrong.

That we are vaccinating people against the idea that many theories they find absurd 
or repugnant at first will later turn out to be true, because nature doesn’t respect
our feelings.

That we are vaccinating people against *doubt*.

And maybe this is partly good. It’s probably a good idea to trust your doctor and 
also a good idea to trust your climatologist, and rare is the field where I would 
feel comfortable challenging expert consensus completely.

But there’s also this problem of hundreds of different religions and political 
ideologies, and most people are born into ones that are at least somewhat wrong. 
That makes this capacity for real doubt – doubting something even though all your
family and friends is telling you it’s obviously true and you must be an idiot to
question it at all – a tremendously important skill. It’s especially important for
the couple of rare individuals who will be in a position to cause a paradigm shift
in a science by doubting one of its fundamental assumptions.

I don’t think that reading about lizard people or creationism will affect people’s
ability to distinguish between, let’s say, cyclic universe theory versus multiverse
theory, or other equally dispassionate debates.

But if ever you ever need to have a true crisis of faith, then any time you spend 
thinking about homeopathy and moon hoaxes beyond the negligible effect they have 
on your life will be time spent learning exactly the wrong mental habits.
```

From what I've seen, this is basically what [RationalWiki](https://rationalwiki.org/wiki/Main_Page) does, and that plus its general lack of [charity](#argumentative-charity) is why I stay away from that place (all the while recognizing its [bravery debate function](https://slatestarcodex.com/2013/06/09/all-debates-are-bravery-debates/)). 

(Apropos of nothing: she just followed me on Twitter. I am over the moon.)

<a name="#argumentative-charity"></a>
## Argumentative charity
([overview](#overview))

My go-to text for charity is Scott Alexander's [founding post](https://slatestarcodex.com/2013/02/12/youre-probably-wondering-why-ive-called-you-here-today/) for his blog SSC. Here's the part I liked, which is pretty much all of the 'transferable' part:

```markdown
Absurdity is the natural human tendency to dismiss anything you disagree with as so stupid it doesn’t
even deserve consideration. In fact, you are virtuous for not considering it, maybe even heroic! You’re
refusing to dignify the evil peddlers of bunkum by acknowledging them as legitimate debate partners.

Charity is the ability to override that response. To assume that if you don’t understand how someone
could possibly believe something as stupid as they do, that this is more likely a failure of understanding 
on your part than a failure of reason on theirs.
```

Charity should be thought of like [Chesterton's fence](#chestertons-fence).

Charity as default, because even when it's uncalled for or ostensibly unnecessary it can be advantageous:

```markdown
The most effective way to learn any subject is to try to figure out exactly why a wrong position is wrong. 
And sometimes even a complete disaster of a theory will have a few salvageable pearls of wisdom that can’t 
be found anywhere else. The rationalist forum Less Wrong teaches the idea of steelmanning, rebuilding a 
stupid position into the nearest intelligent position and then seeing what you can learn from it.
```

There's also what Megan McArdle noted in [Only stupid people call people stupid](https://www.bloomberg.com/opinion/articles/2014-08-12/only-stupid-people-call-people-stupid):

```markdown
I’m always fascinated by the number of people who proudly build columns, tweets, blog posts or Facebook 
posts around the same core statement: “I don’t understand how anyone could (oppose legal abortion/support 
a carbon tax/sympathize with the Palestinians over the Israelis/want to privatize Social Security/insert 
your pet issue here)." It’s such an interesting statement, because it has three layers of meaning.

The first layer is the literal meaning of the words: *I lack the knowledge and understanding to figure this 
out*. But the second, intended meaning is the opposite: *I am such a superior moral being that I cannot even 
imagine the cognitive errors or moral turpitude that could lead someone to such obviously wrong conclusions*. 
And yet, the third, true meaning is actually more like the first: *I lack the empathy, moral imagination or 
analytical skills to attempt even a basic understanding of the people who disagree with me*.

In short, “I’m stupid.” Something that few people would ever post so starkly on their Facebook feeds.
```

<a name="#chestertons-fence"></a>
## Chesterton's fence
([overview](#overview))

From Scott Alexander's [founding post](https://slatestarcodex.com/2013/02/12/youre-probably-wondering-why-ive-called-you-here-today/):

```markdown
There are many things charity is not. Charity is not a fuzzy-headed caricature-pomo attempt to say no one 
can ever be sure they’re right or wrong about anything. Once you understand the reasons a belief is 
attractive to someone, you can go ahead and reject it as soundly as you want. Nor is it an obligation to
spend time researching every crazy belief that might come your way. Time is valuable, and the less of it
you waste on intellectual wild goose chases, the better.

It’s more like Chesterton’s Fence. G.K. Chesterton gave the example of a fence in the middle of nowhere. A
traveller comes across it, thinks “I can’t think of any reason to have a fence out here, it sure was dumb 
to build one” and so takes it down. She is then gored by an angry bull who was being kept on the other side
of the fence.

Chesterton’s point is that “I can’t think of any reason to have a fence out here” is the worst reason to 
remove a fence. Someone had a reason to put a fence up here, and if you can’t even imagine what it was, it
probably means there’s something you’re missing about the situation and that you’re meddling in things you
don’t understand. None of this precludes the traveller who knows that this was historically a cattle farming
area but is now abandoned – ie the traveller who understands what’s going on – from taking down the fence.

As with fences, so with arguments. If you have no clue how someone could believe something, and so you decide
it’s stupid, you are much like Chesterton’s traveler dismissing the fence (and philosophers, like travelers, 
are at high risk of stumbling across bull.)
``` 

See [legibility](#legibility) for some examples of tradition-as-Chesterton's fence.

<a name="#absurdity-heuristic"></a>
## Absurdity heuristic
([overview](#overview))

From Scott Alexander's [Talking Snakes: A Cautionary Tale](https://www.lesswrong.com/posts/atcJqdhCxTZiJSxo2/talking-snakes-a-cautionary-tale):

```markdown
I have read of the absurdity heuristic. I know that it is not carte blanche to go around rejecting
beliefs that seem silly. But I was still sympathetic to (Bill Maher's) talking snake argument. After
all... *a talking snake?*

I changed my mind in a Cairo cafe, talking to a young Muslim woman. I let it slip during the
conversation that I was an atheist, and she seemed genuinely curious why. You've all probably been in
such a situation, and you probably know how hard it is to choose just one reason, but I'd been 
reading about Biblical contradictions at the time and I mentioned the myriad errors and atrocities 
and contradictions in all the Holy Books.

Her response? "Oh, thank goodness it's that. I was afraid you were one of those crazies who believed
that monkeys transformed into humans."

I admitted that um, well, maybe I sorta kinda might in fact believe that.

It is hard for me to describe exactly the look of shock on her face, but I have no doubt that her
horror was genuine. I may have been the first flesh-and-blood evolutionist she ever met. "But..." she
looked at me as if I was an idiot. "Monkeys don't change into humans. What on Earth makes you think 
monkeys can change into humans?"

I admitted that the whole process was rather complicated. I suggested that it wasn't exactly a
Optimus Prime-style transformation so much as a gradual change over eons and eons. I recommended a few 
books on evolution that might explain it better than I could.

She said that she respected me as a person but that quite frankly I could save my breath because there 
was no way any book could possibly convince her that monkeys have human babies or whatever sort of
balderdash I was preaching. She accused me and other evolution believers of being too willing to accept
absurdities, motivated by our atheism and our fear of the self-esteem hit we'd take by accepting Allah
was greater than ourselves.

It is not clear to me that this woman did anything differently than Bill Maher. Both heard statements 
that sounded so crazy as to not even merit further argument. Both recognized that there was a large
group of people who found these statements plausible and had written extensive literature justifying
them. Both decided that the statements were so absurd as to not merit examining that literature more
closely. Both came up with reasons why they could discount the large number of believers because
those believers must be biased.

I post this as a cautionary tale as we discuss the logic or illogic of theism. I propose taking from 
it the following lessons:

- The absurdity heuristic doesn't work very well.

- Even on things that sound really, really absurd.

- If a large number of intelligent people believe something, it deserves your attention. After you've 
studied it on its own terms, then you have a right to reject it. You could still be wrong, though.

- Even if you can think of a good reason why people might be biased towards the silly idea, thus
explaining it away, your good reason may still be false.

- If someone cannot explain why something is not stupid to you over twenty minutes at a cafe, that
doesn't mean it's stupid. It just means it's complicated, or they're not very good at explaining things.

- There is no royal road.
```

Additional commentary by Eliezer Yudkowsky:

```markdown
Consider: If all the *rest* of the religious framework were granted, would the talking snake be an 
*additional problem*? No. The talking snake is only absurd if you refuse to grant the rest of the 
religious framework. The fact that a snake is talking is not, of itself, the source of any *additional*
problem - unless you were to argue that it fits the mode of a classic bias like minimal 
counterintuitiveness or thinking that "talking" is a simple feature that can easily be grafted on, etc.
But the point is, the part where a talking snake is in this story, is, presuming the story's other 
premises, not the proper subject of the dispute.

The problem is the other premises, and notions like sin passed down through generations, or that the 
sin was contained in an easily accessible tree put right there in the Garden (trap much?), or the fact
that a supernatural God is in the story - and so on and so on.

When you look at it from that perspective, then indeed, saying "Ha ha, a talking snake" is the exact
mirror image of saying "Ha ha, a monkey birthed a human", because it takes refuge in absurdity instead
of addressing the most important part of an argument as a whole.

The contradictions are a proper point of attack, but only if they would be really, genuinely troublesome 
*even granting the rest of the premises*.
```

Zaph:

```markdown
The use of absurdity seems more like a tool to enforce group norms than a means of conversion. That 
doesn't mean the beliefs aren't absurd, just that pointing out the absurdity of outsiders is common 
practice by in-group members. Most creationist-minded believers would use some similarly absurd way
of describing evolution, with the group benefit of passing along "evolution is stupid" meme. That said,
it is important to start to tease apart just how many other enforcement strategies are out there, as
they are going to need to be dealt with one by one.
```

<a name="#typical-mind-fallacy"></a>
## Typical mind fallacy
([overview](#overview))

Scott Alexander's LW post [Generalizing From One Example](https://www.lesswrong.com/posts/baTWMegR42PAsH9qJ/generalizing-from-one-example) begins with the following example of the "typical mind fallacy" by his old professor David Berman, about whether "imagination" was real or just a turn of phrase:

```markdown
There was a debate, in the late 1800s, about whether "imagination" was simply a turn of phrase or 
a real phenomenon. That is, can people actually create images in their minds which they see vividly,
or do they simply say "I saw it in my mind" as a metaphor for considering what it looked like?

Upon hearing this, my response was "How the stars was this actually a real debate? Of course we have
mental imagery. Anyone who doesn't think we have mental imagery is either such a fanatical Behaviorist 
that she doubts the evidence of her own senses, or simply insane." Unfortunately, the professor was 
able to parade a long list of famous people who denied mental imagery, including some leading scientists
of the era. And this was all before Behaviorism even existed.

The debate was resolved by Francis Galton, a fascinating man who among other achievements invented 
eugenics, the "wisdom of crowds", and standard deviation. Galton gave people some very detailed surveys,
and found that some people did have mental imagery and others didn't. The ones who did had simply 
assumed everyone did, and the ones who didn't had simply assumed everyone didn't, to the point of coming 
up with absurd justifications for why they were lying or misunderstanding the question. There was a wide
spectrum of imaging ability, from about five percent of people with perfect eidetic imagery to three
percent of people completely unable to form mental images.

Dr. Berman dubbed this the Typical Mind Fallacy: the human tendency to believe that one's own mental 
structure can be generalized to apply to everyone else's.

He kind of took this idea and ran with it. He interpreted certain passages in George Berkeley's biography
to mean that Berkeley was an eidetic imager, and that this was why the idea of the universe as sense-
perception held such interest to him. He also suggested that experience of consciousness and qualia were 
as variable as imaging, and that philosophers who deny their existence (Ryle? Dennett? Behaviorists?) were
simply people whose mind lacked the ability to easily experience qualia. In general, he believed philosophy
of mind was littered with examples of philosophers taking their own mental experiences and building theories
on them, and other philosophers with different mental experiences critiquing them and wondering why they
disagreed.
```

Now this is "about serious matters of mental structure". Scott noticed something similar going on with "matters of the psyche" -- a tendency to generalize from our personalities and behaviors. He gives two personal examples, introversion and noise sensitivity:

```markdown
For example, I'm about as introverted a person as you're ever likely to meet - anyone more introverted 
than I am doesn't communicate with anyone. All through elementary and middle school, I suspected that 
the other children were out to get me. They kept on grabbing me when I was busy with something and trying
to drag me off to do some rough activity with them and their friends. When I protested, they counter-
protested and told me I really needed to stop whatever I was doing and come join them. I figured they 
were bullies who were trying to annoy me, and found ways to hide from them and scare them off.

Eventually I realized that it was a double misunderstanding. They figured I must be like them, and the 
only thing keeping me from playing their fun games was that I was too shy. I figured they must be like me,
and that the only reason they would interrupt a person who was obviously busy reading was that they wanted
to annoy him.

Likewise: I can't deal with noise. If someone's being loud, I can't sleep, I can't study, I can't 
concentrate, I can't do anything except bang my head against the wall and hope they stop. I once had a noisy
housemate. Whenever I asked her to keep it down, she told me I was being oversensitive and should just
mellow out. I can't claim total victory here, because she was very neat and kept yelling at me for leaving
things out of place, and I told her she needed to just mellow out and you couldn't even tell that there was
dust on that dresser anyway. It didn't occur to me then that neatness to her might be as necessary and
uncompromisable as quiet was to me, and that this was an actual feature of how our minds processed information
rather than just some weird quirk on her part.

"Just some weird quirk on her part" and "just being oversensitive" are representative of the problem with the
typical psyche fallacy, which is that it's invisible. We tend to neglect the role of differently-built minds
in disagreements, and attribute the problems to the other side being deliberately perverse or confused. I 
happen to know that loud noise seriously pains and debilitates me, but when I say this to other people they
think I'm just expressing some weird personal preference for quiet. Think about all those poor non-imagers 
who thought everyone else was just taking a metaphor about seeing mental images way too far and refusing to 
give it up.
```

An example from Scott's experience with teaching -- see also [here](#teaching-and-learning):

```markdown
There's some evidence that the usual method of interacting with people involves something sorta like 
emulating them within our own brain. We think about how we would react, adjust for the other person's
differences, and then assume the other person would react that way. This method of interaction is very 
tempting, and it always feels like it ought to work.

But when statistics tell you that the method that would work on you doesn't work on anyone else, then
continuing to follow that gut feeling is a Typical Psyche Fallacy. You've got to be a good rationalist,
reject your gut feeling, and follow the data.

I only really discovered this in my last job as a school teacher. There's a lot of data on teaching 
methods that students enjoy and learn from. I had some of these methods...inflicted...on me during my 
school days, and I had no intention of abusing my own students in the same way. And when I tried the
sorts of really creative stuff I would have loved as a student...it fell completely flat. What ended up 
working? Something pretty close to the teaching methods I'd hated as a kid. Oh. Well. Now I know why 
people use them so much. And here I'd gone through life thinking my teachers were just inexplicably bad 
at what they did, never figuring out that I was just the odd outlier who couldn't be reached by this sort
of stuff.
```

Scott elaborates:

```markdown
Keeping in mind that I taught English as a second language to older elementary school children:

Ordinary teaching methods: constant repetition of unconnected topics followed by endless vapid games.
For example, a game of bingo with vocabulary words in each square. Attempts to trick children into 
thinking something was interesting; for example, calling vocabulary "word baseball" or something like that
and dressing up in a baseball cap while teaching it.

Things I predicted would work better: attempts to make material genuinely interesting, have each lesson 
build on the previous, and create links between different concepts. For example, a lesson on the days of
the week including a mini-presentation on the Norse gods after whom they were named, references to previous 
lessons when we had learned "sun" and "moon" for Sunday and Monday. Attempt to teach how to apply general 
principles instead of doing everything ad hoc.
```

Note that this all goes against the University of Missouri's [25 important findings on learning](#important-findings-on-learning), which is basically just an executive summary of the literature plus action items (themselves shortened rephrasings of the executive summaries), and yet they agree with Quoran teacher Matthew Bates' experience (see [his answers](https://www.quora.com/profile/Matthew-Bates-27)) so in the end I don't know. Maybe the former are talking about students from lower SES families (correlating with lower educational achievement)?

Dan Dennett gives an interesting illustration/test of mental imagery:

```markdown
Picture a 3 by 3 grid. Then picture the words "gas", "oil", and "dry" spelled downwards in the columns 
left to right in that order. Looking at the picture in your mind, read the words across on the grid.
```

Scientism points out a version of the typical mind fallacy in how people "vastly overestimate their own goodness" when it comes to "testimony on one's moral worth":

```markdown
Often "goodness" is just a way to dress up powerlessness. Like an overweight man might say he's "stocky" 
or an overweight woman might say she's "curvy," so an undesirable or shy man or woman might emphasize the 
upside: "I would never cheat." There's a version of the typical mind fallacy in there: a person might 
genuinely think they would never cheat but be extrapolating from a position where the opportunity rarely 
presents itself. We can all talk about how, if we were in a position of political power, we'd never succumb
to bribes or cronyism because we don't have any political power. It both makes us look good and, as far as 
we know, it's true. I think testimony, especially when it comes to ones moral worth, is the least valuable 
form of data available.
```

This segues naturall to the Milgram experiment, the Stanford prison experiment, and the case of Nazi-era German civilians:

```markdown
When I've taught ethics in the past, we always discuss the Nazi era. Not because the Nazis acted
unethically, but because of how everyone else acted.

For example, we read about the vans that carried Jewish prisoners that had the exhaust system designed
to empty into the van. The point is not how awful that is, but that there must have been an engineer 
somewhere who figured out the best way to design and build such a thing. And that engineer wasn't a Nazi
soldier, he or she was probably no different from anyone else at that time, with kids and a family and
friends and so on. Not an evil scientist in a lab, but just a design engineer in a corporation.

One point of the discussion is that "normal" people have acted quite unethically in the past, and how can
we prevent that happening to us.
```

From mental imagery to aural imagination, and their trainability, per cousin_it:

```markdown
Only this winter did I really understand that good musicians have vivid aural imagination, while I 
couldn't hear any sounds in my head, period. Immediately after this realization I started exercising. 
By now I can hear complete monophonic melodies, and (on good days) imagine two notes sounding at the 
same time. Classically trained conductors can imagine a complete orchestral sound while reading sheet
music. I don't see any reason why visual imagination can't be similarly trained.
```

How cousin_it trained the skill:

```markdown
The hardest part for me was the beginning, getting a toehold at any inner sound. Pick a note on 
the guitar - I started with D on the second string. Play it at a steady rhythm with rests, slowly
fading away into nothing. (Might not be possible on the piano or other instruments.) At some moment
the brain will start to "complete" the sound, even though by that point you're playing too softly to
hear. Catch that feeling, expand on it. When you can "do" several different notes, try playing a 
simple melody and hearing it afterwards. After you're comfortable with that, try to hear a simple major
scale without playing it immediately beforehand. Then work from unfamiliar sheet music without playing it
- solfege-sing in your mind - by now I can do this quite easily. And so on.
```

Prismattic points out how this plays out in books vs movies preferences:

```markdown
It struck me that I think you can still see the imagination debate playing out today. Consider the 
following conversation, which most people will have encountered a variant of at least once+:

-- Mr. Highbrow: It is better to read books than watch movies based on them. The movies limit you to 
someone else's perspective on the material, but the book gives maximum reign to your imagination.

-- Mr. Lowbrow: What are you smoking? The movie is an immersive experience that makes me feel like I'm 
really in the story. The book is just somebody else's description of the story.

Having thought about it, my highest-probability hypothesis is now that Mr. HB has more vivid mental 
imagery than does Mr. LB. Further introspection led me to realize that when I read fiction, I often have
very specific images of places and scenery, but usually only vague impressions of faces. When I watch 
film adaptions, I'm often struck that the setting is "wrong," but rarely have that feeling about the 
appearance of people (unless the actors are grossly divergent from the description of them in the book)
```

<a name="#general-philosophy"></a>
## General philosophy
([overview](#overview))

Scott Aaronson, in response to Luke Muehlhauser's interview question "why be interested in philosophy?" in the [MIRI Conversations series](https://intelligence.org/2013/12/13/aaronson/):

```markdown
I’ve always been reflexively drawn to the biggest, most general questions that it seemed possible to 
ask. You know, like are we living in a computer simulation? if not, could we upload our consciousnesses
into one? are there discrete “pixels” of spacetime? why does it seem impossible to change the past? 
could there be different laws of physics where 2+2 equaled 5? are there objective facts about morality?
what does it mean to be rational? is there an explanation for why I’m alive right now, rather than some
other time? What are explanations, anyway? In fact, what really perplexes me is when I meet a smart, 
inquisitive person—let’s say a mathematician or scientist—who claims NOT to be obsessed with these huge
issues! I suspect many MIRI readers might feel drawn to such questions the same way I am, in which case
there’s no need to belabor the point.

From my perspective, then, the best way to frame the question is not: “why be interested in philosophy?” 
Rather it’s: “why be interested in anything else?”

But I think the latter question has an excellent answer. A crucial thing humans learned, starting around 
Galileo’s time, is that even if you’re interested in the biggest questions, usually the only way to make
progress on them is to pick off smaller subquestions: ideally, subquestions that you can attack using 
math, empirical observation, or both. For again and again, you find that the subquestions aren’t nearly
as small as they originally looked! Much like with zooming in to the Mandelbrot set, each subquestion has 
its own twists and tendrils that could occupy you for a lifetime, and each one gives you a new perspective 
on the big questions. And best of all, you can actually answer a few of the subquestions, and be the first
person to do so: you can permanently move the needle of human knowledge, even if only by a minuscule amount.
As I once put it, progress in math and science — think of natural selection, Godel’s and Turing’s theorems,
relativity and quantum mechanics — has repeatedly altered the terms of philosophical discussion, as
philosophical discussion itself has rarely altered them! (Of course, this is completely leaving aside math
and science’s “fringe benefit” of enabling our technological civilization, which is not chickenfeed either.)


On this view, philosophy is simply too big and too important to be confined to philosophy departments! Of 
course, the word “philosophy” used to mean the entire range of fundamental inquiry, from epistemology and
metaphysics to physics and biology (which were then called “natural philosophy”), rather than just close
textual analysis, or writing papers with names like “A Kripkean Reading of Wittgenstein’s Reading of Frege’s
Reading of Kant.” And it seems clear to me that there’s enormous scope today for “philosophy” in the former 
sense — and in particular, for people who love working on the subquestions, on pushing the frontiers of
neuroscience or computer science or physics or whatever else, but who also like to return every once in a
while to the “deep” philosophical mysteries that motivated them as children or teenagers. Admittedly, there
have been many great scientists who didn’t care at all about philosophy, or who were explicitly anti-philosophy.
But there were also scientists like Einstein, Schrodinger, Godel, Turing, or Bell, who not only read lots of
philosophy but (I would say) used it as a sort of springboard into science — in their cases, a wildly successful
one. My guess would be that science ultimately benefits from both the “pro-philosophical” and the
“anti-philosophical” temperaments, and even from the friction between them.
```

Making progress on big problems:

```markdown
Pick off smaller subquestions: ideally, subquestions that you can attack using math, empirical observation, 
or both.

whenever it’s been possible to make definite progress on ancient philosophical problems, such progress has 
almost always involved a [kind of] “bait-and-switch.” In other words: one replaces an unanswerable
philosophical riddle Q by a “merely” scientific or mathematical question Q′, which captures part of what 
people have wanted to know when they’ve asked Q. Then, with luck, one solves Q′.

Of course, even if Q′ is solved, centuries later philosophers might still be debating the exact relation 
between Q and Q′! And further exploration might lead to other scientific or mathematical questions — Q′′, Q′′′,
and so on — which capture aspects of Q that Q′ left untouched. But from my perspective, this process of 
“breaking oﬀ” answerable parts of unanswerable riddles, then trying to answer those parts, is the closest thing
to philosophical progress that there is.

…A good replacement question Q′ should satisfy two properties: (a) Q′ should capture some aspect of the original
question Q — so that an answer to Q′ would be hard to ignore in any subsequent discussion of Q, [and] (b) Q′
should be precise enough that one can see what it would mean to make progress on Q′: what experiments one would
need to do, what theorems one would need to prove, etc.
```

Patrick McKenzie, "Some Perspective on the Japan Earthquake":

```markdown
The story of Japanese railways during the earthquake and tsunami is the story of an unceasing drumbeat 
of everything going right [...] The overwhelming response of Japanese engineering to the challenge posed 
by an earthquake larger than any in the last century was to function exactly as designed. Millions of 
people are alive right now because the system worked and the system worked and the system worked.

That this happened was, I say with no hint of exaggeration, one of the triumphs of human civilization. 
Every engineer in this country should be walking a little taller this week. We can’t say that too loudly, 
because it would be inappropriate with folks still missing and many families in mourning, but it doesn’t 
make it any less true.
```

Bruce Schneier:

```markdown
In our large, anonymous society, it's easy to forget moral and reputational pressures and concentrate on 
legal pressure and security systems. This is a mistake; even though our informal social pressures fade 
into the background, they're still responsible for most of the cooperation in society.
```

Hastie Dawes, *Rational Choice in an Uncertain World*, pp. 67-8:

```markdown
A lot of outcomes about which we care deeply are not very predictable. For example, it is not comforting 
to members of a graduate school admissions committee to know that only 23% of the variance in later 
faculty ratings of a student can be predicted by a unit weighting of the student's undergraduate GPA, 
his or her GRE score, and a measure of the student's undergraduate institution selectivity -- but that 
is opposed to 4% based on those committee members' global ratings of the applicant. We want to predict 
outcomes important to us. It is only rational to conclude that if one method (a linear model) does not 
predict well, something else may do better. What is not rational -- in fact, it's irrational -- is to 
conclude that this "something else" necessarily exists and, in the absence of any positive supporting 
evidence, is intuitive global judgment.
```

<a name="#Reality-has-a-surprising-amount-of-detail"></a>
## Reality has a surprising amount of detail
([overview](#overview))

The main impetus for starting this subsection is John Salvatier's [eponymous essay](http://johnsalvatier.org/blog/2017/reality-has-a-surprising-amount-of-detail), which I keep thinking off from time to time, albeit at a very vague level. Putting this here hopefully allows me to think about it at a granular enough level to internalize and build upon. 

Thesis: 

```markdown
Reality has a surprising amount of detail. This explains why its so easy for people to end 
up intellectually stuck. Even when they’re literally the best in the world in their field.
```

Example from personal hands-on experience:

```markdown
My dad emigrated from Colombia to North America when he was 18 looking looking for a
better life. For my brother and I that meant a lot of standing outside in the cold. 
My dad’s preferred method of improving his lot was improving lots, and my brother and 
I were “voluntarily” recruited to help working on the buildings we owned. That’s how 
I came to spend a substantial part of my teenage years replacing fences, digging
trenches, and building flooring and sheds. ...

Consider building some basement stairs for a moment. Stairs seem pretty simple at 
first, and at a high level they are simple, just two long, wide parallel boards 
(2” x 12” x 16’), some boards for the stairs and an angle bracket on each side to hold 
up each stair. But as you actually start building you’ll find there’s a surprising 
amount of nuance.

The first thing you’ll notice is that there are actually quite a few subtasks. Even at
a high level, you have to cut both ends of the 2x12s at the correct angles; then screw
in some u-brackets to the main floor to hold the stairs in place; then screw in the
2x12s into the u-brackets; then attach the angle brackets for the stairs; then screw in
the stairs.

Next you’ll notice that each of those steps above decomposes into several steps, some
of which have some tricky details to them due to the properties of the materials and 
task and the limitations of yourself and your tools.

The first problem you’ll encounter is that cutting your 2x12s to the right angle is a
bit complicated because there’s no obvious way to trace the correct angles. You can
either get creative (there is a way to trace it), or you can bust out your trig book 
and figure out how to calculate the angle and position of the cuts.

You’ll probably also want to look up what are reasonable angles for stairs. What looks
reasonable when you’re cutting and what feels safe can be different. Also, you’re
probably going to want to attach a guide for your circular saw when cutting the angle
on the 2x12s because the cut has to be pretty straight.

When you’re ready to you will quickly find that getting the stair boards at all the 
same angle is non-trivial. You’re going to need something that can give you an angle 
to the main board very consistently. Once you have that, and you’ve drawn your lines,
you may be dismayed to discover that your straight looking board is not that straight.
Lumber warps after it’s made because it was cut when it was new and wet and now it’s 
dryer, so no lumber is perfectly straight.

Once you’ve gone back to the lumber store and gotten some straighter 2x12s and redrawn
your lines, you can start screwing in your brackets. Now you’ll learn that despite 
starting aligned with the lines you drew, after screwing them in, your angle brackets
are no longer quite straight because the screws didn’t go in quite straight and now they 
tightly secure the bracket at the wrong angle. You can fix that by drilling guide holes 
first. Also you’ll have to move them an inch or so because it’s more or less impossible
to get a screw to go in differently than it did the first time in the same hole.

Now you’re finally ready to screw in the stair boards. If your screws are longer than 2”,
you’ll need different ones, otherwise they will poke out the top of the board and stab 
you in the foot.

At every step and every level there’s an abundance of detail with material consequences.
```

John points out that the lesson doesn't apply just to stair carpentry:

```markdown
It’s tempting to think ‘So what?’ and dismiss these details as incidental or specific to
stair carpentry. And they are specific to stair carpentry; that’s what makes them details.
But the existence of a surprising number of meaningful details is *not* specific to stairs.
Surprising detail is a near universal property of getting up close and personal with reality.

You can see this everywhere if you look. For example, you’ve probably had the experience
of doing something for the first time, maybe growing vegetables or using a Haskell package
for the first time, and being frustrated by how many annoying snags there were. Then you 
got more practice and then you told yourself ‘man, it was so simple all along, I don’t know
why I had so much trouble’. We run into a fundamental property of the universe and mistake 
it for a personal failing.

If you’re a programmer, you might think that the fiddliness of programming is a special 
feature of programming, but really it’s that everything is fiddly, but you only notice the 
fiddliness when you’re new, and in programming you do new things more often.
```

This isn't just human-centric domains. Even physical laws have a surprising amount of detail, as John illustrates with the example of determining the boiling point of water:

```markdown
You might think the fiddly detailiness of things is limited to human centric domains, and 
that physics itself is simple and elegant. That’s true in some sense – the physical laws
themselves tend to be quite simple – but the manifestation of those laws is often complex 
and counterintuitive.

Consider the boiling of water. That’s straightforward, water boils at 100 °C, right? Well 
the stairs seemed simple too, so let’s double check.

Put yourself in the shoes of someone at the start of the 1800’s, with only a crude, unmarked 
mercury thermometer, trying to figure the physics of temperature. Go to your stove, put some
water in a pot, start heating some water, and pay attention as it heats.

*(I suggest actually doing this)*

The first thing you’ll probably notice is a lot of small bubbles gathering on the surface of
the pot. Is that boiling? The water’s not that hot yet; you can still even stick your finger
in. Then the bubbles will appear faster and start rising, but they somehow seem ‘unboiling’.
Then you’ll start to see little bubble storms in patches, and you start to hear a hissing 
noise. Is that Boiling? Sort of? It doesn’t really look like boiling. The bubble storms grow
larger and start releasing bigger bubbles. Eventually the bubbles get big and the surface of
the water grows turbulent as the bubbles begin to make it to the surface. Finally we seem to
have reached real boiling. I guess this is the boiling point? That seems kind of weird, what
were the things that happened earlier if not boiling.

To make matters worse, if you’d used a glass pot instead of a metal one, the water would boil
at a higher temperature. If you cleaned the glass vessel with sulfuric acid, to remove any 
residue, you’d find that you can heat water substantially more before it boils and when it
does boil it boils in little explosions of boiling and the temperature fluctuates unstably.

Worse still, if you trap a drop of water between two other liquids and heat it, you can raise 
the temperature to at least 300 °C with nothing happening. That kind of makes a mockery of the
statement ‘water boils at 100 °C’.

It turns out that ‘boiling’ is a lot more complicated than you thought.

This surprising amount of detail is is not limited to “human” or “complicated” domains, it is
a near universal property of everything from space travel to sewing, to your internal
experience of your own mind.
```

I feel like this should be apparent if you've ever done experiments, or for that matter done engineering -- it's probably a big failure mode only for high theory folk. This naturally segues into Kovar/Hall's legendary [Electron Band Structure In Germanium, My Ass](http://pages.cs.wisc.edu/~kovar/hall.html) -- you should go to the original article for Fig 1 ("check this shit out -- resistivity vs temperature"):

```markdown
   **Abstract: The exponential dependence of resistivity on temperature in germanium is found to
   be a great big lie. My careful theoretical modeling and painstaking experimentation reveal 

   1) that my equipment is crap, as are all the available texts on the subject and 
   2) that this whole exercise was a complete waste of my time.**

   **Introduction**

      Electrons in germanium are confined to well-defined energy bands that are separated
   by "forbidden regions" of zero charge-carrier density. You can read about it yourself
   if you want to, although I don't recommend it. You'll have to wade through an obtuse,
   convoluted discussion about considering an arbitrary number of non-coupled harmonic-
   oscillator potentials and taking limits and so on. The upshot is that if you heat up 
   a sample of germanium, electrons will jump from a non-conductive energy band to a 
   conductive one, thereby creating a measurable change in resistivity. This relation 
   between temperature and resistivity can be shown to be exponential in certain 
   temperature regimes by waving your hands and chanting "to first order".

   **Experiment procedure**

      I sifted through the box of germanium crystals and chose the one that appeared to 
   be the least cracked. Then I soldered wires onto the crystal in the spots shown in
   figure 2b of Lab Handout 32. Do you have any idea how hard it is to solder wires 
   to germanium? I'll tell you: real goddamn hard. The solder simply won't stick, and
   you can forget about getting any of the grad students in the solid state labs to 
   help you out. 

      Once the wires were in place, I attached them as appropriate to the second-rate 
   equipment I scavenged from the back of the lab, none of which worked properly. I
   soon wised up and swiped replacements from the well-stocked research labs. This is
   how they treat undergrads around here: they give you broken tools and then don't 
   understand why you don't get any results.

      In order to control the temperature of the germanium, I attached the crystal to a 
   copper rod, the upper end of which was attached to a heating coil and the lower end
   of which was dipped in a thermos of liquid nitrogen. Midway through the project, the 
   thermos began leaking. That's right: I pay a cool ten grand a quarter to come here, 
   and yet they can't spare the five bucks to ensure that I have a working thermos.

   **Results**

      Check this shit out (Fig. 1). That's bonafide, 100%-real data, my friends. I took 
   it myself over the course of two weeks. And this was not a leisurely two weeks,
   either; I busted my ass day and night in order to provide you with nothing but 
   the best data possible. Now, let's look a bit more closely at this data, 
   remembering that it is absolutely first-rate. Do you see the exponential 
   dependence? I sure don't. I see a bunch of crap.

      Christ, this was such a waste of my time. 

      Banking on my hopes that whoever grades this will just look at the pictures, I 
   drew an exponential through my noise. I believe the apparent legitimacy is enhanced
   by the fact that I used a complicated computer program to make the fit. I understand
   this is the same process by which the top quark was discovered.	 
```

Why can't you just "deal with it as you go along"? Because when you're trying to do really hard things that we don't know are possible, lots of details turn out to be critical for success:

```markdown
You might hope that these surprising details are irrelevant to your mission, but not so. Some of
them will end up being key. Wood’s tendency to warp means it’s more accurate to trace a cut than 
to calculate its length and angle. The possibility of superheating liquids means it’s important
to use a packed bed when boiling liquids in industrial processes lest your process be highly 
inefficient and unpredictable. The massive difference in weight between a rocket full of fuel and
an empty one means that a reusable rocket can’t hover if it can’t throttle down to a very small 
fraction of its original thrust, which in turn means it must plan its trajectory very precisely 
to achieve 0 velocity at exactly the moment it reaches the ground.
```

And they're also frequently nonobvious when you run into them, they just look like "noise":

```markdown
You might also hope that the important details will be obvious when you run into them, but not so.
Such details aren’t *automatically* visible, even when you’re directly running up against them. 
Things can just seem messy and noisy instead. ‘Spirit’ thermometers, made using brandy and other
liquors, were in common use in the early days of thermometry. They were even considered as a
potential standard fluid for thermometers. It wasn’t until the careful work of Swiss physicist
Jean-André De Luc in the 18th century that physicists realized that alcohol thermometers are 
highly nonlinear and highly variable depending on concentration, which is in turn hard to measure.

You’ve probably also had experiences where you were trying to do something and growing increasingly
frustrated because it wasn’t working, and then finally, after some time you realize that your 
solution method can’t possibly work.
```

And different people notice different details:

```markdown
Another way to see that noticing the right details is hard, is that different people end up noticing
*different* details. My brother and I once built a set of stairs for the garage with my dad, and we
ran into the problem of determining where to cut the long boards so they lie at the correct angle. 
After struggling with the problem for a while (and I do mean struggling, a 16’ long board is heavy),
we got to arguing. I remembered from trig that we could figure out angle so I wanted to go dig up my 
textbook and think about it. My dad said, ‘no, no, no, let’s just trace it’, insisting that we could
figure out how to do it.

I kept arguing because I thought I was right. I felt really annoyed with him and he was annoyed with
me. In retrospect, I think I saw the fundamental difficulty in what we were doing and I don’t think
he appreciated it (look at the stairs picture and see if you can figure it out), he just heard ‘let’s
draw some diagrams and compute the angle’ and didn’t think that was the solution, and if he had
appreciated the thing that I saw I think he would have been more open to drawing some diagrams. But at
the same time, he also understood that diagrams and math don’t account for the shape of the wood,
which I did not appreciate. If we had been able to get these points across, we could have come to 
consensus. Drawing a diagram was probably a good idea, but computing the angle was probably not.
Instead we stayed annoyed at each other for the next 3 hours.
```

Notice that this example is about something as concrete and ostensibly simple as cutting long boards in stair carpentry. Differences of ideology are light-years harder, hence [erisology](#Erisology-and-thinking-less-wrongly).

This brings John to an important point -- that details are either invisible because you haven't noticed them, or because you *have* and they've become integrated into your world-models a la water is to fish:

```markdown
Before you’ve noticed important details they are, of course, basically invisible. It’s hard to
put your attention on them because you don’t even know what you’re looking for. But *after* you 
see them they quickly become so integrated into your intuitive models of the world that they 
become essentially transparent. Do you remember the insights that were crucial in learning to 
ride a bike or drive? How about the details and insights you have that led you to be good at the
things you’re good at?

This means it’s really easy to get *stuck*. Stuck in your current way of seeing and thinking about
things. Frames are made out of the details that seem important to you. The important details you
haven’t noticed are invisible to you, and the details you have noticed seem completely obvious and
you see right through them. This all makes makes it difficult to imagine how you could be missing
something important.

That’s why if you ask an anti-climate change person (or a climate scientist) “what could convince
you you were wrong?” you’ll likely get back an answer like “if it turned out all the data on my 
side was faked” or some other extremely strong requirement for evidence rather than “I would start
doubting if I noticed numerous important mistakes in the details my side’s data and my colleagues
didn’t want to talk about it”. The second case is much more likely than the first, but you’ll
never see it if you’re not paying close attention.

If you’re trying to do impossible things, this effect should *chill you to your bones*. It means 
you could be intellectually stuck right at this very moment, with the evidence right in front of
your face and you just can’t see it.
```

I'm probably lucky to not be working on impossible things. (Or maybe I am. This entire document is supposed to be an early-stage attempt in my neverending journey to build ideas via perfect *deliberate* recall.)

One way to get unstuck is to try to read lots of [non-expert explanations](https://slatestarcodex.com/2017/11/02/non-expert-explanation/), because they tend to focus on different sticking points (i.e. critical details). Another is to take John's advice:

```markdown
This problem is not easy to fix, but it’s not impossible either. I’ve mostly fixed it for myself.
The direction for improvement is clear: seek detail you would not normally notice about the world.
When you go for a walk, notice the unexpected detail in a flower or what the seams in the road 
imply about how the road was built. When you talk to someone who is smart but just seems so wrong,
figure out what details seem important to them and why. In your work, notice how that meeting 
actually wouldn’t have accomplished much if Sarah hadn’t pointed out that one thing. As you learn,
notice which details actually change how you think.
```

<a name="#reading-the-masters-in-philosophy"></a>
## Reading the masters in philosophy
([overview](#overview))

(See also [Reading the masters in math](#reading-the-masters-in-math), or my old post [8If Aristotle were a pro skater: or, reading the masters in math and philosophy*](https://mosstuff.quora.com/If-Aristotle-were-a-pro-skater-or-reading-the-masters-in-math-and-philosophy) to see both math and philo in one place.) 

Should you read the masters? In other words, should you prefer primary sources to summaries and commentaries?

On the one hand, the masters are the masters, so surely there’s *something* to reading them. On the other hand, I’m the kind of person who easily gets lost in walls of text, so when it comes to writing on difficult / ‘slippery’ topics I prefer polished, non-digressive reads. And primary texts, so they seem, are nothing but digressive.

(I suppose it depends why you’re reading. If it’s for enjoyment then secondhand sources certainly won’t cut it. I’m usually looking for insight; enjoyment I relegate to fiction, or exceptionally-written exposition, or something.)

This means I’m partial to Scott Alexander’s stance w.r.t reading the masters, from his post [Book Review: Singer on Marx](http://slatestarcodex.com/2014/09/13/book-review-singer-on-marx/):

```markdown
I’m not embarrassed for choosing Singer’s Marx: A Very Short Introduction as a jumping-off
point for learning more leftist philosophy. I weighed the costs and benefits of reading
primary sources versus summaries and commentaries, and decided in favor of the latter.

The clincher was that the rare times I felt like I really understand certain thinkers and 
philosophies on a deep level, it’s rarely been the primary sources that did it for me, 
even when I’d read them. It’s only after hearing a bunch of different people attack the 
same idea from different angles that I’ve gotten the gist of it. The primary sources – 
especially when they’re translated, especially when they’re from the olden days before 
people discovered how to be interesting – just turn me off. Singer is a known person who
can think and write clearly, and his book was just about the shortest I could find, so I 
jumped on it…
```

It doesn’t help that Andrew L’s comment in [this MO thread](https://mathoverflow.net/questions/28268/do-you-read-the-masters) is essentially what I think of the masters (to wit, that they’re notoriously hard to read):

```markdown
There's a myth surrounding Abel's dictum that stems from the unreadability of the masters
like Gauss as a measure of their nearly inhuman brilliance. This is a fallacy.

The reason the masters are so difficult to read is because we are catching them with their
pants down in the act of creation: they are groping towards the right notation and 
terminology, but aren't quite there yet.
```

Notation ("polish", as derisively referred to sometimes) is a UI design problem. UI design problems in research can be very nontrivial and extremely impactful from the standpoint of [interpretive labor](#distillation-and-research-debt). 

In Katja Grace's essay [Why read old philosophy?](https://meteuphoric.com/2017/01/04/why-read-old-philosophy/amp/), which is the main inspiration for this section, she begins by contrasting philosophy with physics, and pretty much every other book subject:

```markdown
We read old physicists if we want to do original research on the history of physics. Or 
maybe if we are studying an aspect of physics so obscure that nobody has covered it in
hundreds of years. If we want to learn physics we read a physics textbook. As far as I 
know, the story is similar in math, chemistry, engineering, economics, and business 
(though maybe some other subjects that I know less about are more like philosophy).

Yet go to philosophy grad school, and you will read original papers and books by 
historical philosophers. Research projects explore in great detail what it is that
Aristotle actually said, thought, and meant. Scholars will learn the languages that the
relevant texts were written in, because none of the translations can do the texts the 
necessary justice. The courses and books will be named after people like ‘Hume’ as often 
as they are named after topics of inquiry like ‘Causality’ and larger subject areas will
be organized by the spatiotemporal location of the philosopher, rather than by the subject
matter: Ancient Philosophy, Early Modern Philosophy, Chinese Philosophy, Continental 
Philosophy.
```

This should be confusing. It definitely confuses me. To elaborate on how it would look like in physics:

```markdown
The physics situation makes a lot more sense to me. Hypothetically, who would I rather 
read an explanation of ‘The Alice Effect’ by? —Alice, the effect’s seventeenth century
discoverer, or Bob, a modern day physics professor authoring a textbook?

Some salient considerations, neutrality not guaranteed:

- Alice’s understanding of the Alice effect is probably the most confused understanding 
of it in all of history, being the first ‘understanding of the Alice effect’ to set 
itself apart from ‘confusion and ignorance about the Alice effect’.

- In the billions of lifetimes that have passed since Alice’s time, the world has 
probably thought substantially more about The Alice Effect than Alice managed to in 
her lifetime, at least if it is important at all.

- Alice’s very first account of the effect probably contained imperfections. Bob can 
write about the theory as it stood after years of adjustment.

- Even if Alice’s account was perfectly correct, it was probably not perfectly well
explained, unless she happens to have been a great explainer as well as a great 
physicist.

- Physics has made many discoveries since Alice’s time, such as Claire forces, Evan motion
and Roger fields. It might be easier to understand all of this by starting with the Roger 
fields, and explaining the Alice effect as a consequence. However literature from the 
likes of Alice is constrained to cover topics chronologically by date of discovery.

- Bob speaks a similar version of English to me.

- Bob can be selected for having particular skill at writing and explanation, whereas Alice
must be selected for having the scientific prowess to make the discovery.

- Bob is actually trying to explain the thing to a 21st Century reader, while Alice is
writing to pique the interest of some seventeenth century noblemen who lack modern 
intellectual machinery and are interested in issues like whether this is compatible with
religion. An accurate impression of a 21st Century reader would probably cause Alice to 
fall over.

I think Bob is a solid choice.
```

So why is philosophy different?

```markdown
Some pieces of explanations I heard, or made up while hearing other explanations:

- You have to be smarter than the original philosopher to summarize their work well, so
there are few good summaries

- The translations are all terrible for conveying the important parts

- Philosophy is not trying to communicate normal content that can be in explicit 
statements, of the kind you might be able to explain well and check the understanding of
and such.

- Philosophy is about having certain experiences which pertain to the relevant philosophy,
much like reading a poem is different to reading a summary of its content.
```

None of this convinces Katja. She eventually settles on the "Aristotle as pro skater" analogy:

```markdown
Here’s my explanation. Reading Aristotle describe his thoughts about the world is like 
watching Aristotle ride a skateboard if Aristotle were a pro skater. You are not getting
value from learning about the streets he is gliding over (or the natural world that he is
describing) and you should not be memorizing the set of jumps he chooses (or his 
particular conceptualizations of the world). You are meant to be learning about how to
carry out the activity that he is carrying out: how to be Aristotle. How to do what
Aristotle would do, even in a new environment.

An old work of philosophy does not describe the thing you are meant to be learning about. 
It was created by the thing you are meant to be learning about, much like watching a video
from skater-Aristotle’s GoPro. And the value proposition is that with this high resolution
Aristotle’s-eye-view, you can infer the motions.

There is not a short description  of the insights you should learn (or at least not one
available), because the insights you are hopefully learning are not the insights that
Aristotle is trying to share. Aristotle might have highly summarizable insights, but what 
you want to know is how to be Aristotle, and nobody has necessarily developed an abstract 
model of how to be Aristotle from which summary statements can be extracted.

So it is not that the useful content being transmitted is of a special kind that is immune
to being communicated as statements. It is just not actually known in statements. Nobody 
knows which aspects of being Aristotle are important, and nobody has successfully made a
simplified summary. What we ‘know’ is this one very detailed example. Much like if I showed
you a bee because I thought I couldn’t communicate it in words—it would not be because bees
are mysteriously indescribable, it would be that I haven’t developed the understanding 
required to describe what is important about it, so I’m just showing you the whole bee.

On this theory, if someone doesn’t realize what is going on, and tries to summarize
Aristotle’s writings in the way that you would usually summarize the content of a passage,
you entirely lose what was valuable about it. Much as you would if you summarized a video 
of a skater in motion into a description of the environment that they had interacted with.
I hypothesize that this is roughly what happens, and is why it feels like summaries can’t 
capture what is important, and probably why translations seem bad always. Whenever a person
tries to do a translation, they faithfully communicate the content of the thoughts at the
expense of faithfully communicating the thinking procedure.
```

This sounds like alkjash's [becoming the grand meta-theorem](#two-cultures):

```markdown
My take on the "Two Cultures" model of problem-solvers and theory-builders: theory-building
fields of mathematics like algebraic topology (say) are those where the goal is to articulate 
grand meta-theorems that are bigger than any particular application. This was the work of a
Grothendieck.

Meanwhile, concrete problem-solving fields of mathematics like combinatorics are those where
the goal is to *become* the grand meta-theorem that contains more understanding than any 
particular theorem you can prove. This was the style of an Erdos. The inarticulate grand meta-
theorems lived in his cognitive strategies so that the theorems he actually proved are 
individually only faint impressions thereof.
```

There may be something about analytic philosophy being the part of philosophy that's more legible, and the less-legible parts of philosophy would then be the ones where you derive more value from reading primary sources -- but that's just a guess. That would be the intra-subject version of the inter-subject situation Katja actually does talk about towards the end:

```markdown
Why would you want to be like Socrates, and not like Newton? Especially since Newton had more 
to show for his thoughts than an account of what his thoughts were like. I suspect the 
difference is that because physicists invent explicit machinery that can be easily taught,
when you learn physics you spend your time mastering these tools. And perhaps in the process,
you come to think in a way that fits well with these tools. Whereas in philosophy there is
much less in the way of explicit methods to learn, so the most natural thing to learn is how
to do whatever mental processes produce good philosophy. And since there is not a consensus on
what they are like in the abstract, emulating existing good philosophers is a plausible way to
proceed.

I was in the CMU philosophy department, which focuses on more formal methods that others might
not class as philosophy—logic, algorithms for determining causality, game theory—and indeed in
logic class we learned a lot of logical lemmas and did a lot of proofs and did not learn much 
about Frege or Gödel, though we did learn a bit about their history and thought at other point
in the program.

(This story would suggest that in physics students are maybe missing out on learning the styles
of thought that produce progress in physics. My guess is that instead they learn them in grad 
school when they are doing research themselves, by emulating their supervisors, and that the 
helpfulness of this might partially explain why Nobel prizewinner advisors beget Nobel
prizewinner students.)
```

Katja gives the following example of a translation that "faithfully communicates the content of the thoughts at the expense of faithfully communicating the thinking procedure":

```markdown
For instance, suppose I have a sentence like this:

	We have enough pieces of evidence to say that 
	friendly banter is for counter-signaling.

If not quite the same words were available in a different language, it might get translated to:

	We have seen enough evidence to know that 
	friendly banter is for counter-signaling.

Which tells us something very similar about whether friendly banter is for counter-signaling.

But something subtle is lost about the process: in the initial statement, the author is 
suggesting that they are relying on the accretion of many separate pieces of evidence that
may not have been independently compelling, whereas in the latter that is not clear. Over a
long text, sentences like the former might give the reader an implicit understanding of how
disparate and independently uncompelling evidence might be combined in the intuition of the 
author, without the issue ever being explicitly discussed. In the latter, this implication is
entirely lost.

So I think this explains the sense that adequate summarization is impossible and translation
is extremely difficult. At least, if we assume that people either don’t know what is really 
going on.
```

<a name="#diseased-philosophy"></a>
## Diseased philosophy
([overview](#overview))

From Scott Aaronson's [Quantum Computing Since Democritus](https://slatestarcodex.com/2014/09/01/book-review-and-highlights-quantum-computing-since-democritus/):

```markdown
The third thing that annoys me about the Chinese Room argument is the way it gets so much mileage from 
a possibly misleading choice of imagery, or, one might say, by trying to sidestep the entire issue of 
computational complexity purely through clever framing. We’re invited to imagine someone pushing around 
slips of paper with zero understanding or insight, much like the doofus freshmen who write 
(a + b)^2 = a^2 + b^2 on their math tests. 

But how many slips of paper are we talking about! How big would the rule book have to be, and how 
quickly would you have to consult it, to carry out an intelligent Chinese conversation in anything 
resembling real time? If each page of the rule book corresponded to one neuron of a native speaker’s 
brain, then probably we’d be talking about a “rule book” at leas the size of the Earth, its pages 
searchable by a swarm of robots traveling at close to the speed of light. When you put it that way, 
maybe it’s not so hard to imagine this enormous Chinese-speaking entity that we’ve brought into being 
might have something we’d be prepared to call understanding or insight.

Philosophers are so good at pure qualitative distinctions that it’s easy to slip the difference between 
“guy in a room” and “planet being processed by lightspeed robots” under the rug.
```

Brandon Watson, [The Success and Failure of Arguments](http://branemrys.blogspot.com/2010/09/success-and-failure-of-arguments.html):

```markdown
Sometimes you hear philosophers bemoaning the fact that philosophers tend not to form consensuses 
like certain other disciplines do (sciences in particular). 

But there is no great mystery to this. The sciences reward consensus-forming as long as certain 
procedures are followed: agreements through experimental verification, processes of peer review, etc. 
Philosophy has nothing like this. Philosophers are rewarded for coming up with creative reasons not to 
agree with other people. The whole thrust of professional philosophy is toward inventing ways to regard 
opposing arguments as failure, as long as those ways don't exhibit any obvious flaws. However much 
philosophers are interested in the truth, philosophy as a profession is not structured so as to converge 
on it; it is structured so as to have the maximal possible divergence that can be sustained given common 
conventions. 

We are not trained to find ways to come to agree with each other; we are trained to find ways to 
disagree with each other.
```

John Perry, from the introduction to *Identity, Personal Identity, and the Self*:

```markdown
There is something about practical things that knocks us off our philosophical high horses. Perhaps Heraclitus 
really thought he couldn't step in the same river twice. Perhaps he even received tenure for that contribution 
to philosophy. But suppose some other ancient had claimed to have as much right as Heraclitus did to an ox 
Heraclitus had bought, on the grounds that since the animal had changed, it wasn't the same one he had bought 
and so was up for grabs. Heraclitus would have quickly come up with some ersatz, watered-down version of 
identity of practical value for dealing with property rights, oxen, lyres, vineyards, and the like. And then 
he might have wondered if that watered-down vulgar sense of identity might be a considerably more valuable 
concept than a pure and philosophical sort of identity that nothing has.
```

Razib Khan, [Reification is alright by me](http://blogs.discovermagazine.com/gnxp/2012/05/reification-is-alright-by-me/):

```markdown
The categories and classes we construct are simply the semantic sugar which makes the reality go down 
easier. They should never get confused for the reality that is, the reality which we perceive but darkly 
and with biased lenses. The hyper-relativists and subjectivists who are moderately fashionable in some 
humane studies today are correct to point out that science is a human construction and endeavor. Where 
they go wrong is that they are often ignorant of the fact that the orderliness of many facets of nature 
is such that even human ignorance and stupidity can be overcome with adherence to particular methods and 
institutional checks and balances. The predictive power of modern science, giving rise to modern 
engineering, is the proof of its validity. No talk or argumentation is needed. Boot up your computer. 
Drive your car.
```

<a name="#morality-axiology-law"></a>
## Morality, axiology, law
([overview](#overview))

Scott Alexander on the distinction between axiology, morality, and law, from [this essay](https://slatestarcodex.com/2017/08/28/contra-askell-on-moral-offsets/):

```markdown
Axiology is the study of what’s good. If you want to get all reductive, think of it as comparing the 
values of world-states. A world-state where everybody is happy seems better than a world-state where 
everybody is sad. A world-state with lots of beautiful art is better than a world-state containing only 
featureless concrete cubes. Maybe some people think a world-state full of people living in harmony with
nature is better than a world-state full of gleaming domed cities, and other people believe the opposite; 
when they debate the point, they’re debating axiology.

Morality is the study of what the right thing to do is. If someone says “don’t murder”, they’re making a 
moral commandment. If someone says “Pirating music is wrong”, they’re making a moral claim. Maybe some 
people believe you should pull the lever on the trolley problem, and other people believe you shouldn’t; 
when they debate the point, they’re debating morality.

(this definition elides a complicated distinction between individual conscience and social pressure; 
fixing that would be really hard and I’m going to keep eliding it)

Law is – oh, come on, you know this one. If someone says “Don’t go above the speed limit, there’s a 
cop car behind that corner”, that’s law. If someone says “my state doesn’t allow recreational marijuana,
but it will next year”, that’s law too. Maybe some people believe that zoning restrictions should ban 
skyscrapers in historic areas, and other people believe they shouldn’t; when they debate the point, 
they’re debating law.

These three concepts are pretty similar; they’re all about some vague sense of what is or isn’t desirable. 
But most societies stop short of making them exactly the same. Only the purest act-utilitarianesque 
consequentialists say that axiology exactly equals morality, and I’m not sure there is anybody quite that
pure. And only the harshest of Puritans try to legislate the state law to be exactly identical to the moral
one. To bridge the whole distance – to directly connect axiology to law and make it illegal to do anything 
other than the most utility-maximizing action at any given time – is such a mind-bogglingly bad idea that 
I don’t think anyone’s even considered it in all of human history.

These concepts stay separate because they each make different compromises between goodness, implementation, 
and coordination.

One example: axiology can’t distinguish between murdering your annoying neighbor vs. not donating money to 
savea child dying of parasitic worms in Uganda. To axiology, they’re both just one life snuffed out of the 
world beforeits time. If you forced it to draw some distinction, it would probably decide that saving the
child dying of parasitic worms was more important, since they have a longer potential future lifespan.

But morality absolutely draws this distinction: it says not-murdering is obligatory, but donating money to
Ugandais supererogatory. Even utilitarians who deny this distinction in principle will use it in everyday 
life: if theirfriend was considering not donating money, they would be a little upset; if their friend was
considering murder, they would be horrified. If they themselves forgot to donate money, they’d feel a little
bad; if they committedmurder in the heat of passion, they’d feel awful.

A final example: axiology tells us a world without alcohol would be better than our current world: ending
alcoholism could avert millions of deaths, illnesses, crimes, and abusive relationships. Morality only tells
us that we should be careful drinking and stop if we find ourselves becoming alcoholic or ruining our
relationships. And the law protests that it tried banning alcohol once, but it turned out to be unenforceable
and gave too many new opportunities to organized crime, so it’s going to stay out of this one except to say
you shouldn’t drink and drive.

So fundamentally, what is the difference between axiology, morality, and law?

Axiology is just our beliefs about what is good. If you defy axiology, you make the world worse.

At least from a rule-utilitarianesque perspective, morality is an attempt to triage the infinite demands 
of axiology, in order to make them implementable by specific people living in specific communities. It 
makes assumptions like “people have limited ability to predict the outcome of their actions”, “people 
are only going to do a certain amount and then get tired”, and “people do better with bright-line rules
than with vague gradients of goodness”. It also admits that it’s important that everyone living in a 
community is on at least kind of the same page morally, both in order to create social pressure to follow 
the rules, and in order to build the social trust that allows the community to keep functioning. If you 
defy morality, you still make the world worse. And you feel guilty. And you betray the social trust that
lets your community function smoothly. And you get ostracized as a bad person.

Law is an attempt to formalize the complicated demands of morality, in order to make them implementable
by a state with police officers and law courts. It makes assumptions like “people’s vague intuitive moral 
judgments can sometimes give different results on the same case”, “sometimes police officers and
legislators are corrupt or wrong”, and “we need to balance the benefits of laws against the cost of
enforcing them”. It also tries to avert civil disorder or civil war by assuring everybody that it’s in 
their best interests to appeal to a fair universal law code rather than try to solve their disagreements
directly. If you defy law, you still get all the problems with defying axiology and morality. And you 
make your country less peaceful and stable. And you go to jail.

In a healthy situation, each of these systems reinforces and promotes the other. Morality helps you 
implement axiology from your limited human perspective, but also helps prevent you from feeling guilty
for not being God and not being able to save everybody. The law helps enforce the most important moral
and axiological rules but also leaves people free enough to use their own best judgment on how to pursue
the others. And axiology and morality help resolve disputes about what the law should be, and then lend
the support of the community, the church, and the individual conscience in keeping people law-abiding.

In these healthy situations, the universally-agreed priority is that law trumps morality, and morality
trumps axiology. First, because you can’t keep your obligations to your community from jail, and you 
can’t work to make the world a better place when you’re a universally-loathed social outcast. But also,
because you can’t work to build strong communities and relationships in the middle of a civil war, and
you can’t work to make the world a better place from within a low-trust defect-defect equilibrium. But
also, because in a just society, axiology wants you to be moral (because morality is just a 
more-effective implementation of axiology), and morality wants you to be law-abiding (because law is 
just a more-effective way of coordinating morality). So first you do your legal duty, then your moral 
duty, and then if you have energy left over, you try to make the world a better place.

In unhealthy situations, you can get all sorts of weird conflicts. Most “moral dilemmas” are 
philosophers trying to create perverse situations where axiology and morality give opposite answers.
For example, the fat man version of the trolley problem sets axiology (“it’s obviously better to 
have a world where one person dies than a world where five people die”) against morality (“it’s a
useful rule that people generally shouldn’t push other people to their deaths”). And when morality 
and state law disagree, you get various acts of civil disobedience, from people hiding Jews from the
Nazis all the way down to Kentucky clerks refusing to perform gay marriages.

I don’t have any special insight into these. My intuition (most authoritative source! is never wrong!)
says that we should be very careful reversing the usual law-trumps-morality-trumps-axiology order, 
since the whole point of having more than one system is that we expect the systems to disagree and we 
want to suppress those disagreements in order to solve important implementation and coordination problems.
But I also can’t deny that for enough gain, I’d reverse the order in a heartbeat. If someone told me 
that by breaking a promise to my friend (morality) I could cure all cancer forever (axiology), then f@$k 
my friend, and f@$k whatever social trust or community cohesion would be lost by the transaction.
```

<a name="#slack-and-deliberate-mediocrity"></a>
## Slack and deliberate mediocrity
([overview](#overview))

The basic idea of Slack comes from the [eponymous LW post](https://www.lesswrong.com/posts/yLLkWMDbC9ZNKbjDG/slack). Quotes I liked, or that made sense to me:

```markdown
Definition: Slack. The absence of binding constraints on behavior.
Poor is the person without Slack. Lack of Slack compounds and traps.

Slack means margin for error. You can relax.

Slack allows pursuing opportunities. You can explore. You can trade.

Slack prevents desperation. You can avoid bad trades and wait for better spots. You can be efficient.

Slack permits planning for the long term. You can invest.

Slack enables doing things for your own amusement. You can play games. You can have fun.

Slack enables doing the right thing. Stand by your friends. Reward the worthy. Punish the wicked. 
You can have a code.

Slack presents things as they are without concern for how things look or what others think. You can 
be honest. ...

Slack in project management is the time a task can be delayed without causing a delay to either 
subsequent tasks or project completion time. The amount of time before a constraint binds.

A slacker is one who has a lazy work ethic or otherwise does not exert maximum effort. They slack off. 
They refuse to be bound by what others view as hard constraints.
```

On things being Out To Get You:

```markdown
Many things in this world are Out to Get You. Often they are Out to Get You for a lot, usually 
but not always your time, attention and money.

If you Get Got for compact amounts too often, it will add up and the constraints will bind.

If you Get Got even once for a non-compact amount, the cost expands until the you have no Slack 
left. The constraints bind you.

You might spend every spare minute and/or dollar on politics, advocacy or charity. You might think 
of every dollar as a fraction of a third-world life saved. Racing to find a cure for your daughter’s
cancer, you already work around the clock. You could have an all-consuming job or be a soldier 
marching off to war. It could be a quest for revenge, for glory, for love. Or you might spend every
spare minute mindlessly checking Facebook or obsessed with your fantasy football league.

You cannot relax. Your life is not your own.

It might even be the right choice! Especially for brief periods. When about to be run over by a truck
or evicted from your house, Slack is a luxury you cannot afford. Extraordinary times call for 
extraordinary effort.

Most times are ordinary. Make an ordinary effort.
```

Can you afford to lose Slack?

```markdown
No, you can’t. This is the most famous attack on Slack. Few words make me angrier.

The person who says “You Can Afford It” is saying to ignore constraints that do not bind you. If you 
do, all constraints soon bind you.

Those who do not value Slack soon lose it. Slack matters. Fight to keep yours!

Ask not whether you can afford it. Ask if it is Worth It.

Unless you can’t afford it. Affordability is invaluable negative selection. Never positive selection.

The You Can Afford It tax on Slack quickly approaches 100% if unchecked.

If those with extra resources are asked to share the whole surplus, all are poor or hide their wealth.
Wealth is a burden and makes you a target. Those visibly flush rush to spend their bounty.

Where those with free time are given extra work, all are busy or look busy. Those with copious free time
seek out relatively painless time sinks they can point to.

When looking happy means you deal with everything unpleasant, no one looks happy for long.
```

Venkat Rao's Maya Millennial is an example of someone who lacks Slack:

```markdown
Constraints bind her every action. Her job in life is putting up a front of the person she wants to 
show people that she wants to be. If her constraints noticeably failed to bind the illusion would fail.

Every action is being watched. If no one is around to watch her, the job falls to her. She must post 
all to Facebook, to Snapchat, to Instagram. Each action and choice signals who she is and her loyalty
to the system. Not doing that this time could mean missing her one chance to make it big.

Maya never has free time. There is signaling to do! At a minimum, she must spend such time on alert and
on her phone lest she miss something.

Maya never has spare cash. All must be spent to advance and fit her profile.

Maya lacks free speech, free association, free taste and free thought. All must serve.

Maya is in a world where she must signal she has no Slack. Slack means insufficient dedication and 
loyalty. Slack cannot be trusted. Slack now means slack later, which means failure. Future failure means 
no opportunity.
```

G Gordon Worley III comments on how Slack relates to distributed systems:

```markdown
If you work with distributed systems, by which I mean any system that must pass information between
multiple, tightly integrated subsystems, there is a well understood concept of maximum sustainable load
and we know that number to be roughly 60% of maximum possible load for all systems.

I don't have a link handy to show you the math, but the basic idea is that the probability that one 
subsystem will have to wait on another increases exponentially with the total load on the system and 
the load level that maximizes throughput (total amount of work done by the system over some period of
time) comes in just above 60%. If you do less work you are wasting capacity (in terms of throughput);
if you do more work you will gum up the works and waste time waiting even if all the subsystems are
always busy.

We normally deal with this in engineering contexts, but as is so often the case this property will hold 
for basically anything that looks sufficiently like a distributed system. Thus the "operate at 60% 
capacity" rule of thumb will maximize throughput in lots of scenarios: assembly lines, service-oriented
architecture software, coordinated work within any organization, an individual's work (since it is 
normally made up of many tasks that information must be passed between with the topology being spread
out over time rather than space), and perhaps most surprisingly an individual's mind-body.

"Slack" is a decent way of putting this, but we can be pretty precise and say you need ~40% slack to
optimize throughput: more and you tip into being "lazy", less and you become "overworked".
```

Some things that give Slack also take it away, per commenter elizabeth:

```markdown
The obvious example is cell phones. Especially at first they gave slack by letting you leave the house 
while you were waiting for an important phone call, but eventually ate it by creating an expectation 
that you'd always be available.
```

ialdabaoth contends that "this is because social structures strive to keep slack homeostatic at your level. As soon as you have more slack than you need to service your superiors in the social hierarchy, they will take that slack for themselves" but I'm not convinced of this argument. 

It's possible to have too much Slack -- I relate to this, as someone who's always subconsciously optimized for Slack myself. Per JacekLach:

```markdown
I often find myself with free time, and 'waste it away'. I don't really do anything on most weekends.
Having more constraints as guidance for behaviour in free time could likely remediate that; but I seem 
to be very good at talking myself out of any recurrent commitments, saying that they would reduce my 
freedom/flexibility/slack.

At the same time, it seems to me that I'm happiest, most 'alive', most in the 'flow', in situations with
exactly the kind of binding constraints this post talks of avoiding. The constraints focus you on the 
present, on the very moment, on being. For me this is clearest in sailing regattas - a clear purpose that
acts as a binding constraint (to go as fast as possible while staying safe - a safety margin does not for 
slack make, since you are not willing to ignore crossing it), consuming all your attention (at least during
the time you're responsible for the ship, and often more).

I suppose one can stretch the metaphor and say that having no slack on too many dimensions is likely to 
squash you; but having slack everywhere leaves you floating around aimlessly. Keeping most constraints 
slack and choosing only a couple aligned ones to bind against is possibly a way to find purpose.
```

Frustrated-demiurge talks about the same concept in her post [Affordance widths](https://frustrateddemiurge.tumblr.com/post/144927712238/affordance-widths). I *think* Venkat Rao talks about this same thing too in [this post](https://www.ribbonfarm.com/2019/03/07/mediocratopia-3/), except he comes at it from a different angle. 

```markdown
There is a paradox at the heart of mediocrity studies: excellence is not actually exceptional. If 
you see an excellent behavior or thing, it’s likely to be a middling instance at its level. The 
perception of exceptionalism is an illusion caused by inappropriate comparisons: you think it is a
99 percentile example of Level 3 performance, but it’s really a median example of Level 4 performance.

Changing levels of performance is self-disruption. The moment you hit, say, the 60% performance 
point on the current S-curve of learning, you start looking for ways to level up. This is the basic 
point in Daniel F. Chambliss’ classic paper, The Mundanity of Excellence. People who rise through 
the levels of a competitive sport do so by making discrete qualitative changes to level up before 
they hit diminishing returns from the current level. This process of leveling up, has less to do 
with striving for excellence in the sense of exceptional performance, and more to do with repeatedly
growing past limits. The visibly excellent are never at a local optimum.

In Age of Speed, skier Vince Poscente claims he won primarily by practicing his skills at a level 
above the one he was competing at. So during actual competition, he could win with less than 100% 
effort.

Making winning a habit is about making sure you’re always operating at a level where you have slack;
where you are in fact mediocre. If you’re being pushed towards excellence, it’s time to find a new 
level.
```

"Leveling up before hitting diminishing returns reminds me of another great essay I recently read, Eugene Wei's [Invisible Asymptotes](https://www.eugenewei.com/blog/2018/5/21/invisible-asymptotes) post from his blog [Remains of the Day](https://www.eugenewei.com/). It's pretty long, but full of great stuff. The relevant part is this:

```markdown
Every successful business goes through the famous S-curve, and most companies, and their investors,
spend a lot of time looking for that inflection point towards hockey-stick growth. But just as 
important, and perhaps less well studied, is that unhappy point later in the S-curve, when you hit
a shoulder and experience a flattening of growth. ...

For so many startups and even larger tech incumbents, the point at which they hit the shoulder in
the S-curve is a mystery, and I suspect the failure to see it occurs much earlier. The good thing is
that identifying the enemy sooner allows you to address it. We focus so much on product-market fit,
but once companies have achieved some semblance of it, most should spend much more time on the 
problem of product-market unfit.

For me, in strategic planning, the question in building my forecast was to flush out what I call the
invisible asymptote: a ceiling that our growth curve would bump its head against if we continued down
our current path. It's an important concept to understand for many people in a company, whether a CEO, 
a product person, or, as I was back then, a planner in finance. ...

An obvious problem for many companies, however, is that they are creating new types of businesses and 
services that don't lend themselves to easily identifying such invisible asymptotes. Many are not like
Amazon where there are readily tracked metrics like the size of the global book market with which to
peg their TAM (total addressable market).

Some of the limits to their growth are easier to spot than others. For messaging and some more general
social networking apps, for example, in many cases network effects are geographical. Since these apps 
build on top of real-world social graphs, and many of those are geographically clustered, there are 
winner-take-all dynamics such that in many countries one messaging app dominates, like Kakao in Korea 
or Line in Taiwan. There can be geo-political considerations, too, that help ensure that that WeChat 
will dominate in China to the exclusion of all competitors, for example.

For others, though, it takes a bit more product insight, and some might say intuition, to see the 
ceiling before you bump into it. For both employees and investors, understanding product-market unfit 
follows very closely on identifying product-market fit as an existential challenge.
```

<a name="#moloch"></a>
## Moloch
([overview](#overview))

Like LW commenter Quinn, I had difficulty summarizing Scott Alexander's celebrated essay *Moloch*, even though it was one of the most impactful pieces I've ever read. So I appreciate that he's conveniently summarized it SparkNotes-style under Stuart Armstrong's [essay](https://www.lesswrong.com/posts/otES8gdmFszCvZiRy/moloch-optimisation-and-vs-or-information-and-sacrificial):

```markdown
Intro - no real content.

Moloch as coordination failure: everyone makes a sacrifice to optimize for a zero-sum 
competition,ends up with the same relative status, but worse absolute status.

10 examples: 
- Prisoner's Dilemma, 
- dollar auctions, 
- fish-farming story (tragedy of the commons), 
- Malthusian trap, 
- ruthless/exploitative Capitalist markets, 
- the two-income trap, 
- agriculture, 
- arms races, 
- cancer, 
- political race to the bottom (lowering taxes to attract business)

4 partial examples: 
- inefficient education, 
- inefficient science, 
- government corruption (corporate welfare), 
- Congress (representatives voting against good of nation for good of constituency)

Existing systems are created by incentive structures, not agents, e.g. Las Vegas caused by 
a known bias in human reward circuitry, not optimization for human values.

But sometimes we move uphill anyway. Possible explanations:

- Excess resources / we are in the dream time and can afford non-competitive behavior.
- Physical limitations to what can be sacrificed
- Economic competition actually producing positive utility for consumers (but this is fragile)
- Coordination, e.g. via governments, guilds, friendships, etc.

Technology/ingenuity creates new opportunities to fall into such traps: 
- Technology overcomes physical limitations, consumes excess resources. 
- Automation further decouples economic activity from human values. 
- Technology can improve coordination, but can also exacerbate existing conflicts by giving all 
sides more power.

AGI opens up whole new worlds of traps: 
- Yudkowsky's paperclipper, 
- Hanson's subsistence-level ems, 
- Bostrom's Disneyland with no children.

6 & 7. Gnon - basically the god of the conservative scarcity mindset. Nick Land advocates 
compliance; Nyan wants to capture Gnon and build a walled garden. Scott warns that Moloch is 
far more terrifying than Gnon and will kill both of them anyway.

8 & 9. So we have to kill this Moloch guy, by lifting a better God to Heaven (Elua).
```

Wei Dai points out that this is captured by the standard academic notion of [positional good](http://en.wikipedia.org/wiki/Positional_good). Robert Frank, in [an article on higher ed](https://net.educause.edu/ir/library/pdf/ffp0001s.pdf), calls Moloch a "positional arms race":

```markdown
Participants in virtually all winner-take-all markets face strong incentives to invest in performance
enhancement, thereby to increase their chances of coming out ahead. As in the classic military arms 
race, however, many such investments prove mutually offsetting in the end. When each nation spends more
on bombs, the balance of power is no different than if none had spent more. Yet that fact alone provides
no escape for individual participants. Countries may find it burdensome to spend a lot on bombs, but the 
alternative—to be less well-armed than their rivals—is even worse.

In light of the growing importance of rank in the education marketplace, universities face increasing 
pressure to bid for the various resources that facilitate the quest for high rank. These pressures have 
spawned a positional arms race that already has proved extremely costly, and promises to become more so.
```

<a name="#Ra"></a>
## Ra
([overview](#overview))	

Every time someone mentions Harvard, or McKinsey, or even Google, I think of Sarah Constantin's [Ra](https://srconstantin.wordpress.com/2016/10/20/ra/). 

A quick sketch:

```markdown
The Egyptian god Ra was a symbol of divine kingship, all-powerful and all-seeing.  
He’s a good metaphor for a certain kind of psychological phenomenon that involves 
thought distortions around authority and legitimacy.

The Establishment is primarily an upper-class phenomenon, that it is more about 
social and moral legitimacy than mere wealth or raw power, and that it is *boringly
evil* — it produces respectable, normal, right-thinking, mild-mannered people who 
do things with very bad consequences.

It’s like a dissipating, entropic motion, a process that corrupts institutions.

Ra is something like a psychological mindset, that causes people to actually 
*seek* corruption and confusion, and to *prefer corruption for its own sake* — 
though, of course, it doesn’t feel quite like that from the inside.

Ra is a specific kind of glitch in intuition, which can roughly be summarized as 
*the drive to idealize vagueness and despise clarity*.  

As forces in the human psyche go, Ra is a pretty mild one. It’s not a powerful 
biological drive like aggression, or a difficult-to-treat problem like depression,
or a highly optimized energy-saving structure like the standard cognitive biases.

Ra is hard to pin down, but vulnerable to open communication and introspection.  
If you can talk and think about what you want, or how you feel, or why you believe
what you do, and you don’t dodge the question, Ra will dissolve like mist. 

Ra is hard to see, but easy to overcome once you see it.
```

What is Ra *not*?

```markdown
The usual pitfall when using poetic language to define egregores is making them too broad.
There is not one root of all evil that causes all the ills of the world.

Ra is not simply conformity, simply authoritarianism, or simply power-seeking.  Ra is not
the same as “bureaucracy” or “capitalism” or “fallen human nature” or all the myriad reasons
why your idealistic goal might fail.  Ra is not “everything that is wrong with people who
disagree with me.”

As a social phenomenon, Ra is responsible for some dysfunctions in the democratic modern 
West; it is not, for instance, what was going on with the Nazis, or with terrorists, or 
with communist revolutionaries, or with the Confederates in the American Civil War.  Ra 
is not driving people who want to take over the world for some fanatic goal. 

But it’s not *merely* the most commonly claimed drivers of institutional decay, like 
“knowledge problems” or “coordination problems”.  People who participate in those problems
*are* following rational self-interest, but wind up contributing individually to collectively
harmful outcomes.
```

Sarah goes on to define Ra extensionally. To summarize:

- Ra is about generic superlativity
- Ra is about legitimacy
- Ra defends itself with vagueness, confusion, incoherence — and then ange
- Ra hates communication and introspection
- Ra is fake Horus
- Ra corresponds to a stage in the corruption of organizations
- Ra is easy to overcome

<a name="#Legibility"></a>
## Legibility
([overview](#overview))	
	
The community forum *The Scholar's Stage* has a great post, [Tradition is Smarter Than You Are](http://scholars-stage.blogspot.com/2018/08/tradition-is-smarter-than-you-are.html), that gives a couple examples of tradition-as-Chesterton's-fence. It begins like so:

```markdown
Brain-power alone is not enough to explain why humans are such a successful species. Humans, he 
(evolutionary anthropologist-cum-cross cultural psychologist Joseph Henrich) argues, are not nearly
as intelligent as we think they are. Remove them from the culture and environment they have learned 
to operate in and they fail quickly. His favorite example of this are European explorers who die in
the middle of deserts, jungles, or arctic wastes even though thousands of generations of hunter-
gatherers were able to survive and thrive in these same environments. If human success was due to our
ability to problem solve, analyze, and rationally develop novel solutions to novel challenges, the 
explorers should have been fine. Their ghastly fates suggest that rationality may not be the key to
human survival.
```
 
The key is cultural evolution. An example via the cassava plant, or manioc, from Heinrich's book [*The Secret of Our Success*](https://amzn.to/2LuDcEh):

```markdown
In the Americas, where manioc was first domesticated, societies who have relied on bitter varieties
for thousands of years show no evidence of chronic cyanide poisoning. In the Colombian Amazon, for
example, indigenous Tukanoans use a multistep, multiday processing technique that involves scraping,
grating, and finally washing the roots in order to separate the fiber, starch, and liquid. Once
separated, the liquid is boiled into a beverage, but the fiber and starch must then sit for two more
days, when they can then be baked and eaten. Figure 7.1 shows the percentage of cyanogenic content in
the liquid, fiber, and starch remaining through each major step in this processing. 

Such processing techniques are crucial for living in many parts of Amazonia, where other crops are 
difficult to cultivate and often unproductive. However, despite their utility, one person would have
a difficult time figuring out the detoxification technique. Consider the situation from the point of
view of the children and adolescents who are learning the techniques. They would have rarely, if ever,
seen anyone get cyanide poisoning, because the techniques work. And even if the processing was
ineffective, such that cases of goiter (swollen necks) or neurological problems were common, it would
still be hard to recognize the link between these chronic health issues and eating manioc. Most people
would have eaten manioc for years with no apparent effects. Low cyanogenic varieties are typically 
boiled, but boiling alone is insufficient to prevent the chronic conditions for bitter varieties. 
Boiling does, however, remove or reduce the bitter taste and prevent the acute symptoms (e.g., diarrhea,
stomach troubles, and vomiting). 

So, if one did the common-sense thing and just boiled the high-cyanogenic manioc, everything would seem
fine. Since the multistep task of processing manioc is long, arduous, and boring, sticking with it is
certainly non-intuitive. Tukanoan women spend about a quarter of their day detoxifying manioc, so this
is a costly technique in the short term. Now consider what might result if a self-reliant Tukanoan
mother decided to drop any seemingly unnecessary steps from the processing of her bitter manioc. She 
might critically examine the procedure handed down to her from earlier generations and conclude that 
the goal of the procedure is to remove the bitter taste. She might then experiment with alternative 
procedures by dropping some of the more labor-intensive or time-consuming steps. She’d find that with
a shorter and much less labor-intensive process, she could remove the bitter taste. Adopting this easier
protocol, she would have more time for other activities, like caring for her children. Of course, years
or decades later her family would begin to develop the symptoms of chronic cyanide poisoning. 

Thus, the unwillingness of this mother to take on faith the practices handed down to her from earlier 
generations would result in sickness and early death for members of her family. Individual learning does
not pay here, and intuitions are misleading. The problem is that the steps in this procedure are causally
opaque—an individual cannot readily infer their functions, interrelationships, or importance. The causal
opacity of many cultural adaptations had a big impact on our psychology. 

Wait. Maybe I’m wrong about manioc processing. Perhaps it’s actually rather easy to individually figure
out the detoxification steps for manioc? Fortunately, history has provided a test case. At the beginning
of the seventeenth century, the Portuguese transported manioc from South America to West Africa for the 
first time. They did not, however, transport the age-old indigenous processing protocols or the underlying
commitment to using those techniques. Because it is easy to plant and provides high yields in infertile 
or drought-prone areas, manioc spread rapidly across Africa and became a staple food for many populations.
The processing techniques, however, were not readily or consistently regenerated. Even after hundreds of
years, chronic cyanide poisoning remains a serious health problem in Africa. Detailed studies of local 
preparation techniques show that high levels of cyanide often remain and that many individuals carry low
levels of cyanide in their blood or urine, which haven’t yet manifested in symptoms. In some places,
there’s no processing at all, or sometimes the processing actually increases the cyanogenic content. On 
the positive side, some African groups have in fact culturally evolved effective processing techniques, 
but these techniques are spreading only slowly.

The point here is that cultural evolution is often much smarter than we are. Operating over generations 
as individuals unconsciously attend to and learn from more successful, prestigious, and healthier members
of their communities, this evolutionary process generates cultural adaptations. Though these complex 
repertoires appear well designed to meet local challenges, they are not primarily the products of 
individuals applying causal models, rational thinking, or cost-benefit analyses. Often, most or all of
the people skilled in deploying such adaptive practices do not understand how or why they work, or even 
that they “do” anything at all. Such complex adaptations can emerge precisely because natural selection
has favored individuals who often place their faith in cultural inheritance—in the accumulated wisdom 
implicit in the practices and beliefs derived from their forbearers—over their own intuitions and 
personal experiences.
```

Another example from northern Canada, where Naskapi foragers hunt caribou:

```markdown
When hunting caribou, Naskapi foragers in Labrador, Canada, had to decide where to go. Common sense might
lead one to go where one had success before or to where friends or neighbors recently spotted caribou. 
However, this situation is like Matching Pennies in chapter 2. The caribou are mismatchers and the 
hunters are matchers. That is, hunters want to match the locations of caribou while caribou want to 
mismatch the hunters, to avoid being shot and eaten. If a hunter shows any bias to return to previous 
spots, where he or others have seen caribou, then the caribou can benefit (survive better) by avoiding
those locations (where they have previously seen humans). 

Thus, the best hunting strategy requires randomizing. Can cultural evolution compensate for our 
cognitive inadequacies? Traditionally, Naskapi hunters decided where to go to hunt using divination and 
believed that the shoulder bones of caribou could point the way to success. To start the ritual, the shoulder
blade was heated over hot coals in a way that caused patterns of cracks and burnt spots to form. This 
patterning was then read as a kind of map, which was held in a pre-specified orientation. The cracking 
patterns were (probably) essentially random from the point of view of hunting locations, since the outcomes 
depended on myriad details about the bone, fire, ambient temperature, and heating process. Thus, these 
divination rituals may have provided a crude randomizing device that helped hunters avoid their own
decision-making biases. The undergraduates in the Matching Pennies game could have used a randomizing 
device like divination, though the chimps seem fine without it.
```

There's a similar practice in Indonesia employed by the Kantus of Kalimantan, who use bird augury to select locations for their agricultural plots:

```markdown
The anthropologist Michael Dove argues that two factors will cause farmers to make plot placements
that are too risky. First, Kantu ecological models contain the Gambler’s Fallacy and lead them to 
expect that floods will be less likely to occur in a specific location after a big flood in that 
location (which is not true). 

Second, as with the MBAs’ investment allocations in chapter 4, Kantus pay attention to others’ 
success and copy the choices of successful households, meaning that if one of their neighbors has
a good yield in an area one year, many other people will want to plant there in the next year. 
Reducing the risks posed by these cognitive and decision-making biases, the Kantu rely on a system
of bird augury that effectively randomizes their choices for locating garden plots, which helps them
avoid catastrophic crop failures. The results of divination depend not only on seeing a particular
bird species in a particular location, but also on what type of call the bird makes (one type of call 
may be favorable, and another unfavorable). 

The patterning of bird augury supports the view that this is a cultural adaptation. The system seems 
to have evolved and spread throughout this region since the seventeenth century when rice cultivation
was introduced. This makes sense, since it is rice cultivation that is most positively influenced by
randomizing garden locations. It’s possible that, with the introduction of rice, a few farmers began
to use bird sightings as an indication of favorable garden sites. On average, over a lifetime, these
farmers would do better—be more successful—than farmers who relied on the Gambler’s Fallacy or on 
copying others’ immediate behavior. 

Whatever the process, within 400 years, the bird augury system had spread throughout the agricultural
populations of this Borneo region. Yet it remains conspicuously missing or underdeveloped among local
foraging groups and recent adopters of rice agriculture, as well as among populations in northern 
Borneo who rely on irrigation. So, bird augury has been systematically spreading in those regions
where it is most adaptive. This example makes a key point: not only do people often not understand
what their cultural practices are doing, but sometimes it may even be important that they don’t
understand what their practices are doing or how they work. If people came to understand that bird 
augury or bone divination didn’t actually predict the future, the practice would probably be dropped
or people would increasingly ignore ritual findings in favor of their own intuitions.
```

There are two arguments Heinrich is making here:

```markdown
The first is that customs, traditions, and the like are subject to Darwinian selection. Henrich is not
always clear on exactly what is being selected for—is it individuals who follow a tradition, groups 
whose members all follow the tradition, or the tradition itself?—but the general gist is that traditions
stick around longest when they are adaptive. 

This process is "blind." Those who follow the traditions do not know how they work, and in some cases
(like religious rituals that build social solidarity) knowing the details of how they work might actually
reduce the efficacy of the tradition. That is the second argument of note: we do not (and often cannot)
understand just how the traditions we inherit help our survival, and because of that, it is difficult to
artificially create replacements. 
```

This, of course, jives perfectly with the work of James C. Scott. Here's *The Scholar's* summary intro:

```markdown
Scott has spent a large amount of his career studying the way states shape the societies they rule over, 
and the way societies try to resist the advance of the state. The central problem of ruler-ship, as Scott
sees it, is what he calls *legibility*. To extract resources from a population the state must be able to
understand that population. The state needs to make the people and things it rules legible to agents of
the government. Legibility means uniformity. States dream up uniform weights and measures, impress national
languages and ID numbers on their people, and divvy the country up into land plots and administrative 
districts, all to make the realm legible to the powers that be. 

The problem is that not all important things can be made legible. Much of what makes a society successful
is knowledge of the tacit sort: rarely articulated, messy, and from the outside looking in, purposeless. 
These are the first things lost in the quest for legibility. Traditions, small cultural differences, odd 
and distinctive lifeways—in other words, the products of cultural evolution that Henrich fills his book 
with—are all swept aside by a rationalizing state that preserves (or in many cases, imposes) only what it 
can be understood and manipulated from the 2,000 foot view. The result, as Scott chronicles with example
after example, are many of the greatest catastrophes of human history. 
```

That's a pretty good summary, but I prefer Scott Alexander's more verbose treatment in his [book review](https://slatestarcodex.com/2017/03/16/book-review-seeing-like-a-state/) of James' book, because microhumor and just *likable* storytelling. 

Scott (SA, not JCS) begins with a suspicious observation:

```markdown
Scott starts with the story of “scientific forestry” in 18th century Prussia. Enlightenment
rationalists noticed that peasants were just cutting down whatever trees happened to grow in the
forests, *like a chump*. They came up with a better idea: clear all the forests and replace them 
by planting identical copies of Norway spruce (the highest-lumber-yield-per-unit-time tree) in 
an evenly-spaced rectangular grid. Then you could just walk in with an axe one day and chop down 
like a zillion trees an hour and have more timber than you could possibly ever want.

This went poorly. The impoverished ecosystem couldn’t support the game animals and medicinal 
herbs that sustained the surrounding peasant villages, and they suffered an economic collapse. 
The endless rows of identical trees were a perfect breeding ground for plant diseases and forest
fires. And the complex ecological processes that sustained the soil stopped working, so after a
generation the Norway spruces grew stunted and malnourished. Yet for some reason, everyone
involved got promoted, and “scientific forestry” spread across Europe and the world.
```

"Evenly-spaced rectangular grids" will become a suspiciously repeating theme, "not just in biological systems but also in social ones":

```markdown
Natural organically-evolved cities tend to be densely-packed mixtures of dark alleys, tiny 
shops, and overcrowded streets. Modern scientific rationalists came up with a better idea: 
an evenly-spaced rectangular grid of identical giant Brutalist apartment buildings separated 
by wide boulevards, with everything separated into carefully-zoned districts. Yet for some 
reason, whenever these new rational cities were built, people hated them and did everything 
they could to move out into more organic suburbs. And again, for some reason the urban
planners got promoted, became famous, and spread their destructive techniques around the world.

Ye olde organically-evolved peasant villages tended to be complicated confusions of everybody
trying to raise fifty different crops at the same time on awkwardly shaped cramped parcels of 
land. Modern scientific rationalists came up with a better idea: giant collective mechanized 
farms growing purpose-bred high-yield crops and arranged in (say it with me) evenly-spaced
rectangular grids. Yet for some reason, these giant collective farms had lower yields per acre
than the old traditional methods, and wherever they arose famine and mass starvation followed.
And again, for some reason governments continued to push the more “modern” methods, whether it
was socialist collectives in the USSR, big agricultural corporations in the US, or sprawling 
banana plantations in the Third World.

Traditional lifestyles of many East African natives were nomadic, involving slash-and-burn 
agriculture in complicated jungle terrain according to a bewildering variety of ad-hoc rules. 
Modern scientific rationalists in African governments (both colonial and independent) came up
with a better idea – resettlement of the natives into villages, where they could have modern 
amenities like schools, wells, electricity, and evenly-spaced rectangular grids. Yet for some
reason, these villages kept failing: their crops died, their economies collapsed, and their 
native inhabitants disappeared back into the jungle. And again, for some reason the African 
governments kept trying to bring the natives back and make them stay, even if they had to blur
the lines between villages and concentration camps to make it work.
```

This raises the question: why did these schemes fail, and why were they still continued despite that? James' two-part answer is High Modernism in service of (this is the key insight) *legibilization of the world by centralized governing bodies to aid monitoring and control*, mostly for efficient taxation:

```markdown
The first part of the story is High Modernism, an aesthetic taste masquerading as a scientific
philosophy. The High Modernists claimed to be about figuring out the most efficient and high-
tech way of doing things, but most of them knew little relevant math or science and were 
basically just LARPing being rational by placing things in evenly-spaced rectangular grids.

But the High Modernists were pawns in service of a deeper motive: the centralized state wanted
the world to be “legible”, ie arranged in a way that made it easy to monitor and control. An 
intact forest might be more productive than an evenly-spaced rectangular grid of Norway spruce,
but it was harder to legislate rules for, or assess taxes on.

The state promoted the High Modernists’ platitudes about The Greater Good as cover, in order to
implement the totalitarian schemes they wanted to implement anyway. The resulting experiments 
were usually failures by the humanitarian goals of the Modernists, but resounding successes by 
the command-and-control goals of the state. And so we gradually transitioned from systems that
were messy but full of fine-tuned hidden order, to ones that were barely-functional but really
easy to tax.
```

The problem that legibilization solves is best illustrated by a parable:

```markdown
Suppose you’re a premodern king, maybe one of the Louises who ruled France in the Middle Ages.
You want to tax people to raise money for a Crusade or something. Practically everyone in your 
kingdom is a peasant, and all the peasants produce is grain, so you’ll tax them in grain.
Shouldn’t be too hard, right? You’ll just measure how many pints of grain everyone produces, and…

	The pint in eighteenth-century Paris was equivalent to 0.93 liters, whereas in Seine-en-
	Montane it was 1.99 liters and in Precy-sous-Thil, an astounding 3.33 liters. The aune, 
	a measure of length used for cloth, varied depending on the material(the unit for silk, 
	for instance, was smaller than that for linen) and across France there were at least 
	seventeen different aunes.
	
Okay, this is stupid. Just give everybody evenly-sized baskets, and tell them that baskets are
the new unit of measurement.

	Virtually everywhere in early modern Europe were endless micropolitics about how baskets 
	might be adjusted through wear, bulging, tricks of weaving, moisture, the thickness of the
	rim, and so on. In some areas the local standards for the bushel and other units of
	measurement were kept in metallic form and placed in the care of a trusted official or else
	literally carved into the stone of a church or the town hall. Nor did it end there. How the
	grain was to be poured (from shoulder height, which packed it somewhat, or from waist height?),
	how damp it could be, whether the container could be shaken down, and finally, if and how it
	was to be leveled off when full were subjects of long and bitter controversy.
	
Huh, this medieval king business is harder than you thought. Maybe you can just leave this problem to 
the feudal lords?

	Thus far, this account of local measurement practices risks giving the impression that, 
	although local conceptions of distance, area, volume, and so on were different from and
	more varied than the unitary abstract standards a state might favor, they were nevertheless
	aiming at objective accuracy. This impression would be false. […]

	A good part of the politics of measurement sprang from what a contemporary economist might 
	call the “stickiness” of feudal rents. Noble and clerical claimants often found it difficult
	to 	increase feudal dues directly; the levels set for various charges were the result of
	long struggle, and even a small increase above the customary level was viewed as a threatening
	breach of tradition. Adjusting the measure, however, represented a roundabout way of achieving
	the same end.

	The local lord might, for example, lend grain to peasants in smaller baskets and insist on 
	repayment in larger baskets. He might surreptitiously or even boldly enlarge the size of the
	grain sacks accepted for milling (a monopoly of the domain lord) and reduce the size of the
	sacks used for measuring out flour; he might also collect feudal dues in larger baskets and
	pay wages in kind in smaller baskets. While the formal custom governing feudal dues and wages 
	would thus remain intact (requiring, for example, the same number of sacks of wheat from the
	harvest of a given holding), the actual transaction might increasingly favor the lord. The
	results of such fiddling were far from trivial. Kula estimates that the size of the bushel
	(boisseau) used to collect the main feudal rent (taille) increased by one-third between 1674
	and 1716 as part of what was called the reaction feodale.
	
Okay, but nobody’s going to make too big a deal about this, right?

	This sense of victimization [over changing units of measure] was evident in the cahiers of 
	grievances prepared for the meeting of the Estates General just before the Revolution. […]
	In an unprecedented revolutionary context where an entirely new political system was being
	created from first principles, it was surely no great matter to legislate uniform weights 
	and measures. As the revolutionary decree read “The centuries old dream of the masses of
	only one just measure has come true! The Revolution has given the people the meter!”	
	
Maybe you should tax land. After all, it’s the land that grows the grain. Just figure out how much
land everybody owns, and you can calculate some kind of appropriate tax from there.

So, uh, peasant villagers, how much land does each of you own?

	A hypothetical case of customary land tenure practices may help demonstrate how difficult
	it is to assimilate such practices to the barebones scheme of a modern cadastral map 
	[land survey suitable for tax assessment][…]

	Let us imagine a community in which families have usufruct rights to parcels of cropland
	during the main growing season. Only certain crops, however, may be planted, and every 
	seven years the usufruct land is distributed among resident families according to each 
	family’s size and its number of able-bodied adults. After the harvest of the main-season
	crop, all cropland reverts to common land where any family may glean, graze their fowl and
	livestock, and even plant quickly maturing, dry-season crops. Rights to graze fowl and
	livestock on pasture-land held in common by the village is extended to all local families, 
	but the number of animals that can be grazed is restricted according to family size, 
	especially in dry years when forage is scarce. Families not using their grazing rights can
	give them to other villagers but not to outsiders. Everyone has the right to gather 
	firewood for normal family needs, and the village blacksmith and baker are given larger
	allotments. No commercial sale from village woodlands is permitted.

	Trees that have been planted and any fruit they may bear are the property of the family 
	who planted them, no matter where they are now growing. Fruit fallen from such tree, however,
	is the property of anyone who gathers it. When a family fells one of its trees or a tree is
	felled by a storm, the trunk belongs to the family, the branches to the immediate neighbors, 
	and the “tops” (leaves and twigs) to any poorer villager who carries them off. Land is set
	aside for use or leasing out by widows with children and dependents of conscripted males.
	Usufruct rights to land and trees may be let to anyone in the village; the only time they
	may be let to someone outside the village is if no one in the community wishes to claim 
	them. After a crop failure leading to a food shortage, many of these arrangements are
	readjusted.

You know what? I’m just going to put you all down as owning ten. Ten land. Everyone okay with that?
Cool. Let’s say ten land for everyone and just move on to the next village.

	Novoselok village had a varied economy of cultivation, grazing, and forestry…the complex
	welter of strips was designed to ensure that each village household received a strip of 
	land in every ecological zone. An individual household might have as many as ten to 
	fifteen different plots constituting something of a representative sample of the village’s
	ecological zones and microclimates. The distribution spread a family’s risks prudently, 
	and from time to time the land was reshuffled as families grew or shrunk…The strips of
	land were generally straight and parallel so that a readjustment could be made by moving
	small stakes along just one side of a field, without having to think of areal dimensions.
	Where the other side of the field was not parallel, the stakes could be shifted to 
	compensate for the fact that the strip lay toward the narrower or wider end of the field.
	Irregular fields were divided, not according to area, but according to yield.

…huh. Maybe this isn’t going to work. Let’s try it the other way around. Instead of mapping land,
we can just get a list with the name of everyone in the village, and go from there.

	Only wealthy aristocrats tended to have fixed surnames…Imagine the dilemma of a tithe or
	capitation-tax collector [in England] faced with a male population, 90% of whom bore just
	six Christian names (John, William, Thomas, Robert, Richard, and Henry).

Okay, fine. That won’t work either. Surely there’s something else we can do to assess a tax burden
on each estate. Think outside the box, scrape the bottom of the barrel!

	The door-and-window tax established in France [in the 18th century] is a striking case in 
	point. Its originator must have reasoned that the number of windows and doors in a dwelling
	was proportional to the dwelling’s size. Thus a tax assessor need not enter the house or 
	measure it, but merely count the doors and windows.

	As a simple, workable formula, it was a brilliant stroke, but it was not without consequences.
	Peasant dwellings were subsequently designed or renovated with the formula in mind so as to
	have as few openings as possible. While the fiscal losses could be recouped by raising the tax
	per opening, the long-term effects on the health of the population lasted for more than a century.	
```

Notice that this is totally in keeping with [reality having a surprising amount of detail](#Reality-has-a-surprising-amount-of-detail), but on top of that there's all this adversarial stuff going on -- feudal rent-seeking and its avoidance, fairness, politicization of measurement, etc.  

Another issue is that the relative illegibility of early cities to outsides granted locals a vital margin of political safety from outside control, as can be illustrated by the simple heuristic of asking if an outsider needed a local guide to navigate; centralized states didn't like this:

```markdown
Historically, the relative illegibility to outsiders of some urban neighborhoods has provided a 
vital margin of political safety from control by outside elites. A simple way of determining whether
this margin exists is to ask if an outsider would have needed a local guide in order to find her way 
successfully. If the answer is yes, then the community or terrain in question enjoys at least a small
measure of insulation from outside intrusion. Coupled with patterns of local solidarity, this 
insulation has proven politically valuable in such disparate contexts as eighteenth-and early 
nineteenth-century urban riots over bread prices in Europe, the Front de Liberation Nationale’s 
tenacious resistance to the French in the Casbah of Algiers, and the politics of the bazaar that 
helped to bring down the Shah of Iran. Illegibility, then, has been and remains a reliable resource
for political autonomy.
```

Anyway, *that's* what legibilization solves:

```markdown
The moral of the story is: premodern states had very limited ability to tax their citizens 
effectively. Along with the problems mentioned above – nonstandardized measurement, 
nonstandardized property rights, nonstandardized personal names – we can add a few others. 
At this point national languages were a cruel fiction; local “dialects” could be as different
from one another as eg Spanish is from Portuguese, so villagers might not even be able to
understand the tax collectors. Worst of all, there was no such thing as a census in France
until the 17th century, so there wasn’t even a good idea of how many people or villages there
were.

Kings usually solved this problem by leaving the tax collection up to local lords, who 
presumably knew the idiosyncracies of their own domains. But one step wasn’t always enough. 
If the King only knew Dukes, and the Dukes only knew Barons, and the Barons only knew village
headmen, and it was only the village headmen who actually knew anything about the peasants, 
then you needed a four-step chain to get any taxes. Each link in the chain had an incentive to
collect as much as they could and give up as little as they could get away with. So on the one
end, the peasants were paying backbreaking punitive taxes. And on the other, the Royal Treasurer
was handing the King half a loaf of moldy bread and saying “Here you go, Sire, apparently this 
is all the grain in France.”

So from the beginning, kings had an incentive to make the country “legible” – that is, so
organized and well-indexed that it was easy to know everything about everyone and collect/double-
check taxes. Also from the beginning, nobles had an incentive to frustrate the kings so that they
wouldn’t be out of a job. And commoners, who figured that anything which made it easier for the 
State to tax them and interfere in their affairs was bad news, usually resisted too.
```

Resistance against legibilization was intense, but centralized states gradually pushed outwards from their capitals iteratively, honing their techniques as they went. Here's what happened in the context of surnames:

```markdown
Peasants didn’t like permanent surnames. Their own system was quite reasonable for them: John the
baker was John Baker, John the blacksmith was John Smith, John who lived under the hill was John 
Underhill, John who was really short was John Short. The same person might be John Smith and John
Underhill in different contexts, where his status as a blacksmith or place of origin was more 
important.

But the government insisted on giving everyone a single permanent name, unique for the village, and 
tracking who was in the same family as whom. Resistance was intense:

	What evidence we have suggests that second names of any kind became rare as distance from the state’s
	fiscal reach increased. Whereas one-third of the households in Florence declared a second name, the
	proportion dropped to one-fifth for secondary towns and to one-tenth in the countryside. It was not
	until the seventeenth century that family names crystallized in the most remote and poorest areas of
	Tuscany – the areas that would have had the least contact with officialdom. […]

	State naming practices, like state mapping practices, were inevitably associated with taxes (labor,
	military service, grain, revenue) and hence aroused popular resistance. The great English peasant 
	rising of 1381 (often called the Wat Tyler Rebellion) is attributed to an unprecedented decade of
	registration and assessments of poll taxes. For English as well as for Tuscan peasants, a census of
	all adult males could not but appear ominous, if not ruinous.

The same issues repeated themselves a few hundred years later when Europe started colonizing other
continents. Again they encountered a population with naming systems they found unclear and unsuitable 
to taxation. But since colonial states had more control over their subjects than the relatively weak
feudal monarchies of the Middle Ages, they were able to deal with it in one fell swoop, sometimes
comically so:

Nowhere is this better illustrated than in the Philippines under the Spanish. Filipinos were instructed
by the decree of November 21, 1849 to take on permanent Hispanic surnames. […]

	Each local official was to be given a supply of surnames sufficient for his jurisdiction, “taking
	care that the distribution be made by letters of the alphabet.” In practice, each town was given
	a number of pages from the alphabetized [catalog], producing whole towns with surnames beginning
	with the same letter. In situations where there has been little in-migration in the past 150 years,
	the traces of this administrative exercise are still perfectly visible across the landscape. “For
	example, in the Bikol region, the entire alphabet is laid out like a garland over the provinces of
	Albay, Sorsogon, and Catanduanes which in 1849 belonged to the single jurisdiction of Albay. 
	Beginning with A at the provincial capital, the letters B and C mark the towns along the cost 
	beyond Tabaco to Wiki. We return and trace along the coast of Sorosgon the letters E to L, then 
	starting down the Iraya Valley at Daraga with M, we stop with S to Polangui and Libon, and finish
	the alphabet with a quick tour around the island of Catanduas.

	The confusion for which the decree is the antidote is largely that of the administrator and the tax
	collector. Universal last names, they believe, will facilitate the administration of justice, finance,
	and public order as well as make it simpler for prospective marriage partners to calculate their 
	degree of consanguinity. For a utilitarian state builder of [Governor] Claveria’s temper, however, the 
	ultimate goal was a complete and legible list of subjects and taxpayers.

This was actually a lot less cute and funny than the alphabetization makes it sound:

	What if the Filipinos chose to ignore their new last names? This possibility had already crossed 
	Claveria’s mind, and he took steps to make sure that the names would stick. Schoolteachers were
	ordered to forbid their students to address or even know one another by any name except the officially
	inscribed family name. Those teachers who did not apply the rule with enthusiasm were to be punished.
	More efficacious perhaps, given the minuscule school enrollment, was the proviso that forbade priests 
	and military and civil officials from accepting any document, application, petition, or deed that did 
	not use the official surnames. All documents using other names would be null and void.

Similar provisions ensured the replacement of local dialects with the approved national language. Students
were only allowed to learn the national language in school and were punished for speaking in vernacular. 
All formal documents had to be in the national language, which meant that peasants who had formally been 
able to manage their own legal affairs had to rely on national-language-speaking intermediaries. Scott
talks about the effect in France:

	One can hardly imagine a more effective formula for immediately devaluing local knowledge and 
	privileging all those who had mastered the official linguistic code. It was a gigantic shift in power.
	Those at the periphery who lacked competence in French were rendered mute and marginal. They were now 
	in need of a local guide to the new state culture, which appeared in the form of lawyers, notaries, 
	schoolteachers, clerks, and soldiers.
```

High Modernism, extensionally defined:

```markdown
- standardization, 
- Henry Ford, 
- the factory as metaphor for the best way to run everything, 
- conquest of nature, 
- New Soviet Man, 
- people with college degrees knowing better than you, 
- wiping away the foolish irrational traditions of the past, 
- Brave New World, 
- everyone living in dormitories and eating exactly 2000 calories of Standardized Food
  Product (TM) per day, 
- anything that is For Your Own Good, 
- gleaming modernist skyscrapers, 
- The X Of The Future, 
- complaints that the unenlightened masses are resisting The X Of The Future, 
- demands that if the unenlightened masses reject The X Of The Future they must be re-
  educated For Their Own Good, and (of course) 
- evenly-spaced rectangular grids.
```

James' description of why Brasilia was abandoned reminds me of Putrajaya, except for the latter they perhaps tried to do a hybrid of sorts to learn from the mistakes of the "Corbusierites":

```markdown
Most of those who have moved to Brasilia from other cities are amazed to discover “that it is a 
city without crowds.” People complain that Brasilia lacks the bustle of street life, that it has 
none of the busy street corners and long stretches of storefront facades that animate a sidewalk
for pedestrians. For them, it is almost as if the founders of Brasilia, rather than having planned
a city, have actually planned to prevent a city. The most common way they put it is to say that
Brasilia “lacks street corners,”by which they mean that it lacks the complex intersections of dense
neighborhoods comprising residences and public cafes and restaurants with places for leisure, work,
and shopping.

While Brasilia provides well for some human needs, the functional separation of work from residence
and of both from commerce and entertainment, the great voids between superquadra, and a road system
devoted exclusively to motorized traffic make the disappearance of the street corner a foregone
conclusion. The plan did eliminate traffic jams; it also eliminated the welcome and familiar 
pedestrian jams that one of Holston’s informants called "the point of social conviviality".

The term brasilite, meaning roughly Brasilia-itis,which was coined by the first-generation residents,
nicely captures the trauma they experienced. As a mock clinical condition, it connotes a rejection of
the standardization and anonymity of life in Brasilia. “They use the term brasilite to refer to their
feelings about a daily life without the pleasures-the distractions, conversations, flirtations, and
little rituals of outdoor life in other Brazilian cities.” Meeting someone normally requires seeing
them either at their apartment or at work. Even if we allow for the initial simplifying premise of 
Brasilia’s being an administrative city, there is nonetheless a bland anonymity built into the very 
structure of the capital. The population simply lacks the small accessible spaces that they could
colonize and stamp with the character of their activity, as they have done historically in Rio and
Sao Paulo. To be sure, the inhabitants of Brasilia haven’t had much time to modify the city through 
their practices, but the city is designed to be fairly recalcitrant to their efforts.

“Brasilite,” as a term, also underscores how the built environment affects those who dwell in it. 
Compared to life in Rio and Sao Paulo, with their color and variety, the daily round in bland,
repetitive, austere Brasilia must have resembled life in a sensory deprivation tank. The recipe for 
high-modernist urban planning, while it may have created formal order and functional segregation, did
so at the cost of a sensorily impoverished and monotonous environment-an environment that inevitably
took its toll on the spirits of its residents.

The anonymity induced by Brasilia is evident from the scale and exterior of the apartments that 
typically make up each residential superquadra. For superquadra residents, the two most frequent 
complaints are the sameness of the apartment blocks and the isolation of the residences (“In Brasilia,
there is only house and work”). The facade of each block is strictly geometric and egalitarian.
Nothing distinguishes the exterior of one apartment from another; there are not even balconies that 
would allow residents to add distinctive touches and create semipublic spaces.
```

It's useful to contrast High Modernist principles (as epitomized by the French architech Le Corbusier) with Jane Jacobs' critique of them. 

High Modernism:

```markdown
First, there can be no compromise with the existing infrastructure. It was designed by superstitious
people who didn’t have architecture degrees, or at the very least got their architecture degrees in
the past and so were insufficiently Modern. The more completely it is bulldozed to make way for the
Glorious Future, the better.

Second, human needs can be abstracted and calculated. A human needs X amount of food. A human needs 
X amount of water. A human needs X amount of light, and prefers to travel at X speed, and wants to 
live within X miles of the workplace. These needs are easily calculable by experiment, and a good 
city is the one built to satisfy these needs and ignore any competing frivolities.

Third, the solution is the solution. It is universal. The rational design for Moscow is the same as
the rational design for Paris is the same as the rational design for Chandigarh, India. As a 
corollary, all of these cities ought to look exactly the same. It is maybe permissible to adjust for
obstacles like mountains or lakes. But only if you are on too short a budget to follow the rationally
correct solution of leveling the mountain and draining the lake to make your city truly optimal.

Fourth, all of the relevant rules should be explicitly determined by technocrats, then followed to the
letter by their subordinates. Following these rules is better than trying to use your intuition, in 
the same way that using the laws of physics to calculate the heat from burning something is better than
just trying to guess, or following an evidence-based clinical algorithm is better than just prescribing
whatever you feel like.

Fifth, there is nothing whatsoever to be gained or learned from the people involved (eg the city’s 
future citizens). You are a rational modern scientist with an architecture degree who has already 
calculated out the precise value for all relevant urban parameters. They are yokels who probably cannot
even spell the word architecture, let alone usefully contribute to it. They probably make all of their
decisions based on superstition or tradition or something, and their input should be ignored For Their
Own Good.
```

Jane Jacobs' critique of them, as summarized twice over by James and Scott:

```markdown
First, existing structures are evolved organisms built by people trying to satisfy their social
goals. They contain far more wisdom about people’s needs and desires than anybody could formally
enumerate. Any attempt at urban planning should try to build on this encoded knowledge, not 
detract from it.

Second, man does not live by bread alone. People don’t want the right amount of Standardized Food
Product, they want social interaction, culture, art, coziness, and a host of other things nobody 
will ever be able to calculate. Existing structures have already been optimized for these things,
and unless you’re really sure you understand all of them, you should be reluctant to disturb them.

Third, solutions are local. Americans want different things than Africans or Indians. One proof of
this is that New York looks different from Lagos and from Delhi. Even if you are the world’s best 
American city planner, you should be very concerned that you have no idea what people in Africa 
need, and you should be very reluctant to design an African city without extensive consultation of
people who understand the local environment.

Fourth, even a very smart and well-intentioned person who is on board with points 1-3 will never be
able to produce a set of rules. Most of people’s knowledge is implicit, and most rule codes are 
quickly replaced by informal systems of things that work which are much more effective (the classic 
example of this is work-to-rule strikes).

Fifth, although well-educated technocrats may understand principles which give them some advantages
in their domain, they are hopeless without the on-the-ground experience of the people they are trying
to serve, whose years of living in their environment and dealing with it every day have given them a
deep practical knowledge which is difficult to codify.
```

To the Tukanoans' multistep manioc/cassava processing, the Naskapi foragers' randomized caribou-hunting and Kantus' bird augury for agricultural plot location selection at the beginning of this section James adds the example of Tanzanian farming:

```markdown
(In Tanzania), small farmers grew dozens of different crops together in seeming chaos. Western 
colonists tried to convince them – often by force – to switch to just growing one thing at a time 
to reap advantages of efficiency, standardization, and specialization of labor. Only growing one 
crop in the same field was Agricultural Science 101. But this turned out to be a bad idea in the 
difficult Tanzanian environment:

	The multistoried effect of polyculture has some distinct advantages for yields and soil 
	conservation. “Upper-story” crops shade “lowerstory” crops, which are selected for their
	ability to thrive in the cooler soil temperature and increased humidity at ground level.
	Rainfall reaches the ground not directly but as a fine spray that is absorbed with less
	damage to soil structure and less erosion. The taller crops often serve as a useful 
	windbreak for the lower crops. Finally, in mixed or relay cropping, a crop is in the field
	at all times, holding the soil together and reducing the leaching effects that sun, wind,
	and rain exert, particularly on fragile land. Even if polyculture is not to be preferred
	on the grounds of immediate yield, there is much to recommend it in terms of sustainability
	and thus long-term production.

	Our discussion of mixed cropping has thus far dealt only with the narrow issues of yield 
	and soil conservation. It has overlooked the cultivators themselves and the various other
	ends that they seek by using such techniques. The most significant advantage of 
	intercropping, Paul Richards claims, is its great flexibility, “the scope [it] offers for
	a range of combinations to match individual needs and preferences, local conditions, and 
	changing circumstances within each season and from season to season.” Farmers may polycrop 
	in order to avoid labor bottlenecks at planting and at harvest.44Growing many different 
	crops is also an obvious way to spread risks and improve food security. Cultivators can
	reduce the danger of going hungry if they sow, instead of only one or two cultivars, crops
	of long and short maturity, crops that are drought resistant and those that do well under
	wetter conditions, crops with different patterns of resistance to pests and diseases, crops
	that can be stored in the ground with little loss (such as cassava), and crops that mature 
	in the “hungry time” before other crops are gathered. Finally, and perhaps most important, 
	each of these crops is embedded in a distinctive set of social relations. Different members
	of the household are likely to have different rights and responsibilities with respect to
	each crop. The planting regimen, in other words, is a reflection of social relations, ritual
	needs, and culinary tastes; it is not just a production strategy that a profit-maximizing 
	entrepreneur took straight out of the pages of a text in neoclassical economics.
```

Okay. After all this talk negatively portraying legibility, is it *bad* somehow? James says that's not what he was getting at:

```markdown
...he’s not against legibility and modernism per se, but he wants to present them as ingredients
in a cocktail of state failure. You need a combination of four things to get a disaster like Soviet
collective farming (or his other favorite example, compulsory village settlement in Tanzania). 
First, a government incentivized to seek greater legibility for its population and territory. 
Second, a High Modernist ideology. Third, authoritarianism. And fourth, a “prostrate civil society”,
like in Russia after the Revolution, or in colonies after the Europeans took over.

I think his theory is that the back-and-forth between centralized government and civil society allows
scientific advances to be implemented smoothly instead of just plowing over everyone in a way that 
leads to disaster. I also think that maybe a big part of it is incremental versus sudden: western 
farming did well because it got to incrementally add advances and see how they worked, but when you
threw the entire edifice at Tanzania it crashed and burned.
```

<a name="#anthropic-principle"></a>
## Anthropic principle
([overview](#overview))

<a name="#critiques-of-the-anthropic-principle"></a>
### Critiques of the anthropic principle
([overview](#overview))

Funny if uncharitable quote by Cosma Shalizi from the introduction to his notebook [Astrophysics and Cosmology](http://bactra.org/notebooks/astrophysics.html):

```markdown
There are interesting issues of statistical mechanics involved, since there are long-range 
interactions: gravity falls off only slowly with distance r-2, after all), and, unlike 
electromagnetism, there are no positive and negative charges which could lead to screening off.
This leads to some weird effects, like spontaneous clumping, and possibilities like negative 
specific heats.

A personal hatred: the anthropic principle. To illustrate: I once happened --- no joke --- to 
find a twenty dollar bill lying in the street in front of my house. This required an extraordinarily
fine adjustment of a huge range of circumstances. Among these, of course, were the incidents of
American history such that we use paper money, denominated in dollars, that the twenty is a common
but large denomination, and that Andrew Jackson's portait be on it. This last involves our political
history through and indeed since Jackson's time. That political history is incomprehensible without 
the influence of the Enlightenment, and of the ideological struggles of 17th century England (no
Lockean possessive individualism, no Jacksonian democracy). Those struggles were intimately tied to
England's political and military history in the 17th century, which is only comprehensible in light of
(among much else) the Norman Invasion, which in turn was only possible given the condition of Anglo-
Saxon England in 1066, but there would have been no Anglo-Saxon England had there not first been a 
Roman Britain. There would have been no Roman Britain had Britain not already been partly integrated 
into the broader trading network, which was largely on account, then, of its metals. 

So, reasoning anthropically, I can conclude, from my stray twenty, that it was necessary that there be
tin in southern Britain.
```

Cosma also led me to this paper by Lee Smolin, [Scientific alternatives to the anthropic principle](https://arxiv.org/abs/hep-th/0407213), whose abstract is just as blunt:

```markdown
It is explained in detail why the Anthropic Principle (AP) cannot yield any falsifiable predictions,
and therefore cannot be a part of science. Cases which have been claimed as successful predictions 
from the AP are shown to be not that. Either they are uncontroversial applications of selection 
principles in one universe (as in Dicke's argument), or the predictions made do not actually logically 
depend on any assumption about life or intelligence, but instead depend only on arguments from
observed facts (as in the case of arguments by Hoyle and Weinberg). The Principle of Mediocrity is
also examined and shown to be unreliable, as arguments for factually true conclusions can easily be
modified to lead to false conclusions by reasonable changes in the specification of the ensemble in 
which we are assumed to be typical. 

We show however that it is still possible to make falsifiable predictions from theories of 
multiverses, if the ensemble predicted has certain properties specified here. An example of such a 
falsifiable multiverse theory is cosmological natural selection. It is reviewed here and it is argued
that the theory remains unfalsified. But it is very vulnerable to falsification by current observations,
which shows that it is a scientific theory.
```

Cosma thinks Smolin is right on the money:

```markdown
Take, for instance, the example he gives in section 5.1.3. Fred Hoyle once reasoned that carbon is 
necessary for life, that carbon must have been formed by stellar nucleosynthesis, and that this reaction
could only have proceeded if carbon nuclei had certain properties, which experimentalists then proceeded
to show they did have. Smolin fairly schematizes this as follows. 

(1) X is necessary for life (or intelligence, etc.). 
(2) X is, as it happens, true. 
(3) If X is true, and the laws of physics are Y, then Z must also be true. 
(4) Therefore Z.

We see clearly that the prediction of Z in no way depends on step 1. The argument has the same force if 
step 1 is removed. To see this ask what we would do were Z found not to be true. Our only option would be
to question either Y or the deduction from the presently known laws of physics to Z. We might conclude 
that the deduction was wrong, for example if we made a mistake in a calculation. If no such option worked,
we might have to conclude that the laws of physics might have to be modified. But we would never question 1,
because, while a true fact, it plays no role in the logic of the argument leading to the prediction for Z.
```

There are actually seven subsections that Smolin devotes to 'varieties of the anthropic principle'; feel free to check them out.

<a name="#Anglerfish-and-beacons"></a>
## Anglerfish and beacons
([overview](#overview))

Ben Hoffman talks about avoiding anglerfish, or Chapman's sociopaths, in a great essay I often come back to called [On the construction of beacons](http://benjaminrosshoffman.com/construction-beacons/). I tried not to just copy-paste everything, but Ben doesn't waste words, he's a precision writer, so it's hard to leave things out because "everything is in its place" so to speak.

First of all, why "anglerfish"?

```markdown
The anglerfish lives in waters too far beneath the surface of the sea for sunlight to reach.
It dangles a luminescent lure in front of itself. This resembles a fishing angle, whence 
comes its name. This lure attracts animals of the deep sea, which approach the anglerfish, 
and are consequently eaten by it.

Why - in the deep sea where no sunlight can reach - would evolution favor animals that are
attracted to light?

The secondary uses of such a strategy are clear enough. Once some deep-sea-dwellers emit
light, larger animals that predate on them might do better if attracted to light sources. 
But that presupposes the existence of other animals that already emit light, for other
reasons.

What are the primary uses of light? In a region where no other creatures emit light, here 
are some reasons why would might begin to do so:

1. To illuminate potential prey.
2. As a ward, to warn potential competitors that one is prepared to defend territory.
3. To attract complementary animals, either as symbiotes, or as mates.

In all these cases, the purpose of the light is to *reveal information*. In all but the
first case, it is to *share information with others, in order to enable cooperation*. 
Perhaps the purest version of this is the mating display. We can see this in the firefly, 
which uses its distinctive patterns of luminescent flashes to find mates.

The firefly has some information. It activates a beacon, in order to find someone with 
*complementary information*, in order to engage in *productive exchange*. Likewise for 
deep-sea fish who mate or find symbiotes by means of a light display.

The predation strategy of the anglerfish, properly generalized is a strategy that predates
on all information-seeking behavior, whether competitive or cooperative. The anglerfish
does not need to know that the animal that just swam in front of it is evaluating its 
mating display and finds it wanting, or is looking for a very different creature as a 
symbiote. So long as there are animals seeking illumination, the anglerfish only cares that
some calories and raw materials have been brought within reach of a single burst of 
swimming and the clamping shut of its great maw.

Typically, a predator has to be more sophisticated than the creatures on which it preys.
But the anglerfish follows a simple, information-poor strategy, that preys on sophisticated,
information-rich ones. It doesn’t have to be a particularly skilled mimic - it simply preys
on the fact that creatures seeking information will move towards beacons.
```

How does this analogize to subculture dilution?

```markdown
In David Chapman’s geeks, MOPs, and sociopaths, “geeks” are the originators of subcultures. 
They are persons of refined taste and discernment. They found subcultures by discovering or
creating something they believe to be of intrinsic value. The originators of this information
share it with others, and the first to respond enthusiastically will be other geeks, who can 
tell that the content of the message is valuable.

Eventually, enough geeks congregate together, and the thing they are creating together becomes
valuable enough, that people without the power to independently discern the source of value 
can tell that value is being created. These Chapman calls “Members Of the Public”, or “MOP”s. 
Geeks map roughly onto Aellagirl's possums, MOPs onto otters.

In the right ratios, MOPs and Geeks are symbiotes. The MOPs enjoy the benefits of the thing the
geeks created, and are generally happy to share their social capital, including money, with the
geeks.

But from another perspective MOPs are an exploitable resource, which the geeks have gathered in
one place but are neither efficiently exploiting, nor effectively defending. This attracts
people following a strategy of predating on such clusters of MOPs. These predators, whom Chapman
names “sociopaths,” do not care about the idiosyncratic value the geeks are busy creating. What 
they do care about, is the generic resources - attention, money, volunteer hours, social proof -
that the MOPs provide.

To summarize the above: Geeks build beacons. Initially these beacons are not very bright, but
they are sending out high-information signals which attract other geeks looking for that 
information. Eventually, enough geeks are contributing to the beacons that they become bright
enough to attract MOPs.

Chapman’s sociopaths can’t just waltz in and propose that everyone give them things for nothing.
After all, everyone in their feeding ground was attracted to it by something about it, something
that distinguishes it from other places in the culture. They need to look like a part of the 
scene. So they start by imitating, or proposing refinements to, the beacons the geeks have erected.

The geeks are only putting up a very particular kind of beacon. There are a lot of constraints 
on exactly what sort of signal they are willing to send. This is the same as saying that their 
beacons have a lot of information content. From the geeks’ perspective, the exchange of this 
information is the whole point of setting up beacons, and the presence of friendly MOPs is just a
happy side effect.

But from the sociopaths’ perspective, these information-bearing constraints are mere shibboleths.
Chapman’s sociopaths will follow whatever rules they have to in order to pass as contributors to
the subculture, but they won’t put independent effort into understanding why these rules are the 
ones they have to follow. Instead, their contribution is to **iteratively improve the beacons’ 
ability to attract prey.**

As sociopaths test out variations in their beacons, they will learn which variants are best at 
attracting people, by means of trial and error. Three things about this will reduce the relative 
proportion of geeks in the subculture, and therefore the geeks’ influence.

1. First, since MOPs are less sensitive to fine variations in signal than geeks are, random
mutations in beacon design are more likely to attract more MOPs than more geeks.

2. Second, as the overall process becomes better at attracting MOPs, more sociopaths will notice
that it is a promising feeding ground.

3. Finally, many changes that are neutral or beneficial for attracting MOPs, will, from the geeks’ 
perspective, seem like the introduction of errors. This will make the signal less attractive to
geeks who have not already invested in the subculture.

What does this process look like from the geeks’ perspective?

At first - people are coming into the geeks’ subculture, and trying to contribute to it. These
newcomers are putting a lot of energy into creating new content, but from time to time 
introduce perplexing errors. But, they are getting a lot of people interested in this wonderful
information you’ve created, so the geeks are not inclined to complain. The MOPs basically trust
the geeks’ implied endorsement, and accept the new contributors on the same footing as the old 
ones.

But now there are two forces at play affecting the content of the signals being sent. One is a
force correcting errors - the geeks’ desire to preserve, transmit, and develop the original 
information-content of the signal. The other force introduces errors: the sociopaths’ desire to
attract more MOPs. When the second force becomes stronger than the first, the sociopaths are now 
the dominant faction, and able to coordinate to suppress geek attempts to correct errors that 
make the message more popular.

At first, the MOPs’ acceptance of the sociopaths depended in part on the geeks’ tacit endorsement.
But once a sufficiently powerful faction of sociopaths has been given social proof, they can wield
the force of disendorsement against the geeks. The only meaningful constraint is that MOPs don’t
like conflict, so the sociopaths will want to avoid escalating to a point where the conflict
becomes overt.

From the sociopaths’ perspective, the geeks were inexplicably donating their time and energy to 
discovering a new signal to broadcast, that would attract a pool of MOPs to feed on. But the geeks
were - again incomprehensibly - neither exploiting nor defending that resource. The sociopath 
strategy invests in general understanding of social dynamics, but does not need to understand the 
specific content of what the geeks are trying to do. The sociopath need only know that some
attention, money, volunteer hours, and social proof have been brought within reach of a competent
marketing and sales effort.

From the sociopaths' perspective, they are not introducing errors - they are correcting them.

The paradigmatic predator is sufficiently smarter than its targets to anticipate and manipulate
their behavior. But Chapman’s sociopaths follow a simple, information-poor strategy, that preys on
sophisticated, information-rich ones. This strategy doesn’t have to understand the signal as well 
as the geeks do - the geeks will help it pass their tests (because geeks are usually guess culture,
and guess culture screens for trying to cooperate). It simply iterates empirically towards shining 
the most attractive beacon it can, of a kind that has already been selected to attract its prey.

The predation strategy of Chapman’s sociopath is a strategy that predates on all information-
seeking behavior, whether competitive or cooperative.
```

Note that sociopaths aren't "bad":

```markdown
Sociopaths are not necessarily universally bad or mean people. They just *don't care about your 
project*. This is fine. You don't care about most people's projects. Likewise, most people don't 
care about yours. The problem is when you let those people run your project.

As far as Chapman's sociopaths know, they are just doing what one does to beacons - trying to make
them more pleasing to more people. They are cooperating with the geeks as sincerely as they know 
how - as sincerely as the believe to be possible. In many cases they simply don’t understand that
the original signal had value. There's little point in being indignant about this.
```

It's the "geeks" who're most responsible for maintaining that subculture, and for the creation of community standards:

```markdown
The people who need to do something about the corruption of a message are the people who *care
the most about that message*: the geeks. In subcultures following this lifecycle, geeks have 
committed a key sin: trying to get something for nothing, by pretending to be more popular than
we are.

People playing sociopath strategies gain a foothold in subcultures, because they *bring in more
resources*, get more people involved, get attention from respectable people, raise money - since 
they are paying attention to how attractive their beacons are, not whether they are correct 
(from a geek perspective).

The obvious strategy to counter this is to speak up early and often when errors are being 
introduced. It is not a sin to be error-tolerant, in the sense of not immediately expelling people 
for making errors. But it is *always* a sin, in an otherwise-cooperative community, to *suppress the
calling-out of errors*, in order to avoid making a scene, scaring off the MOPs, harming morale and
momentum. If you are a geek in that sort of subculture, the MOPs are relying on your implied 
endorsement of the other content-creators. If you remain silent in the face of error, then you are
*betraying this trust*. There is no additional error-correction system that will save you - you were
supposed to be the error-correction system.

If you and your collaborators diligently follow this practice, then this will enable the creation 
of common knowledge when someone is reliably introducing errors, and either failing to correct them
or making the minimum possible correction. You will have shared knowledge of track records - who is
introducing information, and who is destroying it with noise. It is only with this knowledge that 
you can begin to have actual community standards.
```
