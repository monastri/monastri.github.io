Sarah Constantin is one of my favorite writers. She has a blog, [Otium](https://srconstantin.wordpress.com/), and goes by 
celandine13 on LiveJournal. This quote on the _error vs bug model of learning_ comes from her LJ essay 
[Errors vs Bugs and the End of Stupidity](https://celandine13.livejournal.com/33599.html).

```markdown
A common mental model for performance is what I'll call the "error model."  In the error model, a person's 
performance of a musical piece (or performance on a test) is a perfect performance plus some random error.  
You can literally think of each note, or each answer, as x + c times epsilon_i, where x is the correct note 
/ answer, and epsilon_i is a random variable, iid Gaussian or something.  Better performers have a lower 
error rate c.  Improvement is a matter of lowering your error rate.  This, or something like it, is the model 
that underlies school grades and test scores. Your grade is based on the percent you get correct.  Your 
performance is defined by a single continuous parameter, your accuracy.

But we could also consider the "bug model" of errors.  A person taking a test or playing a piece of music is 
executing a program, a deterministic procedure.  If your program has a bug, then you'll get a whole class of 
problems wrong, consistently.  Bugs, unlike error rates, can't be quantified along a single axis as less or 
more severe.  A bug gets everything that it affects wrong.  And fixing bugs doesn't improve your performance 
in a continuous fashion; you can fix a "little" bug and immediately go from getting everything wrong to 
everything right.  You can't really describe the accuracy of a buggy program by the percent of questions it 
gets right; if you ask it to do something different, it could suddenly go from 99% right to 0% right.  You 
can only define its behavior by isolating what the bug does.

Often, I think mistakes are more like bugs than errors.  My clinkers weren't random; they were in specific 
places, because I had sub-optimal fingerings in those places.  A kid who gets arithmetic questions wrong 
usually isn't getting them wrong at random; there's something missing in their understanding, like not 
getting the difference between multiplication and addition.  Working generically "harder" doesn't fix bugs 
(though fixing bugs does require work). 

Once you start to think of mistakes as deterministic rather than random, as caused by "bugs" (incorrect 
understanding or incorrect procedures) rather than random inaccuracy, a curious thing happens.

You stop thinking of people as "stupid."

Tags like "stupid," "bad at X", "sloppy," and so on, are ways of saying "You're performing badly and I 
don't know why." Once you move it to "you're performing badly because you have the wrong fingerings," or 
"you're performing badly because you don't understand what a limit is," it's no longer a vague personal 
failing but a causal necessity. Anyone who never understood limits will flunk calculus. 

It's not you, it's the bug.
```

The rest of the linked article is _fantastic_. I had trouble quoting it because I felt like quoting everything.

Megan McArdle, [Only stupid people call people stupid](https://www.bloomberg.com/opinion/articles/2014-08-12/only-stupid-people-call-people-stupid):

```markdown
I’m always fascinated by the number of people who proudly build columns, tweets, blog posts or Facebook 
posts around the same core statement: “I don’t understand how anyone could (oppose legal abortion/support 
a carbon tax/sympathize with the Palestinians over the Israelis/want to privatize Social Security/insert 
your pet issue here)." It’s such an interesting statement, because it has three layers of meaning.

The first layer is the literal meaning of the words: *I lack the knowledge and understanding to figure this 
out*. But the second, intended meaning is the opposite: *I am such a superior moral being that I cannot even 
imagine the cognitive errors or moral turpitude that could lead someone to such obviously wrong conclusions*. 
And yet, the third, true meaning is actually more like the first: *I lack the empathy, moral imagination or 
analytical skills to attempt even a basic understanding of the people who disagree with me*.

In short, “I’m stupid.” Something that few people would ever post so starkly on their Facebook feeds.
```

Steven Pinker, [The trouble with Harvard](https://newrepublic.com/article/119321/harvard-ivy-league-should-judge-students-standardized-tests): 

```markdown
A skilled professional I know had to turn down an important freelance assignment because of a recurring 
commitment to chauffeur her son to a resumé-building “social action” assignment required by his high 
school. This involved driving the boy for 45 minutes to a community center, cooling her heels while he 
sorted used clothing for charity, and driving him back—forgoing income which, judiciously donated, could 
have fed, clothed, and inoculated an African village. The dubious “lessons” of this forced labor as an 
overqualified ragpicker are that children are entitled to treat their mothers’ time as worth nothing, 
that you can make the world a better place by destroying economic value, and that the moral worth of 
an action should be measured by the conspicuousness of the sacrifice rather than the gain to the beneficiary.
```

Douglas Hofstadter on the necessary strangeness of scientific explanations:

```markdown
It is no accident, I would maintain, that quantum mechanics is so wildly counterintuitive. Part of the 
nature of explanation is that it must eventually hit some point where further probing only increases 
opacity rather than decreasing it. 

Consider the problem of understanding the nature of solids. You might wonder where solidity comes form. 
What if someone said to you, "The ultimate basis of this brick's solidity is that it is composed of a 
stupendous number of eensy weensy bricklike objects that themselves are rock-solid"? You might be 
interested to learn that bricks are composed of micro-bricks, but the initial question - "What accounts 
for solidity?" - has been thoroughly begged. What we ultimately want is for solidity to vanish, to 
dissolve, to disintegrate into some totally different kind of phenomenon with which we have no experience. 
Only then, when we have reached some completely novel, alien level will we feel that we have really made 
progress in explaining the top-level phenomenon.

...

I first saw this thought expressed in the stimulating book Patterns of Discovery by Norwood Russell 
Hanson. Hanson attributes it to a number of thinkers, such as Isaac Newton, who wrote, in his famous 
work Opticks: "The parts of all homogeneal hard Bodies which fully touch one another, stick together 
very strongly. And for explaining how this may be, some have invented hooked Atoms, which is begging 
the Question." Hanson also quotes James Clerk Maxwell (from an article entitled "Atom"): "We may 
indeed suppose the atom elastic, but this is to endow it with the very property for the explanation 
of which... the atomic constitution was originally assumed." Finally, here is a quote Hanson provides 
from Werner Heisenberg himself: "If atoms are really to explain the origin of color and smell of 
visible material bodies, then they cannot possess properties like color and smell." 

So, although it is not an original thought, it is useful to bear in mind that "greenness disintegrates".
```

From Scott Aaronson's [Quantum Computing Since Democritus](https://slatestarcodex.com/2014/09/01/book-review-and-highlights-quantum-computing-since-democritus/):

```markdown
The third thing that annoys me about the Chinese Room argument is the way it gets so much mileage from 
a possibly misleading choice of imagery, or, one might say, by trying to sidestep the entire issue of 
computational complexity purely through clever framing. We’re invited to imagine someone pushing around 
slips of paper with zero understanding or insight, much like the doofus freshmen who write 
(a + b)^2 = a^2 + b^2 on their math tests. 

But how many slips of paper are we talking about! How big would the rule book have to be, and how 
quickly would you have to consult it, to carry out an intelligent Chinese conversation in anything 
resembling real time? If each page of the rule book corresponded to one neuron of a native speaker’s 
brain, then probably we’d be talking about a “rule book” at leas the size of the Earth, its pages 
searchable by a swarm of robots traveling at close to the speed of light. When you put it that way, 
maybe it’s not so hard to imagine this enormous Chinese-speaking entity that we’ve brought into being 
might have something we’d be prepared to call understanding or insight.

Philosophers are so good at pure qualitative distinctions that it’s easy to slip the difference between 
“guy in a room” and “planet being processed by lightspeed robots” under the rug.
```
